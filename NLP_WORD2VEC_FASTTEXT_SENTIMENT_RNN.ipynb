{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djvampire123/NLP_SENTIMENT_RNN/blob/main/NLP_WORD2VEC_FASTTEXT_SENTIMENT_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gdCwjPsQ3tM",
        "outputId": "4fbf0872-e7ee-47de-f3e7-07880a3a999e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "aclImdb/train/unsup/44983_0.txt\n",
            "aclImdb/train/unsup/44982_0.txt\n",
            "aclImdb/train/unsup/44981_0.txt\n",
            "aclImdb/train/unsup/44980_0.txt\n",
            "aclImdb/train/unsup/44979_0.txt\n",
            "aclImdb/train/unsup/44978_0.txt\n",
            "aclImdb/train/unsup/44977_0.txt\n",
            "aclImdb/train/unsup/44976_0.txt\n",
            "aclImdb/train/unsup/44975_0.txt\n",
            "aclImdb/train/unsup/44974_0.txt\n",
            "aclImdb/train/unsup/44973_0.txt\n",
            "aclImdb/train/unsup/44972_0.txt\n",
            "aclImdb/train/unsup/44971_0.txt\n",
            "aclImdb/train/unsup/44970_0.txt\n",
            "aclImdb/train/unsup/44969_0.txt\n",
            "aclImdb/train/unsup/44968_0.txt\n",
            "aclImdb/train/unsup/44967_0.txt\n",
            "aclImdb/train/unsup/44966_0.txt\n",
            "aclImdb/train/unsup/44965_0.txt\n",
            "aclImdb/train/unsup/44964_0.txt\n",
            "aclImdb/train/unsup/44963_0.txt\n",
            "aclImdb/train/unsup/44962_0.txt\n",
            "aclImdb/train/unsup/44961_0.txt\n",
            "aclImdb/train/unsup/44960_0.txt\n",
            "aclImdb/train/unsup/44959_0.txt\n",
            "aclImdb/train/unsup/44958_0.txt\n",
            "aclImdb/train/unsup/44957_0.txt\n",
            "aclImdb/train/unsup/44956_0.txt\n",
            "aclImdb/train/unsup/44955_0.txt\n",
            "aclImdb/train/unsup/44954_0.txt\n",
            "aclImdb/train/unsup/44953_0.txt\n",
            "aclImdb/train/unsup/44952_0.txt\n",
            "aclImdb/train/unsup/44951_0.txt\n",
            "aclImdb/train/unsup/44950_0.txt\n",
            "aclImdb/train/unsup/44949_0.txt\n",
            "aclImdb/train/unsup/44948_0.txt\n",
            "aclImdb/train/unsup/44947_0.txt\n",
            "aclImdb/train/unsup/44946_0.txt\n",
            "aclImdb/train/unsup/44945_0.txt\n",
            "aclImdb/train/unsup/44944_0.txt\n",
            "aclImdb/train/unsup/44943_0.txt\n",
            "aclImdb/train/unsup/44942_0.txt\n",
            "aclImdb/train/unsup/44941_0.txt\n",
            "aclImdb/train/unsup/44940_0.txt\n",
            "aclImdb/train/unsup/44939_0.txt\n",
            "aclImdb/train/unsup/44938_0.txt\n",
            "aclImdb/train/unsup/44937_0.txt\n",
            "aclImdb/train/unsup/44936_0.txt\n",
            "aclImdb/train/unsup/44935_0.txt\n",
            "aclImdb/train/unsup/44934_0.txt\n",
            "aclImdb/train/unsup/44933_0.txt\n",
            "aclImdb/train/unsup/44932_0.txt\n",
            "aclImdb/train/unsup/44931_0.txt\n",
            "aclImdb/train/unsup/44930_0.txt\n",
            "aclImdb/train/unsup/44929_0.txt\n",
            "aclImdb/train/unsup/44928_0.txt\n",
            "aclImdb/train/unsup/45183_0.txt\n",
            "aclImdb/train/unsup/45182_0.txt\n",
            "aclImdb/train/unsup/45181_0.txt\n",
            "aclImdb/train/unsup/45180_0.txt\n",
            "aclImdb/train/unsup/45179_0.txt\n",
            "aclImdb/train/unsup/45178_0.txt\n",
            "aclImdb/train/unsup/45177_0.txt\n",
            "aclImdb/train/unsup/45176_0.txt\n",
            "aclImdb/train/unsup/45175_0.txt\n",
            "aclImdb/train/unsup/45174_0.txt\n",
            "aclImdb/train/unsup/45173_0.txt\n",
            "aclImdb/train/unsup/45172_0.txt\n",
            "aclImdb/train/unsup/45171_0.txt\n",
            "aclImdb/train/unsup/45170_0.txt\n",
            "aclImdb/train/unsup/45169_0.txt\n",
            "aclImdb/train/unsup/45168_0.txt\n",
            "aclImdb/train/unsup/45167_0.txt\n",
            "aclImdb/train/unsup/45166_0.txt\n",
            "aclImdb/train/unsup/45165_0.txt\n",
            "aclImdb/train/unsup/45164_0.txt\n",
            "aclImdb/train/unsup/45163_0.txt\n",
            "aclImdb/train/unsup/45162_0.txt\n",
            "aclImdb/train/unsup/45161_0.txt\n",
            "aclImdb/train/unsup/45160_0.txt\n",
            "aclImdb/train/unsup/45159_0.txt\n",
            "aclImdb/train/unsup/45158_0.txt\n",
            "aclImdb/train/unsup/45157_0.txt\n",
            "aclImdb/train/unsup/45156_0.txt\n",
            "aclImdb/train/unsup/45155_0.txt\n",
            "aclImdb/train/unsup/45154_0.txt\n",
            "aclImdb/train/unsup/45153_0.txt\n",
            "aclImdb/train/unsup/45152_0.txt\n",
            "aclImdb/train/unsup/45151_0.txt\n",
            "aclImdb/train/unsup/45150_0.txt\n",
            "aclImdb/train/unsup/45149_0.txt\n",
            "aclImdb/train/unsup/45148_0.txt\n",
            "aclImdb/train/unsup/45147_0.txt\n",
            "aclImdb/train/unsup/45146_0.txt\n",
            "aclImdb/train/unsup/45145_0.txt\n",
            "aclImdb/train/unsup/45144_0.txt\n",
            "aclImdb/train/unsup/45143_0.txt\n",
            "aclImdb/train/unsup/45142_0.txt\n",
            "aclImdb/train/unsup/45141_0.txt\n",
            "aclImdb/train/unsup/45140_0.txt\n",
            "aclImdb/train/unsup/45139_0.txt\n",
            "aclImdb/train/unsup/45138_0.txt\n",
            "aclImdb/train/unsup/45137_0.txt\n",
            "aclImdb/train/unsup/45136_0.txt\n",
            "aclImdb/train/unsup/45135_0.txt\n",
            "aclImdb/train/unsup/45134_0.txt\n",
            "aclImdb/train/unsup/45133_0.txt\n",
            "aclImdb/train/unsup/45132_0.txt\n",
            "aclImdb/train/unsup/45131_0.txt\n",
            "aclImdb/train/unsup/45130_0.txt\n",
            "aclImdb/train/unsup/45129_0.txt\n",
            "aclImdb/train/unsup/45128_0.txt\n",
            "aclImdb/train/unsup/45127_0.txt\n",
            "aclImdb/train/unsup/45126_0.txt\n",
            "aclImdb/train/unsup/45125_0.txt\n",
            "aclImdb/train/unsup/45124_0.txt\n",
            "aclImdb/train/unsup/45123_0.txt\n",
            "aclImdb/train/unsup/45122_0.txt\n",
            "aclImdb/train/unsup/45121_0.txt\n",
            "aclImdb/train/unsup/45120_0.txt\n",
            "aclImdb/train/unsup/45119_0.txt\n",
            "aclImdb/train/unsup/45118_0.txt\n",
            "aclImdb/train/unsup/45117_0.txt\n",
            "aclImdb/train/unsup/45116_0.txt\n",
            "aclImdb/train/unsup/45115_0.txt\n",
            "aclImdb/train/unsup/45114_0.txt\n",
            "aclImdb/train/unsup/45113_0.txt\n",
            "aclImdb/train/unsup/45112_0.txt\n",
            "aclImdb/train/unsup/45111_0.txt\n",
            "aclImdb/train/unsup/45110_0.txt\n",
            "aclImdb/train/unsup/45109_0.txt\n",
            "aclImdb/train/unsup/45108_0.txt\n",
            "aclImdb/train/unsup/45107_0.txt\n",
            "aclImdb/train/unsup/45106_0.txt\n",
            "aclImdb/train/unsup/45105_0.txt\n",
            "aclImdb/train/unsup/45104_0.txt\n",
            "aclImdb/train/unsup/45103_0.txt\n",
            "aclImdb/train/unsup/45102_0.txt\n",
            "aclImdb/train/unsup/45101_0.txt\n",
            "aclImdb/train/unsup/45100_0.txt\n",
            "aclImdb/train/unsup/45099_0.txt\n",
            "aclImdb/train/unsup/45098_0.txt\n",
            "aclImdb/train/unsup/45097_0.txt\n",
            "aclImdb/train/unsup/45096_0.txt\n",
            "aclImdb/train/unsup/45095_0.txt\n",
            "aclImdb/train/unsup/45094_0.txt\n",
            "aclImdb/train/unsup/45093_0.txt\n",
            "aclImdb/train/unsup/45092_0.txt\n",
            "aclImdb/train/unsup/45091_0.txt\n",
            "aclImdb/train/unsup/45090_0.txt\n",
            "aclImdb/train/unsup/45089_0.txt\n",
            "aclImdb/train/unsup/45088_0.txt\n",
            "aclImdb/train/unsup/45087_0.txt\n",
            "aclImdb/train/unsup/45086_0.txt\n",
            "aclImdb/train/unsup/45085_0.txt\n",
            "aclImdb/train/unsup/45084_0.txt\n",
            "aclImdb/train/unsup/45083_0.txt\n",
            "aclImdb/train/unsup/45082_0.txt\n",
            "aclImdb/train/unsup/45081_0.txt\n",
            "aclImdb/train/unsup/45080_0.txt\n",
            "aclImdb/train/unsup/45079_0.txt\n",
            "aclImdb/train/unsup/45078_0.txt\n",
            "aclImdb/train/unsup/45077_0.txt\n",
            "aclImdb/train/unsup/45076_0.txt\n",
            "aclImdb/train/unsup/45075_0.txt\n",
            "aclImdb/train/unsup/45074_0.txt\n",
            "aclImdb/train/unsup/45073_0.txt\n",
            "aclImdb/train/unsup/45072_0.txt\n",
            "aclImdb/train/unsup/45071_0.txt\n",
            "aclImdb/train/unsup/45070_0.txt\n",
            "aclImdb/train/unsup/45069_0.txt\n",
            "aclImdb/train/unsup/45068_0.txt\n",
            "aclImdb/train/unsup/45067_0.txt\n",
            "aclImdb/train/unsup/45066_0.txt\n",
            "aclImdb/train/unsup/45065_0.txt\n",
            "aclImdb/train/unsup/45064_0.txt\n",
            "aclImdb/train/unsup/45063_0.txt\n",
            "aclImdb/train/unsup/45062_0.txt\n",
            "aclImdb/train/unsup/45061_0.txt\n",
            "aclImdb/train/unsup/45060_0.txt\n",
            "aclImdb/train/unsup/45059_0.txt\n",
            "aclImdb/train/unsup/45058_0.txt\n",
            "aclImdb/train/unsup/45057_0.txt\n",
            "aclImdb/train/unsup/45056_0.txt\n",
            "aclImdb/train/unsup/45311_0.txt\n",
            "aclImdb/train/unsup/45310_0.txt\n",
            "aclImdb/train/unsup/45309_0.txt\n",
            "aclImdb/train/unsup/45308_0.txt\n",
            "aclImdb/train/unsup/45307_0.txt\n",
            "aclImdb/train/unsup/45306_0.txt\n",
            "aclImdb/train/unsup/45305_0.txt\n",
            "aclImdb/train/unsup/45304_0.txt\n",
            "aclImdb/train/unsup/45303_0.txt\n",
            "aclImdb/train/unsup/45302_0.txt\n",
            "aclImdb/train/unsup/45301_0.txt\n",
            "aclImdb/train/unsup/45300_0.txt\n",
            "aclImdb/train/unsup/45299_0.txt\n",
            "aclImdb/train/unsup/45298_0.txt\n",
            "aclImdb/train/unsup/45297_0.txt\n",
            "aclImdb/train/unsup/45296_0.txt\n",
            "aclImdb/train/unsup/45295_0.txt\n",
            "aclImdb/train/unsup/45294_0.txt\n",
            "aclImdb/train/unsup/45293_0.txt\n",
            "aclImdb/train/unsup/45292_0.txt\n",
            "aclImdb/train/unsup/45291_0.txt\n",
            "aclImdb/train/unsup/45290_0.txt\n",
            "aclImdb/train/unsup/45289_0.txt\n",
            "aclImdb/train/unsup/45288_0.txt\n",
            "aclImdb/train/unsup/45287_0.txt\n",
            "aclImdb/train/unsup/45286_0.txt\n",
            "aclImdb/train/unsup/45285_0.txt\n",
            "aclImdb/train/unsup/45284_0.txt\n",
            "aclImdb/train/unsup/45283_0.txt\n",
            "aclImdb/train/unsup/45282_0.txt\n",
            "aclImdb/train/unsup/45281_0.txt\n",
            "aclImdb/train/unsup/45280_0.txt\n",
            "aclImdb/train/unsup/45279_0.txt\n",
            "aclImdb/train/unsup/45278_0.txt\n",
            "aclImdb/train/unsup/45277_0.txt\n",
            "aclImdb/train/unsup/45276_0.txt\n",
            "aclImdb/train/unsup/45275_0.txt\n",
            "aclImdb/train/unsup/45274_0.txt\n",
            "aclImdb/train/unsup/45273_0.txt\n",
            "aclImdb/train/unsup/45272_0.txt\n",
            "aclImdb/train/unsup/45271_0.txt\n",
            "aclImdb/train/unsup/45270_0.txt\n",
            "aclImdb/train/unsup/45269_0.txt\n",
            "aclImdb/train/unsup/45268_0.txt\n",
            "aclImdb/train/unsup/45267_0.txt\n",
            "aclImdb/train/unsup/45266_0.txt\n",
            "aclImdb/train/unsup/45265_0.txt\n",
            "aclImdb/train/unsup/45264_0.txt\n",
            "aclImdb/train/unsup/45263_0.txt\n",
            "aclImdb/train/unsup/45262_0.txt\n",
            "aclImdb/train/unsup/45261_0.txt\n",
            "aclImdb/train/unsup/45260_0.txt\n",
            "aclImdb/train/unsup/45259_0.txt\n",
            "aclImdb/train/unsup/45258_0.txt\n",
            "aclImdb/train/unsup/45257_0.txt\n",
            "aclImdb/train/unsup/45256_0.txt\n",
            "aclImdb/train/unsup/45255_0.txt\n",
            "aclImdb/train/unsup/45254_0.txt\n",
            "aclImdb/train/unsup/45253_0.txt\n",
            "aclImdb/train/unsup/45252_0.txt\n",
            "aclImdb/train/unsup/45251_0.txt\n",
            "aclImdb/train/unsup/45250_0.txt\n",
            "aclImdb/train/unsup/45249_0.txt\n",
            "aclImdb/train/unsup/45248_0.txt\n",
            "aclImdb/train/unsup/45247_0.txt\n",
            "aclImdb/train/unsup/45246_0.txt\n",
            "aclImdb/train/unsup/45245_0.txt\n",
            "aclImdb/train/unsup/45244_0.txt\n",
            "aclImdb/train/unsup/45243_0.txt\n",
            "aclImdb/train/unsup/45242_0.txt\n",
            "aclImdb/train/unsup/45241_0.txt\n",
            "aclImdb/train/unsup/45240_0.txt\n",
            "aclImdb/train/unsup/45239_0.txt\n",
            "aclImdb/train/unsup/45238_0.txt\n",
            "aclImdb/train/unsup/45237_0.txt\n",
            "aclImdb/train/unsup/45236_0.txt\n",
            "aclImdb/train/unsup/45235_0.txt\n",
            "aclImdb/train/unsup/45234_0.txt\n",
            "aclImdb/train/unsup/45233_0.txt\n",
            "aclImdb/train/unsup/45232_0.txt\n",
            "aclImdb/train/unsup/45231_0.txt\n",
            "aclImdb/train/unsup/45230_0.txt\n",
            "aclImdb/train/unsup/45229_0.txt\n",
            "aclImdb/train/unsup/45228_0.txt\n",
            "aclImdb/train/unsup/45227_0.txt\n",
            "aclImdb/train/unsup/45226_0.txt\n",
            "aclImdb/train/unsup/45225_0.txt\n",
            "aclImdb/train/unsup/45224_0.txt\n",
            "aclImdb/train/unsup/45223_0.txt\n",
            "aclImdb/train/unsup/45222_0.txt\n",
            "aclImdb/train/unsup/45221_0.txt\n",
            "aclImdb/train/unsup/45220_0.txt\n",
            "aclImdb/train/unsup/45219_0.txt\n",
            "aclImdb/train/unsup/45218_0.txt\n",
            "aclImdb/train/unsup/45217_0.txt\n",
            "aclImdb/train/unsup/45216_0.txt\n",
            "aclImdb/train/unsup/45215_0.txt\n",
            "aclImdb/train/unsup/45214_0.txt\n",
            "aclImdb/train/unsup/45213_0.txt\n",
            "aclImdb/train/unsup/45212_0.txt\n",
            "aclImdb/train/unsup/45211_0.txt\n",
            "aclImdb/train/unsup/45210_0.txt\n",
            "aclImdb/train/unsup/45209_0.txt\n",
            "aclImdb/train/unsup/45208_0.txt\n",
            "aclImdb/train/unsup/45207_0.txt\n",
            "aclImdb/train/unsup/45206_0.txt\n",
            "aclImdb/train/unsup/45205_0.txt\n",
            "aclImdb/train/unsup/45204_0.txt\n",
            "aclImdb/train/unsup/45203_0.txt\n",
            "aclImdb/train/unsup/45202_0.txt\n",
            "aclImdb/train/unsup/45201_0.txt\n",
            "aclImdb/train/unsup/45200_0.txt\n",
            "aclImdb/train/unsup/45199_0.txt\n",
            "aclImdb/train/unsup/45198_0.txt\n",
            "aclImdb/train/unsup/45197_0.txt\n",
            "aclImdb/train/unsup/45196_0.txt\n",
            "aclImdb/train/unsup/45195_0.txt\n",
            "aclImdb/train/unsup/45194_0.txt\n",
            "aclImdb/train/unsup/45193_0.txt\n",
            "aclImdb/train/unsup/45192_0.txt\n",
            "aclImdb/train/unsup/45191_0.txt\n",
            "aclImdb/train/unsup/45190_0.txt\n",
            "aclImdb/train/unsup/45189_0.txt\n",
            "aclImdb/train/unsup/45188_0.txt\n",
            "aclImdb/train/unsup/45187_0.txt\n",
            "aclImdb/train/unsup/45186_0.txt\n",
            "aclImdb/train/unsup/45185_0.txt\n",
            "aclImdb/train/unsup/45184_0.txt\n",
            "aclImdb/train/unsup/45439_0.txt\n",
            "aclImdb/train/unsup/45438_0.txt\n",
            "aclImdb/train/unsup/45437_0.txt\n",
            "aclImdb/train/unsup/45436_0.txt\n",
            "aclImdb/train/unsup/45435_0.txt\n",
            "aclImdb/train/unsup/45434_0.txt\n",
            "aclImdb/train/unsup/45433_0.txt\n",
            "aclImdb/train/unsup/45432_0.txt\n",
            "aclImdb/train/unsup/45431_0.txt\n",
            "aclImdb/train/unsup/45430_0.txt\n",
            "aclImdb/train/unsup/45429_0.txt\n",
            "aclImdb/train/unsup/45428_0.txt\n",
            "aclImdb/train/unsup/45427_0.txt\n",
            "aclImdb/train/unsup/45426_0.txt\n",
            "aclImdb/train/unsup/45425_0.txt\n",
            "aclImdb/train/unsup/45424_0.txt\n",
            "aclImdb/train/unsup/45423_0.txt\n",
            "aclImdb/train/unsup/45422_0.txt\n",
            "aclImdb/train/unsup/45421_0.txt\n",
            "aclImdb/train/unsup/45420_0.txt\n",
            "aclImdb/train/unsup/45419_0.txt\n",
            "aclImdb/train/unsup/45418_0.txt\n",
            "aclImdb/train/unsup/45417_0.txt\n",
            "aclImdb/train/unsup/45416_0.txt\n",
            "aclImdb/train/unsup/45415_0.txt\n",
            "aclImdb/train/unsup/45414_0.txt\n",
            "aclImdb/train/unsup/45413_0.txt\n",
            "aclImdb/train/unsup/45412_0.txt\n",
            "aclImdb/train/unsup/45411_0.txt\n",
            "aclImdb/train/unsup/45410_0.txt\n",
            "aclImdb/train/unsup/45409_0.txt\n",
            "aclImdb/train/unsup/45408_0.txt\n",
            "aclImdb/train/unsup/45407_0.txt\n",
            "aclImdb/train/unsup/45406_0.txt\n",
            "aclImdb/train/unsup/45405_0.txt\n",
            "aclImdb/train/unsup/45404_0.txt\n",
            "aclImdb/train/unsup/45403_0.txt\n",
            "aclImdb/train/unsup/45402_0.txt\n",
            "aclImdb/train/unsup/45401_0.txt\n",
            "aclImdb/train/unsup/45400_0.txt\n",
            "aclImdb/train/unsup/45399_0.txt\n",
            "aclImdb/train/unsup/45398_0.txt\n",
            "aclImdb/train/unsup/45397_0.txt\n",
            "aclImdb/train/unsup/45396_0.txt\n",
            "aclImdb/train/unsup/45395_0.txt\n",
            "aclImdb/train/unsup/45394_0.txt\n",
            "aclImdb/train/unsup/45393_0.txt\n",
            "aclImdb/train/unsup/45392_0.txt\n",
            "aclImdb/train/unsup/45391_0.txt\n",
            "aclImdb/train/unsup/45390_0.txt\n",
            "aclImdb/train/unsup/45389_0.txt\n",
            "aclImdb/train/unsup/45388_0.txt\n",
            "aclImdb/train/unsup/45387_0.txt\n",
            "aclImdb/train/unsup/45386_0.txt\n",
            "aclImdb/train/unsup/45385_0.txt\n",
            "aclImdb/train/unsup/45384_0.txt\n",
            "aclImdb/train/unsup/45383_0.txt\n",
            "aclImdb/train/unsup/45382_0.txt\n",
            "aclImdb/train/unsup/45381_0.txt\n",
            "aclImdb/train/unsup/45380_0.txt\n",
            "aclImdb/train/unsup/45379_0.txt\n",
            "aclImdb/train/unsup/45378_0.txt\n",
            "aclImdb/train/unsup/45377_0.txt\n",
            "aclImdb/train/unsup/45376_0.txt\n",
            "aclImdb/train/unsup/45375_0.txt\n",
            "aclImdb/train/unsup/45374_0.txt\n",
            "aclImdb/train/unsup/45373_0.txt\n",
            "aclImdb/train/unsup/45372_0.txt\n",
            "aclImdb/train/unsup/45371_0.txt\n",
            "aclImdb/train/unsup/45370_0.txt\n",
            "aclImdb/train/unsup/45369_0.txt\n",
            "aclImdb/train/unsup/45368_0.txt\n",
            "aclImdb/train/unsup/45367_0.txt\n",
            "aclImdb/train/unsup/45366_0.txt\n",
            "aclImdb/train/unsup/45365_0.txt\n",
            "aclImdb/train/unsup/45364_0.txt\n",
            "aclImdb/train/unsup/45363_0.txt\n",
            "aclImdb/train/unsup/45362_0.txt\n",
            "aclImdb/train/unsup/45361_0.txt\n",
            "aclImdb/train/unsup/45360_0.txt\n",
            "aclImdb/train/unsup/45359_0.txt\n",
            "aclImdb/train/unsup/45358_0.txt\n",
            "aclImdb/train/unsup/45357_0.txt\n",
            "aclImdb/train/unsup/45356_0.txt\n",
            "aclImdb/train/unsup/45355_0.txt\n",
            "aclImdb/train/unsup/45354_0.txt\n",
            "aclImdb/train/unsup/45353_0.txt\n",
            "aclImdb/train/unsup/45352_0.txt\n",
            "aclImdb/train/unsup/45351_0.txt\n",
            "aclImdb/train/unsup/45350_0.txt\n",
            "aclImdb/train/unsup/45349_0.txt\n",
            "aclImdb/train/unsup/45348_0.txt\n",
            "aclImdb/train/unsup/45347_0.txt\n",
            "aclImdb/train/unsup/45346_0.txt\n",
            "aclImdb/train/unsup/45345_0.txt\n",
            "aclImdb/train/unsup/45344_0.txt\n",
            "aclImdb/train/unsup/45343_0.txt\n",
            "aclImdb/train/unsup/45342_0.txt\n",
            "aclImdb/train/unsup/45341_0.txt\n",
            "aclImdb/train/unsup/45340_0.txt\n",
            "aclImdb/train/unsup/45339_0.txt\n",
            "aclImdb/train/unsup/45338_0.txt\n",
            "aclImdb/train/unsup/45337_0.txt\n",
            "aclImdb/train/unsup/45336_0.txt\n",
            "aclImdb/train/unsup/45335_0.txt\n",
            "aclImdb/train/unsup/45334_0.txt\n",
            "aclImdb/train/unsup/45333_0.txt\n",
            "aclImdb/train/unsup/45332_0.txt\n",
            "aclImdb/train/unsup/45331_0.txt\n",
            "aclImdb/train/unsup/45330_0.txt\n",
            "aclImdb/train/unsup/45329_0.txt\n",
            "aclImdb/train/unsup/45328_0.txt\n",
            "aclImdb/train/unsup/45327_0.txt\n",
            "aclImdb/train/unsup/45326_0.txt\n",
            "aclImdb/train/unsup/45325_0.txt\n",
            "aclImdb/train/unsup/45324_0.txt\n",
            "aclImdb/train/unsup/45323_0.txt\n",
            "aclImdb/train/unsup/45322_0.txt\n",
            "aclImdb/train/unsup/45321_0.txt\n",
            "aclImdb/train/unsup/45320_0.txt\n",
            "aclImdb/train/unsup/45319_0.txt\n",
            "aclImdb/train/unsup/45318_0.txt\n",
            "aclImdb/train/unsup/45317_0.txt\n",
            "aclImdb/train/unsup/45316_0.txt\n",
            "aclImdb/train/unsup/45315_0.txt\n",
            "aclImdb/train/unsup/45314_0.txt\n",
            "aclImdb/train/unsup/45313_0.txt\n",
            "aclImdb/train/unsup/45312_0.txt\n",
            "aclImdb/train/unsup/45567_0.txt\n",
            "aclImdb/train/unsup/45566_0.txt\n",
            "aclImdb/train/unsup/45565_0.txt\n",
            "aclImdb/train/unsup/45564_0.txt\n",
            "aclImdb/train/unsup/45563_0.txt\n",
            "aclImdb/train/unsup/45562_0.txt\n",
            "aclImdb/train/unsup/45561_0.txt\n",
            "aclImdb/train/unsup/45560_0.txt\n",
            "aclImdb/train/unsup/45559_0.txt\n",
            "aclImdb/train/unsup/45558_0.txt\n",
            "aclImdb/train/unsup/45557_0.txt\n",
            "aclImdb/train/unsup/45556_0.txt\n",
            "aclImdb/train/unsup/45555_0.txt\n",
            "aclImdb/train/unsup/45554_0.txt\n",
            "aclImdb/train/unsup/45553_0.txt\n",
            "aclImdb/train/unsup/45552_0.txt\n",
            "aclImdb/train/unsup/45551_0.txt\n",
            "aclImdb/train/unsup/45550_0.txt\n",
            "aclImdb/train/unsup/45549_0.txt\n",
            "aclImdb/train/unsup/45548_0.txt\n",
            "aclImdb/train/unsup/45547_0.txt\n",
            "aclImdb/train/unsup/45546_0.txt\n",
            "aclImdb/train/unsup/45545_0.txt\n",
            "aclImdb/train/unsup/45544_0.txt\n",
            "aclImdb/train/unsup/45543_0.txt\n",
            "aclImdb/train/unsup/45542_0.txt\n",
            "aclImdb/train/unsup/45541_0.txt\n",
            "aclImdb/train/unsup/45540_0.txt\n",
            "aclImdb/train/unsup/45539_0.txt\n",
            "aclImdb/train/unsup/45538_0.txt\n",
            "aclImdb/train/unsup/45537_0.txt\n",
            "aclImdb/train/unsup/45536_0.txt\n",
            "aclImdb/train/unsup/45535_0.txt\n",
            "aclImdb/train/unsup/45534_0.txt\n",
            "aclImdb/train/unsup/45533_0.txt\n",
            "aclImdb/train/unsup/45532_0.txt\n",
            "aclImdb/train/unsup/45531_0.txt\n",
            "aclImdb/train/unsup/45530_0.txt\n",
            "aclImdb/train/unsup/45529_0.txt\n",
            "aclImdb/train/unsup/45528_0.txt\n",
            "aclImdb/train/unsup/45527_0.txt\n",
            "aclImdb/train/unsup/45526_0.txt\n",
            "aclImdb/train/unsup/45525_0.txt\n",
            "aclImdb/train/unsup/45524_0.txt\n",
            "aclImdb/train/unsup/45523_0.txt\n",
            "aclImdb/train/unsup/45522_0.txt\n",
            "aclImdb/train/unsup/45521_0.txt\n",
            "aclImdb/train/unsup/45520_0.txt\n",
            "aclImdb/train/unsup/45519_0.txt\n",
            "aclImdb/train/unsup/45518_0.txt\n",
            "aclImdb/train/unsup/45517_0.txt\n",
            "aclImdb/train/unsup/45516_0.txt\n",
            "aclImdb/train/unsup/45515_0.txt\n",
            "aclImdb/train/unsup/45514_0.txt\n",
            "aclImdb/train/unsup/45513_0.txt\n",
            "aclImdb/train/unsup/45512_0.txt\n",
            "aclImdb/train/unsup/45511_0.txt\n",
            "aclImdb/train/unsup/45510_0.txt\n",
            "aclImdb/train/unsup/45509_0.txt\n",
            "aclImdb/train/unsup/45508_0.txt\n",
            "aclImdb/train/unsup/45507_0.txt\n",
            "aclImdb/train/unsup/45506_0.txt\n",
            "aclImdb/train/unsup/45505_0.txt\n",
            "aclImdb/train/unsup/45504_0.txt\n",
            "aclImdb/train/unsup/45503_0.txt\n",
            "aclImdb/train/unsup/45502_0.txt\n",
            "aclImdb/train/unsup/45501_0.txt\n",
            "aclImdb/train/unsup/45500_0.txt\n",
            "aclImdb/train/unsup/45499_0.txt\n",
            "aclImdb/train/unsup/45498_0.txt\n",
            "aclImdb/train/unsup/45497_0.txt\n",
            "aclImdb/train/unsup/45496_0.txt\n",
            "aclImdb/train/unsup/45495_0.txt\n",
            "aclImdb/train/unsup/45494_0.txt\n",
            "aclImdb/train/unsup/45493_0.txt\n",
            "aclImdb/train/unsup/45492_0.txt\n",
            "aclImdb/train/unsup/45491_0.txt\n",
            "aclImdb/train/unsup/45490_0.txt\n",
            "aclImdb/train/unsup/45489_0.txt\n",
            "aclImdb/train/unsup/45488_0.txt\n",
            "aclImdb/train/unsup/45487_0.txt\n",
            "aclImdb/train/unsup/45486_0.txt\n",
            "aclImdb/train/unsup/45485_0.txt\n",
            "aclImdb/train/unsup/45484_0.txt\n",
            "aclImdb/train/unsup/45483_0.txt\n",
            "aclImdb/train/unsup/45482_0.txt\n",
            "aclImdb/train/unsup/45481_0.txt\n",
            "aclImdb/train/unsup/45480_0.txt\n",
            "aclImdb/train/unsup/45479_0.txt\n",
            "aclImdb/train/unsup/45478_0.txt\n",
            "aclImdb/train/unsup/45477_0.txt\n",
            "aclImdb/train/unsup/45476_0.txt\n",
            "aclImdb/train/unsup/45475_0.txt\n",
            "aclImdb/train/unsup/45474_0.txt\n",
            "aclImdb/train/unsup/45473_0.txt\n",
            "aclImdb/train/unsup/45472_0.txt\n",
            "aclImdb/train/unsup/45471_0.txt\n",
            "aclImdb/train/unsup/45470_0.txt\n",
            "aclImdb/train/unsup/45469_0.txt\n",
            "aclImdb/train/unsup/45468_0.txt\n",
            "aclImdb/train/unsup/45467_0.txt\n",
            "aclImdb/train/unsup/45466_0.txt\n",
            "aclImdb/train/unsup/45465_0.txt\n",
            "aclImdb/train/unsup/45464_0.txt\n",
            "aclImdb/train/unsup/45463_0.txt\n",
            "aclImdb/train/unsup/45462_0.txt\n",
            "aclImdb/train/unsup/45461_0.txt\n",
            "aclImdb/train/unsup/45460_0.txt\n",
            "aclImdb/train/unsup/45459_0.txt\n",
            "aclImdb/train/unsup/45458_0.txt\n",
            "aclImdb/train/unsup/45457_0.txt\n",
            "aclImdb/train/unsup/45456_0.txt\n",
            "aclImdb/train/unsup/45455_0.txt\n",
            "aclImdb/train/unsup/45454_0.txt\n",
            "aclImdb/train/unsup/45453_0.txt\n",
            "aclImdb/train/unsup/45452_0.txt\n",
            "aclImdb/train/unsup/45451_0.txt\n",
            "aclImdb/train/unsup/45450_0.txt\n",
            "aclImdb/train/unsup/45449_0.txt\n",
            "aclImdb/train/unsup/45448_0.txt\n",
            "aclImdb/train/unsup/45447_0.txt\n",
            "aclImdb/train/unsup/45446_0.txt\n",
            "aclImdb/train/unsup/45445_0.txt\n",
            "aclImdb/train/unsup/45444_0.txt\n",
            "aclImdb/train/unsup/45443_0.txt\n",
            "aclImdb/train/unsup/45442_0.txt\n",
            "aclImdb/train/unsup/45441_0.txt\n",
            "aclImdb/train/unsup/45440_0.txt\n",
            "aclImdb/train/unsup/45695_0.txt\n",
            "aclImdb/train/unsup/45694_0.txt\n",
            "aclImdb/train/unsup/45693_0.txt\n",
            "aclImdb/train/unsup/45692_0.txt\n",
            "aclImdb/train/unsup/45691_0.txt\n",
            "aclImdb/train/unsup/45690_0.txt\n",
            "aclImdb/train/unsup/45689_0.txt\n",
            "aclImdb/train/unsup/45688_0.txt\n",
            "aclImdb/train/unsup/45687_0.txt\n",
            "aclImdb/train/unsup/45686_0.txt\n",
            "aclImdb/train/unsup/45685_0.txt\n",
            "aclImdb/train/unsup/45684_0.txt\n",
            "aclImdb/train/unsup/45683_0.txt\n",
            "aclImdb/train/unsup/45682_0.txt\n",
            "aclImdb/train/unsup/45681_0.txt\n",
            "aclImdb/train/unsup/45680_0.txt\n",
            "aclImdb/train/unsup/45679_0.txt\n",
            "aclImdb/train/unsup/45678_0.txt\n",
            "aclImdb/train/unsup/45677_0.txt\n",
            "aclImdb/train/unsup/45676_0.txt\n",
            "aclImdb/train/unsup/45675_0.txt\n",
            "aclImdb/train/unsup/45674_0.txt\n",
            "aclImdb/train/unsup/45673_0.txt\n",
            "aclImdb/train/unsup/45672_0.txt\n",
            "aclImdb/train/unsup/45671_0.txt\n",
            "aclImdb/train/unsup/45670_0.txt\n",
            "aclImdb/train/unsup/45669_0.txt\n",
            "aclImdb/train/unsup/45668_0.txt\n",
            "aclImdb/train/unsup/45667_0.txt\n",
            "aclImdb/train/unsup/45666_0.txt\n",
            "aclImdb/train/unsup/45665_0.txt\n",
            "aclImdb/train/unsup/45664_0.txt\n",
            "aclImdb/train/unsup/45663_0.txt\n",
            "aclImdb/train/unsup/45662_0.txt\n",
            "aclImdb/train/unsup/45661_0.txt\n",
            "aclImdb/train/unsup/45660_0.txt\n",
            "aclImdb/train/unsup/45659_0.txt\n",
            "aclImdb/train/unsup/45658_0.txt\n",
            "aclImdb/train/unsup/45657_0.txt\n",
            "aclImdb/train/unsup/45656_0.txt\n",
            "aclImdb/train/unsup/45655_0.txt\n",
            "aclImdb/train/unsup/45654_0.txt\n",
            "aclImdb/train/unsup/45653_0.txt\n",
            "aclImdb/train/unsup/45652_0.txt\n",
            "aclImdb/train/unsup/45651_0.txt\n",
            "aclImdb/train/unsup/45650_0.txt\n",
            "aclImdb/train/unsup/45649_0.txt\n",
            "aclImdb/train/unsup/45648_0.txt\n",
            "aclImdb/train/unsup/45647_0.txt\n",
            "aclImdb/train/unsup/45646_0.txt\n",
            "aclImdb/train/unsup/45645_0.txt\n",
            "aclImdb/train/unsup/45644_0.txt\n",
            "aclImdb/train/unsup/45643_0.txt\n",
            "aclImdb/train/unsup/45642_0.txt\n",
            "aclImdb/train/unsup/45641_0.txt\n",
            "aclImdb/train/unsup/45640_0.txt\n",
            "aclImdb/train/unsup/45639_0.txt\n",
            "aclImdb/train/unsup/45638_0.txt\n",
            "aclImdb/train/unsup/45637_0.txt\n",
            "aclImdb/train/unsup/45636_0.txt\n",
            "aclImdb/train/unsup/45635_0.txt\n",
            "aclImdb/train/unsup/45634_0.txt\n",
            "aclImdb/train/unsup/45633_0.txt\n",
            "aclImdb/train/unsup/45632_0.txt\n",
            "aclImdb/train/unsup/45631_0.txt\n",
            "aclImdb/train/unsup/45630_0.txt\n",
            "aclImdb/train/unsup/45629_0.txt\n",
            "aclImdb/train/unsup/45628_0.txt\n",
            "aclImdb/train/unsup/45627_0.txt\n",
            "aclImdb/train/unsup/45626_0.txt\n",
            "aclImdb/train/unsup/45625_0.txt\n",
            "aclImdb/train/unsup/45624_0.txt\n",
            "aclImdb/train/unsup/45623_0.txt\n",
            "aclImdb/train/unsup/45622_0.txt\n",
            "aclImdb/train/unsup/45621_0.txt\n",
            "aclImdb/train/unsup/45620_0.txt\n",
            "aclImdb/train/unsup/45619_0.txt\n",
            "aclImdb/train/unsup/45618_0.txt\n",
            "aclImdb/train/unsup/45617_0.txt\n",
            "aclImdb/train/unsup/45616_0.txt\n",
            "aclImdb/train/unsup/45615_0.txt\n",
            "aclImdb/train/unsup/45614_0.txt\n",
            "aclImdb/train/unsup/45613_0.txt\n",
            "aclImdb/train/unsup/45612_0.txt\n",
            "aclImdb/train/unsup/45611_0.txt\n",
            "aclImdb/train/unsup/45610_0.txt\n",
            "aclImdb/train/unsup/45609_0.txt\n",
            "aclImdb/train/unsup/45608_0.txt\n",
            "aclImdb/train/unsup/45607_0.txt\n",
            "aclImdb/train/unsup/45606_0.txt\n",
            "aclImdb/train/unsup/45605_0.txt\n",
            "aclImdb/train/unsup/45604_0.txt\n",
            "aclImdb/train/unsup/45603_0.txt\n",
            "aclImdb/train/unsup/45602_0.txt\n",
            "aclImdb/train/unsup/45601_0.txt\n",
            "aclImdb/train/unsup/45600_0.txt\n",
            "aclImdb/train/unsup/45599_0.txt\n",
            "aclImdb/train/unsup/45598_0.txt\n",
            "aclImdb/train/unsup/45597_0.txt\n",
            "aclImdb/train/unsup/45596_0.txt\n",
            "aclImdb/train/unsup/45595_0.txt\n",
            "aclImdb/train/unsup/45594_0.txt\n",
            "aclImdb/train/unsup/45593_0.txt\n",
            "aclImdb/train/unsup/45592_0.txt\n",
            "aclImdb/train/unsup/45591_0.txt\n",
            "aclImdb/train/unsup/45590_0.txt\n",
            "aclImdb/train/unsup/45589_0.txt\n",
            "aclImdb/train/unsup/45588_0.txt\n",
            "aclImdb/train/unsup/45587_0.txt\n",
            "aclImdb/train/unsup/45586_0.txt\n",
            "aclImdb/train/unsup/45585_0.txt\n",
            "aclImdb/train/unsup/45584_0.txt\n",
            "aclImdb/train/unsup/45583_0.txt\n",
            "aclImdb/train/unsup/45582_0.txt\n",
            "aclImdb/train/unsup/45581_0.txt\n",
            "aclImdb/train/unsup/45580_0.txt\n",
            "aclImdb/train/unsup/45579_0.txt\n",
            "aclImdb/train/unsup/45578_0.txt\n",
            "aclImdb/train/unsup/45577_0.txt\n",
            "aclImdb/train/unsup/45576_0.txt\n",
            "aclImdb/train/unsup/45575_0.txt\n",
            "aclImdb/train/unsup/45574_0.txt\n",
            "aclImdb/train/unsup/45573_0.txt\n",
            "aclImdb/train/unsup/45572_0.txt\n",
            "aclImdb/train/unsup/45571_0.txt\n",
            "aclImdb/train/unsup/45570_0.txt\n",
            "aclImdb/train/unsup/45569_0.txt\n",
            "aclImdb/train/unsup/45568_0.txt\n",
            "aclImdb/train/unsup/45823_0.txt\n",
            "aclImdb/train/unsup/45822_0.txt\n",
            "aclImdb/train/unsup/45821_0.txt\n",
            "aclImdb/train/unsup/45820_0.txt\n",
            "aclImdb/train/unsup/45819_0.txt\n",
            "aclImdb/train/unsup/45818_0.txt\n",
            "aclImdb/train/unsup/45817_0.txt\n",
            "aclImdb/train/unsup/45816_0.txt\n",
            "aclImdb/train/unsup/45815_0.txt\n",
            "aclImdb/train/unsup/45814_0.txt\n",
            "aclImdb/train/unsup/45813_0.txt\n",
            "aclImdb/train/unsup/45812_0.txt\n",
            "aclImdb/train/unsup/45811_0.txt\n",
            "aclImdb/train/unsup/45810_0.txt\n",
            "aclImdb/train/unsup/45809_0.txt\n",
            "aclImdb/train/unsup/45808_0.txt\n",
            "aclImdb/train/unsup/45807_0.txt\n",
            "aclImdb/train/unsup/45806_0.txt\n",
            "aclImdb/train/unsup/45805_0.txt\n",
            "aclImdb/train/unsup/45804_0.txt\n",
            "aclImdb/train/unsup/45803_0.txt\n",
            "aclImdb/train/unsup/45802_0.txt\n",
            "aclImdb/train/unsup/45801_0.txt\n",
            "aclImdb/train/unsup/45800_0.txt\n",
            "aclImdb/train/unsup/45799_0.txt\n",
            "aclImdb/train/unsup/45798_0.txt\n",
            "aclImdb/train/unsup/45797_0.txt\n",
            "aclImdb/train/unsup/45796_0.txt\n",
            "aclImdb/train/unsup/45795_0.txt\n",
            "aclImdb/train/unsup/45794_0.txt\n",
            "aclImdb/train/unsup/45793_0.txt\n",
            "aclImdb/train/unsup/45792_0.txt\n",
            "aclImdb/train/unsup/45791_0.txt\n",
            "aclImdb/train/unsup/45790_0.txt\n",
            "aclImdb/train/unsup/45789_0.txt\n",
            "aclImdb/train/unsup/45788_0.txt\n",
            "aclImdb/train/unsup/45787_0.txt\n",
            "aclImdb/train/unsup/45786_0.txt\n",
            "aclImdb/train/unsup/45785_0.txt\n",
            "aclImdb/train/unsup/45784_0.txt\n",
            "aclImdb/train/unsup/45783_0.txt\n",
            "aclImdb/train/unsup/45782_0.txt\n",
            "aclImdb/train/unsup/45781_0.txt\n",
            "aclImdb/train/unsup/45780_0.txt\n",
            "aclImdb/train/unsup/45779_0.txt\n",
            "aclImdb/train/unsup/45778_0.txt\n",
            "aclImdb/train/unsup/45777_0.txt\n",
            "aclImdb/train/unsup/45776_0.txt\n",
            "aclImdb/train/unsup/45775_0.txt\n",
            "aclImdb/train/unsup/45774_0.txt\n",
            "aclImdb/train/unsup/45773_0.txt\n",
            "aclImdb/train/unsup/45772_0.txt\n",
            "aclImdb/train/unsup/45771_0.txt\n",
            "aclImdb/train/unsup/45770_0.txt\n",
            "aclImdb/train/unsup/45769_0.txt\n",
            "aclImdb/train/unsup/45768_0.txt\n",
            "aclImdb/train/unsup/45767_0.txt\n",
            "aclImdb/train/unsup/45766_0.txt\n",
            "aclImdb/train/unsup/45765_0.txt\n",
            "aclImdb/train/unsup/45764_0.txt\n",
            "aclImdb/train/unsup/45763_0.txt\n",
            "aclImdb/train/unsup/45762_0.txt\n",
            "aclImdb/train/unsup/45761_0.txt\n",
            "aclImdb/train/unsup/45760_0.txt\n",
            "aclImdb/train/unsup/45759_0.txt\n",
            "aclImdb/train/unsup/45758_0.txt\n",
            "aclImdb/train/unsup/45757_0.txt\n",
            "aclImdb/train/unsup/45756_0.txt\n",
            "aclImdb/train/unsup/45755_0.txt\n",
            "aclImdb/train/unsup/45754_0.txt\n",
            "aclImdb/train/unsup/45753_0.txt\n",
            "aclImdb/train/unsup/45752_0.txt\n",
            "aclImdb/train/unsup/45751_0.txt\n",
            "aclImdb/train/unsup/45750_0.txt\n",
            "aclImdb/train/unsup/45749_0.txt\n",
            "aclImdb/train/unsup/45748_0.txt\n",
            "aclImdb/train/unsup/45747_0.txt\n",
            "aclImdb/train/unsup/45746_0.txt\n",
            "aclImdb/train/unsup/45745_0.txt\n",
            "aclImdb/train/unsup/45744_0.txt\n",
            "aclImdb/train/unsup/45743_0.txt\n",
            "aclImdb/train/unsup/45742_0.txt\n",
            "aclImdb/train/unsup/45741_0.txt\n",
            "aclImdb/train/unsup/45740_0.txt\n",
            "aclImdb/train/unsup/45739_0.txt\n",
            "aclImdb/train/unsup/45738_0.txt\n",
            "aclImdb/train/unsup/45737_0.txt\n",
            "aclImdb/train/unsup/45736_0.txt\n",
            "aclImdb/train/unsup/45735_0.txt\n",
            "aclImdb/train/unsup/45734_0.txt\n",
            "aclImdb/train/unsup/45733_0.txt\n",
            "aclImdb/train/unsup/45732_0.txt\n",
            "aclImdb/train/unsup/45731_0.txt\n",
            "aclImdb/train/unsup/45730_0.txt\n",
            "aclImdb/train/unsup/45729_0.txt\n",
            "aclImdb/train/unsup/45728_0.txt\n",
            "aclImdb/train/unsup/45727_0.txt\n",
            "aclImdb/train/unsup/45726_0.txt\n",
            "aclImdb/train/unsup/45725_0.txt\n",
            "aclImdb/train/unsup/45724_0.txt\n",
            "aclImdb/train/unsup/45723_0.txt\n",
            "aclImdb/train/unsup/45722_0.txt\n",
            "aclImdb/train/unsup/45721_0.txt\n",
            "aclImdb/train/unsup/45720_0.txt\n",
            "aclImdb/train/unsup/45719_0.txt\n",
            "aclImdb/train/unsup/45718_0.txt\n",
            "aclImdb/train/unsup/45717_0.txt\n",
            "aclImdb/train/unsup/45716_0.txt\n",
            "aclImdb/train/unsup/45715_0.txt\n",
            "aclImdb/train/unsup/45714_0.txt\n",
            "aclImdb/train/unsup/45713_0.txt\n",
            "aclImdb/train/unsup/45712_0.txt\n",
            "aclImdb/train/unsup/45711_0.txt\n",
            "aclImdb/train/unsup/45710_0.txt\n",
            "aclImdb/train/unsup/45709_0.txt\n",
            "aclImdb/train/unsup/45708_0.txt\n",
            "aclImdb/train/unsup/45707_0.txt\n",
            "aclImdb/train/unsup/45706_0.txt\n",
            "aclImdb/train/unsup/45705_0.txt\n",
            "aclImdb/train/unsup/45704_0.txt\n",
            "aclImdb/train/unsup/45703_0.txt\n",
            "aclImdb/train/unsup/45702_0.txt\n",
            "aclImdb/train/unsup/45701_0.txt\n",
            "aclImdb/train/unsup/45700_0.txt\n",
            "aclImdb/train/unsup/45699_0.txt\n",
            "aclImdb/train/unsup/45698_0.txt\n",
            "aclImdb/train/unsup/45697_0.txt\n",
            "aclImdb/train/unsup/45696_0.txt\n",
            "aclImdb/train/unsup/45951_0.txt\n",
            "aclImdb/train/unsup/45950_0.txt\n",
            "aclImdb/train/unsup/45949_0.txt\n",
            "aclImdb/train/unsup/45948_0.txt\n",
            "aclImdb/train/unsup/45947_0.txt\n",
            "aclImdb/train/unsup/45946_0.txt\n",
            "aclImdb/train/unsup/45945_0.txt\n",
            "aclImdb/train/unsup/45944_0.txt\n",
            "aclImdb/train/unsup/45943_0.txt\n",
            "aclImdb/train/unsup/45942_0.txt\n",
            "aclImdb/train/unsup/45941_0.txt\n",
            "aclImdb/train/unsup/45940_0.txt\n",
            "aclImdb/train/unsup/45939_0.txt\n",
            "aclImdb/train/unsup/45938_0.txt\n",
            "aclImdb/train/unsup/45937_0.txt\n",
            "aclImdb/train/unsup/45936_0.txt\n",
            "aclImdb/train/unsup/45935_0.txt\n",
            "aclImdb/train/unsup/45934_0.txt\n",
            "aclImdb/train/unsup/45933_0.txt\n",
            "aclImdb/train/unsup/45932_0.txt\n",
            "aclImdb/train/unsup/45931_0.txt\n",
            "aclImdb/train/unsup/45930_0.txt\n",
            "aclImdb/train/unsup/45929_0.txt\n",
            "aclImdb/train/unsup/45928_0.txt\n",
            "aclImdb/train/unsup/45927_0.txt\n",
            "aclImdb/train/unsup/45926_0.txt\n",
            "aclImdb/train/unsup/45925_0.txt\n",
            "aclImdb/train/unsup/45924_0.txt\n",
            "aclImdb/train/unsup/45923_0.txt\n",
            "aclImdb/train/unsup/45922_0.txt\n",
            "aclImdb/train/unsup/45921_0.txt\n",
            "aclImdb/train/unsup/45920_0.txt\n",
            "aclImdb/train/unsup/45919_0.txt\n",
            "aclImdb/train/unsup/45918_0.txt\n",
            "aclImdb/train/unsup/45917_0.txt\n",
            "aclImdb/train/unsup/45916_0.txt\n",
            "aclImdb/train/unsup/45915_0.txt\n",
            "aclImdb/train/unsup/45914_0.txt\n",
            "aclImdb/train/unsup/45913_0.txt\n",
            "aclImdb/train/unsup/45912_0.txt\n",
            "aclImdb/train/unsup/45911_0.txt\n",
            "aclImdb/train/unsup/45910_0.txt\n",
            "aclImdb/train/unsup/45909_0.txt\n",
            "aclImdb/train/unsup/45908_0.txt\n",
            "aclImdb/train/unsup/45907_0.txt\n",
            "aclImdb/train/unsup/45906_0.txt\n",
            "aclImdb/train/unsup/45905_0.txt\n",
            "aclImdb/train/unsup/45904_0.txt\n",
            "aclImdb/train/unsup/45903_0.txt\n",
            "aclImdb/train/unsup/45902_0.txt\n",
            "aclImdb/train/unsup/45901_0.txt\n",
            "aclImdb/train/unsup/45900_0.txt\n",
            "aclImdb/train/unsup/45899_0.txt\n",
            "aclImdb/train/unsup/45898_0.txt\n",
            "aclImdb/train/unsup/45897_0.txt\n",
            "aclImdb/train/unsup/45896_0.txt\n",
            "aclImdb/train/unsup/45895_0.txt\n",
            "aclImdb/train/unsup/45894_0.txt\n",
            "aclImdb/train/unsup/45893_0.txt\n",
            "aclImdb/train/unsup/45892_0.txt\n",
            "aclImdb/train/unsup/45891_0.txt\n",
            "aclImdb/train/unsup/45890_0.txt\n",
            "aclImdb/train/unsup/45889_0.txt\n",
            "aclImdb/train/unsup/45888_0.txt\n",
            "aclImdb/train/unsup/45887_0.txt\n",
            "aclImdb/train/unsup/45886_0.txt\n",
            "aclImdb/train/unsup/45885_0.txt\n",
            "aclImdb/train/unsup/45884_0.txt\n",
            "aclImdb/train/unsup/45883_0.txt\n",
            "aclImdb/train/unsup/45882_0.txt\n",
            "aclImdb/train/unsup/45881_0.txt\n",
            "aclImdb/train/unsup/45880_0.txt\n",
            "aclImdb/train/unsup/45879_0.txt\n",
            "aclImdb/train/unsup/45878_0.txt\n",
            "aclImdb/train/unsup/45877_0.txt\n",
            "aclImdb/train/unsup/45876_0.txt\n",
            "aclImdb/train/unsup/45875_0.txt\n",
            "aclImdb/train/unsup/45874_0.txt\n",
            "aclImdb/train/unsup/45873_0.txt\n",
            "aclImdb/train/unsup/45872_0.txt\n",
            "aclImdb/train/unsup/45871_0.txt\n",
            "aclImdb/train/unsup/45870_0.txt\n",
            "aclImdb/train/unsup/45869_0.txt\n",
            "aclImdb/train/unsup/45868_0.txt\n",
            "aclImdb/train/unsup/45867_0.txt\n",
            "aclImdb/train/unsup/45866_0.txt\n",
            "aclImdb/train/unsup/45865_0.txt\n",
            "aclImdb/train/unsup/45864_0.txt\n",
            "aclImdb/train/unsup/45863_0.txt\n",
            "aclImdb/train/unsup/45862_0.txt\n",
            "aclImdb/train/unsup/45861_0.txt\n",
            "aclImdb/train/unsup/45860_0.txt\n",
            "aclImdb/train/unsup/45859_0.txt\n",
            "aclImdb/train/unsup/45858_0.txt\n",
            "aclImdb/train/unsup/45857_0.txt\n",
            "aclImdb/train/unsup/45856_0.txt\n",
            "aclImdb/train/unsup/45855_0.txt\n",
            "aclImdb/train/unsup/45854_0.txt\n",
            "aclImdb/train/unsup/45853_0.txt\n",
            "aclImdb/train/unsup/45852_0.txt\n",
            "aclImdb/train/unsup/45851_0.txt\n",
            "aclImdb/train/unsup/45850_0.txt\n",
            "aclImdb/train/unsup/45849_0.txt\n",
            "aclImdb/train/unsup/45848_0.txt\n",
            "aclImdb/train/unsup/45847_0.txt\n",
            "aclImdb/train/unsup/45846_0.txt\n",
            "aclImdb/train/unsup/45845_0.txt\n",
            "aclImdb/train/unsup/45844_0.txt\n",
            "aclImdb/train/unsup/45843_0.txt\n",
            "aclImdb/train/unsup/45842_0.txt\n",
            "aclImdb/train/unsup/45841_0.txt\n",
            "aclImdb/train/unsup/45840_0.txt\n",
            "aclImdb/train/unsup/45839_0.txt\n",
            "aclImdb/train/unsup/45838_0.txt\n",
            "aclImdb/train/unsup/45837_0.txt\n",
            "aclImdb/train/unsup/45836_0.txt\n",
            "aclImdb/train/unsup/45835_0.txt\n",
            "aclImdb/train/unsup/45834_0.txt\n",
            "aclImdb/train/unsup/45833_0.txt\n",
            "aclImdb/train/unsup/45832_0.txt\n",
            "aclImdb/train/unsup/45831_0.txt\n",
            "aclImdb/train/unsup/45830_0.txt\n",
            "aclImdb/train/unsup/45829_0.txt\n",
            "aclImdb/train/unsup/45828_0.txt\n",
            "aclImdb/train/unsup/45827_0.txt\n",
            "aclImdb/train/unsup/45826_0.txt\n",
            "aclImdb/train/unsup/45825_0.txt\n",
            "aclImdb/train/unsup/45824_0.txt\n",
            "aclImdb/train/unsup/46079_0.txt\n",
            "aclImdb/train/unsup/46078_0.txt\n",
            "aclImdb/train/unsup/46077_0.txt\n",
            "aclImdb/train/unsup/46076_0.txt\n",
            "aclImdb/train/unsup/46075_0.txt\n",
            "aclImdb/train/unsup/46074_0.txt\n",
            "aclImdb/train/unsup/46073_0.txt\n",
            "aclImdb/train/unsup/46072_0.txt\n",
            "aclImdb/train/unsup/46071_0.txt\n",
            "aclImdb/train/unsup/46070_0.txt\n",
            "aclImdb/train/unsup/46069_0.txt\n",
            "aclImdb/train/unsup/46068_0.txt\n",
            "aclImdb/train/unsup/46067_0.txt\n",
            "aclImdb/train/unsup/46066_0.txt\n",
            "aclImdb/train/unsup/46065_0.txt\n",
            "aclImdb/train/unsup/46064_0.txt\n",
            "aclImdb/train/unsup/46063_0.txt\n",
            "aclImdb/train/unsup/46062_0.txt\n",
            "aclImdb/train/unsup/46061_0.txt\n",
            "aclImdb/train/unsup/46060_0.txt\n",
            "aclImdb/train/unsup/46059_0.txt\n",
            "aclImdb/train/unsup/46058_0.txt\n",
            "aclImdb/train/unsup/46057_0.txt\n",
            "aclImdb/train/unsup/46056_0.txt\n",
            "aclImdb/train/unsup/46055_0.txt\n",
            "aclImdb/train/unsup/46054_0.txt\n",
            "aclImdb/train/unsup/46053_0.txt\n",
            "aclImdb/train/unsup/46052_0.txt\n",
            "aclImdb/train/unsup/46051_0.txt\n",
            "aclImdb/train/unsup/46050_0.txt\n",
            "aclImdb/train/unsup/46049_0.txt\n",
            "aclImdb/train/unsup/46048_0.txt\n",
            "aclImdb/train/unsup/46047_0.txt\n",
            "aclImdb/train/unsup/46046_0.txt\n",
            "aclImdb/train/unsup/46045_0.txt\n",
            "aclImdb/train/unsup/46044_0.txt\n",
            "aclImdb/train/unsup/46043_0.txt\n",
            "aclImdb/train/unsup/46042_0.txt\n",
            "aclImdb/train/unsup/46041_0.txt\n",
            "aclImdb/train/unsup/46040_0.txt\n",
            "aclImdb/train/unsup/46039_0.txt\n",
            "aclImdb/train/unsup/46038_0.txt\n",
            "aclImdb/train/unsup/46037_0.txt\n",
            "aclImdb/train/unsup/46036_0.txt\n",
            "aclImdb/train/unsup/46035_0.txt\n",
            "aclImdb/train/unsup/46034_0.txt\n",
            "aclImdb/train/unsup/46033_0.txt\n",
            "aclImdb/train/unsup/46032_0.txt\n",
            "aclImdb/train/unsup/46031_0.txt\n",
            "aclImdb/train/unsup/46030_0.txt\n",
            "aclImdb/train/unsup/46029_0.txt\n",
            "aclImdb/train/unsup/46028_0.txt\n",
            "aclImdb/train/unsup/46027_0.txt\n",
            "aclImdb/train/unsup/46026_0.txt\n",
            "aclImdb/train/unsup/46025_0.txt\n",
            "aclImdb/train/unsup/46024_0.txt\n",
            "aclImdb/train/unsup/46023_0.txt\n",
            "aclImdb/train/unsup/46022_0.txt\n",
            "aclImdb/train/unsup/46021_0.txt\n",
            "aclImdb/train/unsup/46020_0.txt\n",
            "aclImdb/train/unsup/46019_0.txt\n",
            "aclImdb/train/unsup/46018_0.txt\n",
            "aclImdb/train/unsup/46017_0.txt\n",
            "aclImdb/train/unsup/46016_0.txt\n",
            "aclImdb/train/unsup/46015_0.txt\n",
            "aclImdb/train/unsup/46014_0.txt\n",
            "aclImdb/train/unsup/46013_0.txt\n",
            "aclImdb/train/unsup/46012_0.txt\n",
            "aclImdb/train/unsup/46011_0.txt\n",
            "aclImdb/train/unsup/46010_0.txt\n",
            "aclImdb/train/unsup/46009_0.txt\n",
            "aclImdb/train/unsup/46008_0.txt\n",
            "aclImdb/train/unsup/46007_0.txt\n",
            "aclImdb/train/unsup/46006_0.txt\n",
            "aclImdb/train/unsup/46005_0.txt\n",
            "aclImdb/train/unsup/46004_0.txt\n",
            "aclImdb/train/unsup/46003_0.txt\n",
            "aclImdb/train/unsup/46002_0.txt\n",
            "aclImdb/train/unsup/46001_0.txt\n",
            "aclImdb/train/unsup/46000_0.txt\n",
            "aclImdb/train/unsup/45999_0.txt\n",
            "aclImdb/train/unsup/45998_0.txt\n",
            "aclImdb/train/unsup/45997_0.txt\n",
            "aclImdb/train/unsup/45996_0.txt\n",
            "aclImdb/train/unsup/45995_0.txt\n",
            "aclImdb/train/unsup/45994_0.txt\n",
            "aclImdb/train/unsup/45993_0.txt\n",
            "aclImdb/train/unsup/45992_0.txt\n",
            "aclImdb/train/unsup/45991_0.txt\n",
            "aclImdb/train/unsup/45990_0.txt\n",
            "aclImdb/train/unsup/45989_0.txt\n",
            "aclImdb/train/unsup/45988_0.txt\n",
            "aclImdb/train/unsup/45987_0.txt\n",
            "aclImdb/train/unsup/45986_0.txt\n",
            "aclImdb/train/unsup/45985_0.txt\n",
            "aclImdb/train/unsup/45984_0.txt\n",
            "aclImdb/train/unsup/45983_0.txt\n",
            "aclImdb/train/unsup/45982_0.txt\n",
            "aclImdb/train/unsup/45981_0.txt\n",
            "aclImdb/train/unsup/45980_0.txt\n",
            "aclImdb/train/unsup/45979_0.txt\n",
            "aclImdb/train/unsup/45978_0.txt\n",
            "aclImdb/train/unsup/45977_0.txt\n",
            "aclImdb/train/unsup/45976_0.txt\n",
            "aclImdb/train/unsup/45975_0.txt\n",
            "aclImdb/train/unsup/45974_0.txt\n",
            "aclImdb/train/unsup/45973_0.txt\n",
            "aclImdb/train/unsup/45972_0.txt\n",
            "aclImdb/train/unsup/45971_0.txt\n",
            "aclImdb/train/unsup/45970_0.txt\n",
            "aclImdb/train/unsup/45969_0.txt\n",
            "aclImdb/train/unsup/45968_0.txt\n",
            "aclImdb/train/unsup/45967_0.txt\n",
            "aclImdb/train/unsup/45966_0.txt\n",
            "aclImdb/train/unsup/45965_0.txt\n",
            "aclImdb/train/unsup/45964_0.txt\n",
            "aclImdb/train/unsup/45963_0.txt\n",
            "aclImdb/train/unsup/45962_0.txt\n",
            "aclImdb/train/unsup/45961_0.txt\n",
            "aclImdb/train/unsup/45960_0.txt\n",
            "aclImdb/train/unsup/45959_0.txt\n",
            "aclImdb/train/unsup/45958_0.txt\n",
            "aclImdb/train/unsup/45957_0.txt\n",
            "aclImdb/train/unsup/45956_0.txt\n",
            "aclImdb/train/unsup/45955_0.txt\n",
            "aclImdb/train/unsup/45954_0.txt\n",
            "aclImdb/train/unsup/45953_0.txt\n",
            "aclImdb/train/unsup/45952_0.txt\n",
            "aclImdb/train/unsup/46207_0.txt\n",
            "aclImdb/train/unsup/46206_0.txt\n",
            "aclImdb/train/unsup/46205_0.txt\n",
            "aclImdb/train/unsup/46204_0.txt\n",
            "aclImdb/train/unsup/46203_0.txt\n",
            "aclImdb/train/unsup/46202_0.txt\n",
            "aclImdb/train/unsup/46201_0.txt\n",
            "aclImdb/train/unsup/46200_0.txt\n",
            "aclImdb/train/unsup/46199_0.txt\n",
            "aclImdb/train/unsup/46198_0.txt\n",
            "aclImdb/train/unsup/46197_0.txt\n",
            "aclImdb/train/unsup/46196_0.txt\n",
            "aclImdb/train/unsup/46195_0.txt\n",
            "aclImdb/train/unsup/46194_0.txt\n",
            "aclImdb/train/unsup/46193_0.txt\n",
            "aclImdb/train/unsup/46192_0.txt\n",
            "aclImdb/train/unsup/46191_0.txt\n",
            "aclImdb/train/unsup/46190_0.txt\n",
            "aclImdb/train/unsup/46189_0.txt\n",
            "aclImdb/train/unsup/46188_0.txt\n",
            "aclImdb/train/unsup/46187_0.txt\n",
            "aclImdb/train/unsup/46186_0.txt\n",
            "aclImdb/train/unsup/46185_0.txt\n",
            "aclImdb/train/unsup/46184_0.txt\n",
            "aclImdb/train/unsup/46183_0.txt\n",
            "aclImdb/train/unsup/46182_0.txt\n",
            "aclImdb/train/unsup/46181_0.txt\n",
            "aclImdb/train/unsup/46180_0.txt\n",
            "aclImdb/train/unsup/46179_0.txt\n",
            "aclImdb/train/unsup/46178_0.txt\n",
            "aclImdb/train/unsup/46177_0.txt\n",
            "aclImdb/train/unsup/46176_0.txt\n",
            "aclImdb/train/unsup/46175_0.txt\n",
            "aclImdb/train/unsup/46174_0.txt\n",
            "aclImdb/train/unsup/46173_0.txt\n",
            "aclImdb/train/unsup/46172_0.txt\n",
            "aclImdb/train/unsup/46171_0.txt\n",
            "aclImdb/train/unsup/46170_0.txt\n",
            "aclImdb/train/unsup/46169_0.txt\n",
            "aclImdb/train/unsup/46168_0.txt\n",
            "aclImdb/train/unsup/46167_0.txt\n",
            "aclImdb/train/unsup/46166_0.txt\n",
            "aclImdb/train/unsup/46165_0.txt\n",
            "aclImdb/train/unsup/46164_0.txt\n",
            "aclImdb/train/unsup/46163_0.txt\n",
            "aclImdb/train/unsup/46162_0.txt\n",
            "aclImdb/train/unsup/46161_0.txt\n",
            "aclImdb/train/unsup/46160_0.txt\n",
            "aclImdb/train/unsup/46159_0.txt\n",
            "aclImdb/train/unsup/46158_0.txt\n",
            "aclImdb/train/unsup/46157_0.txt\n",
            "aclImdb/train/unsup/46156_0.txt\n",
            "aclImdb/train/unsup/46155_0.txt\n",
            "aclImdb/train/unsup/46154_0.txt\n",
            "aclImdb/train/unsup/46153_0.txt\n",
            "aclImdb/train/unsup/46152_0.txt\n",
            "aclImdb/train/unsup/46151_0.txt\n",
            "aclImdb/train/unsup/46150_0.txt\n",
            "aclImdb/train/unsup/46149_0.txt\n",
            "aclImdb/train/unsup/46148_0.txt\n",
            "aclImdb/train/unsup/46147_0.txt\n",
            "aclImdb/train/unsup/46146_0.txt\n",
            "aclImdb/train/unsup/46145_0.txt\n",
            "aclImdb/train/unsup/46144_0.txt\n",
            "aclImdb/train/unsup/46143_0.txt\n",
            "aclImdb/train/unsup/46142_0.txt\n",
            "aclImdb/train/unsup/46141_0.txt\n",
            "aclImdb/train/unsup/46140_0.txt\n",
            "aclImdb/train/unsup/46139_0.txt\n",
            "aclImdb/train/unsup/46138_0.txt\n",
            "aclImdb/train/unsup/46137_0.txt\n",
            "aclImdb/train/unsup/46136_0.txt\n",
            "aclImdb/train/unsup/46135_0.txt\n",
            "aclImdb/train/unsup/46134_0.txt\n",
            "aclImdb/train/unsup/46133_0.txt\n",
            "aclImdb/train/unsup/46132_0.txt\n",
            "aclImdb/train/unsup/46131_0.txt\n",
            "aclImdb/train/unsup/46130_0.txt\n",
            "aclImdb/train/unsup/46129_0.txt\n",
            "aclImdb/train/unsup/46128_0.txt\n",
            "aclImdb/train/unsup/46127_0.txt\n",
            "aclImdb/train/unsup/46126_0.txt\n",
            "aclImdb/train/unsup/46125_0.txt\n",
            "aclImdb/train/unsup/46124_0.txt\n",
            "aclImdb/train/unsup/46123_0.txt\n",
            "aclImdb/train/unsup/46122_0.txt\n",
            "aclImdb/train/unsup/46121_0.txt\n",
            "aclImdb/train/unsup/46120_0.txt\n",
            "aclImdb/train/unsup/46119_0.txt\n",
            "aclImdb/train/unsup/46118_0.txt\n",
            "aclImdb/train/unsup/46117_0.txt\n",
            "aclImdb/train/unsup/46116_0.txt\n",
            "aclImdb/train/unsup/46115_0.txt\n",
            "aclImdb/train/unsup/46114_0.txt\n",
            "aclImdb/train/unsup/46113_0.txt\n",
            "aclImdb/train/unsup/46112_0.txt\n",
            "aclImdb/train/unsup/46111_0.txt\n",
            "aclImdb/train/unsup/46110_0.txt\n",
            "aclImdb/train/unsup/46109_0.txt\n",
            "aclImdb/train/unsup/46108_0.txt\n",
            "aclImdb/train/unsup/46107_0.txt\n",
            "aclImdb/train/unsup/46106_0.txt\n",
            "aclImdb/train/unsup/46105_0.txt\n",
            "aclImdb/train/unsup/46104_0.txt\n",
            "aclImdb/train/unsup/46103_0.txt\n",
            "aclImdb/train/unsup/46102_0.txt\n",
            "aclImdb/train/unsup/46101_0.txt\n",
            "aclImdb/train/unsup/46100_0.txt\n",
            "aclImdb/train/unsup/46099_0.txt\n",
            "aclImdb/train/unsup/46098_0.txt\n",
            "aclImdb/train/unsup/46097_0.txt\n",
            "aclImdb/train/unsup/46096_0.txt\n",
            "aclImdb/train/unsup/46095_0.txt\n",
            "aclImdb/train/unsup/46094_0.txt\n",
            "aclImdb/train/unsup/46093_0.txt\n",
            "aclImdb/train/unsup/46092_0.txt\n",
            "aclImdb/train/unsup/46091_0.txt\n",
            "aclImdb/train/unsup/46090_0.txt\n",
            "aclImdb/train/unsup/46089_0.txt\n",
            "aclImdb/train/unsup/46088_0.txt\n",
            "aclImdb/train/unsup/46087_0.txt\n",
            "aclImdb/train/unsup/46086_0.txt\n",
            "aclImdb/train/unsup/46085_0.txt\n",
            "aclImdb/train/unsup/46084_0.txt\n",
            "aclImdb/train/unsup/46083_0.txt\n",
            "aclImdb/train/unsup/46082_0.txt\n",
            "aclImdb/train/unsup/46081_0.txt\n",
            "aclImdb/train/unsup/46080_0.txt\n",
            "aclImdb/train/unsup/46335_0.txt\n",
            "aclImdb/train/unsup/46334_0.txt\n",
            "aclImdb/train/unsup/46333_0.txt\n",
            "aclImdb/train/unsup/46332_0.txt\n",
            "aclImdb/train/unsup/46331_0.txt\n",
            "aclImdb/train/unsup/46330_0.txt\n",
            "aclImdb/train/unsup/46329_0.txt\n",
            "aclImdb/train/unsup/46328_0.txt\n",
            "aclImdb/train/unsup/46327_0.txt\n",
            "aclImdb/train/unsup/46326_0.txt\n",
            "aclImdb/train/unsup/46325_0.txt\n",
            "aclImdb/train/unsup/46324_0.txt\n",
            "aclImdb/train/unsup/46323_0.txt\n",
            "aclImdb/train/unsup/46322_0.txt\n",
            "aclImdb/train/unsup/46321_0.txt\n",
            "aclImdb/train/unsup/46320_0.txt\n",
            "aclImdb/train/unsup/46319_0.txt\n",
            "aclImdb/train/unsup/46318_0.txt\n",
            "aclImdb/train/unsup/46317_0.txt\n",
            "aclImdb/train/unsup/46316_0.txt\n",
            "aclImdb/train/unsup/46315_0.txt\n",
            "aclImdb/train/unsup/46314_0.txt\n",
            "aclImdb/train/unsup/46313_0.txt\n",
            "aclImdb/train/unsup/46312_0.txt\n",
            "aclImdb/train/unsup/46311_0.txt\n",
            "aclImdb/train/unsup/46310_0.txt\n",
            "aclImdb/train/unsup/46309_0.txt\n",
            "aclImdb/train/unsup/46308_0.txt\n",
            "aclImdb/train/unsup/46307_0.txt\n",
            "aclImdb/train/unsup/46306_0.txt\n",
            "aclImdb/train/unsup/46305_0.txt\n",
            "aclImdb/train/unsup/46304_0.txt\n",
            "aclImdb/train/unsup/46303_0.txt\n",
            "aclImdb/train/unsup/46302_0.txt\n",
            "aclImdb/train/unsup/46301_0.txt\n",
            "aclImdb/train/unsup/46300_0.txt\n",
            "aclImdb/train/unsup/46299_0.txt\n",
            "aclImdb/train/unsup/46298_0.txt\n",
            "aclImdb/train/unsup/46297_0.txt\n",
            "aclImdb/train/unsup/46296_0.txt\n",
            "aclImdb/train/unsup/46295_0.txt\n",
            "aclImdb/train/unsup/46294_0.txt\n",
            "aclImdb/train/unsup/46293_0.txt\n",
            "aclImdb/train/unsup/46292_0.txt\n",
            "aclImdb/train/unsup/46291_0.txt\n",
            "aclImdb/train/unsup/46290_0.txt\n",
            "aclImdb/train/unsup/46289_0.txt\n",
            "aclImdb/train/unsup/46288_0.txt\n",
            "aclImdb/train/unsup/46287_0.txt\n",
            "aclImdb/train/unsup/46286_0.txt\n",
            "aclImdb/train/unsup/46285_0.txt\n",
            "aclImdb/train/unsup/46284_0.txt\n",
            "aclImdb/train/unsup/46283_0.txt\n",
            "aclImdb/train/unsup/46282_0.txt\n",
            "aclImdb/train/unsup/46281_0.txt\n",
            "aclImdb/train/unsup/46280_0.txt\n",
            "aclImdb/train/unsup/46279_0.txt\n",
            "aclImdb/train/unsup/46278_0.txt\n",
            "aclImdb/train/unsup/46277_0.txt\n",
            "aclImdb/train/unsup/46276_0.txt\n",
            "aclImdb/train/unsup/46275_0.txt\n",
            "aclImdb/train/unsup/46274_0.txt\n",
            "aclImdb/train/unsup/46273_0.txt\n",
            "aclImdb/train/unsup/46272_0.txt\n",
            "aclImdb/train/unsup/46271_0.txt\n",
            "aclImdb/train/unsup/46270_0.txt\n",
            "aclImdb/train/unsup/46269_0.txt\n",
            "aclImdb/train/unsup/46268_0.txt\n",
            "aclImdb/train/unsup/46267_0.txt\n",
            "aclImdb/train/unsup/46266_0.txt\n",
            "aclImdb/train/unsup/46265_0.txt\n",
            "aclImdb/train/unsup/46264_0.txt\n",
            "aclImdb/train/unsup/46263_0.txt\n",
            "aclImdb/train/unsup/46262_0.txt\n",
            "aclImdb/train/unsup/46261_0.txt\n",
            "aclImdb/train/unsup/46260_0.txt\n",
            "aclImdb/train/unsup/46259_0.txt\n",
            "aclImdb/train/unsup/46258_0.txt\n",
            "aclImdb/train/unsup/46257_0.txt\n",
            "aclImdb/train/unsup/46256_0.txt\n",
            "aclImdb/train/unsup/46255_0.txt\n",
            "aclImdb/train/unsup/46254_0.txt\n",
            "aclImdb/train/unsup/46253_0.txt\n",
            "aclImdb/train/unsup/46252_0.txt\n",
            "aclImdb/train/unsup/46251_0.txt\n",
            "aclImdb/train/unsup/46250_0.txt\n",
            "aclImdb/train/unsup/46249_0.txt\n",
            "aclImdb/train/unsup/46248_0.txt\n",
            "aclImdb/train/unsup/46247_0.txt\n",
            "aclImdb/train/unsup/46246_0.txt\n",
            "aclImdb/train/unsup/46245_0.txt\n",
            "aclImdb/train/unsup/46244_0.txt\n",
            "aclImdb/train/unsup/46243_0.txt\n",
            "aclImdb/train/unsup/46242_0.txt\n",
            "aclImdb/train/unsup/46241_0.txt\n",
            "aclImdb/train/unsup/46240_0.txt\n",
            "aclImdb/train/unsup/46239_0.txt\n",
            "aclImdb/train/unsup/46238_0.txt\n",
            "aclImdb/train/unsup/46237_0.txt\n",
            "aclImdb/train/unsup/46236_0.txt\n",
            "aclImdb/train/unsup/46235_0.txt\n",
            "aclImdb/train/unsup/46234_0.txt\n",
            "aclImdb/train/unsup/46233_0.txt\n",
            "aclImdb/train/unsup/46232_0.txt\n",
            "aclImdb/train/unsup/46231_0.txt\n",
            "aclImdb/train/unsup/46230_0.txt\n",
            "aclImdb/train/unsup/46229_0.txt\n",
            "aclImdb/train/unsup/46228_0.txt\n",
            "aclImdb/train/unsup/46227_0.txt\n",
            "aclImdb/train/unsup/46226_0.txt\n",
            "aclImdb/train/unsup/46225_0.txt\n",
            "aclImdb/train/unsup/46224_0.txt\n",
            "aclImdb/train/unsup/46223_0.txt\n",
            "aclImdb/train/unsup/46222_0.txt\n",
            "aclImdb/train/unsup/46221_0.txt\n",
            "aclImdb/train/unsup/46220_0.txt\n",
            "aclImdb/train/unsup/46219_0.txt\n",
            "aclImdb/train/unsup/46218_0.txt\n",
            "aclImdb/train/unsup/46217_0.txt\n",
            "aclImdb/train/unsup/46216_0.txt\n",
            "aclImdb/train/unsup/46215_0.txt\n",
            "aclImdb/train/unsup/46214_0.txt\n",
            "aclImdb/train/unsup/46213_0.txt\n",
            "aclImdb/train/unsup/46212_0.txt\n",
            "aclImdb/train/unsup/46211_0.txt\n",
            "aclImdb/train/unsup/46210_0.txt\n",
            "aclImdb/train/unsup/46209_0.txt\n",
            "aclImdb/train/unsup/46208_0.txt\n",
            "aclImdb/train/unsup/46463_0.txt\n",
            "aclImdb/train/unsup/46462_0.txt\n",
            "aclImdb/train/unsup/46461_0.txt\n",
            "aclImdb/train/unsup/46460_0.txt\n",
            "aclImdb/train/unsup/46459_0.txt\n",
            "aclImdb/train/unsup/46458_0.txt\n",
            "aclImdb/train/unsup/46457_0.txt\n",
            "aclImdb/train/unsup/46456_0.txt\n",
            "aclImdb/train/unsup/46455_0.txt\n",
            "aclImdb/train/unsup/46454_0.txt\n",
            "aclImdb/train/unsup/46453_0.txt\n",
            "aclImdb/train/unsup/46452_0.txt\n",
            "aclImdb/train/unsup/46451_0.txt\n",
            "aclImdb/train/unsup/46450_0.txt\n",
            "aclImdb/train/unsup/46449_0.txt\n",
            "aclImdb/train/unsup/46448_0.txt\n",
            "aclImdb/train/unsup/46447_0.txt\n",
            "aclImdb/train/unsup/46446_0.txt\n",
            "aclImdb/train/unsup/46445_0.txt\n",
            "aclImdb/train/unsup/46444_0.txt\n",
            "aclImdb/train/unsup/46443_0.txt\n",
            "aclImdb/train/unsup/46442_0.txt\n",
            "aclImdb/train/unsup/46441_0.txt\n",
            "aclImdb/train/unsup/46440_0.txt\n",
            "aclImdb/train/unsup/46439_0.txt\n",
            "aclImdb/train/unsup/46438_0.txt\n",
            "aclImdb/train/unsup/46437_0.txt\n",
            "aclImdb/train/unsup/46436_0.txt\n",
            "aclImdb/train/unsup/46435_0.txt\n",
            "aclImdb/train/unsup/46434_0.txt\n",
            "aclImdb/train/unsup/46433_0.txt\n",
            "aclImdb/train/unsup/46432_0.txt\n",
            "aclImdb/train/unsup/46431_0.txt\n",
            "aclImdb/train/unsup/46430_0.txt\n",
            "aclImdb/train/unsup/46429_0.txt\n",
            "aclImdb/train/unsup/46428_0.txt\n",
            "aclImdb/train/unsup/46427_0.txt\n",
            "aclImdb/train/unsup/46426_0.txt\n",
            "aclImdb/train/unsup/46425_0.txt\n",
            "aclImdb/train/unsup/46424_0.txt\n",
            "aclImdb/train/unsup/46423_0.txt\n",
            "aclImdb/train/unsup/46422_0.txt\n",
            "aclImdb/train/unsup/46421_0.txt\n",
            "aclImdb/train/unsup/46420_0.txt\n",
            "aclImdb/train/unsup/46419_0.txt\n",
            "aclImdb/train/unsup/46418_0.txt\n",
            "aclImdb/train/unsup/46417_0.txt\n",
            "aclImdb/train/unsup/46416_0.txt\n",
            "aclImdb/train/unsup/46415_0.txt\n",
            "aclImdb/train/unsup/46414_0.txt\n",
            "aclImdb/train/unsup/46413_0.txt\n",
            "aclImdb/train/unsup/46412_0.txt\n",
            "aclImdb/train/unsup/46411_0.txt\n",
            "aclImdb/train/unsup/46410_0.txt\n",
            "aclImdb/train/unsup/46409_0.txt\n",
            "aclImdb/train/unsup/46408_0.txt\n",
            "aclImdb/train/unsup/46407_0.txt\n",
            "aclImdb/train/unsup/46406_0.txt\n",
            "aclImdb/train/unsup/46405_0.txt\n",
            "aclImdb/train/unsup/46404_0.txt\n",
            "aclImdb/train/unsup/46403_0.txt\n",
            "aclImdb/train/unsup/46402_0.txt\n",
            "aclImdb/train/unsup/46401_0.txt\n",
            "aclImdb/train/unsup/46400_0.txt\n",
            "aclImdb/train/unsup/46399_0.txt\n",
            "aclImdb/train/unsup/46398_0.txt\n",
            "aclImdb/train/unsup/46397_0.txt\n",
            "aclImdb/train/unsup/46396_0.txt\n",
            "aclImdb/train/unsup/46395_0.txt\n",
            "aclImdb/train/unsup/46394_0.txt\n",
            "aclImdb/train/unsup/46393_0.txt\n",
            "aclImdb/train/unsup/46392_0.txt\n",
            "aclImdb/train/unsup/46391_0.txt\n",
            "aclImdb/train/unsup/46390_0.txt\n",
            "aclImdb/train/unsup/46389_0.txt\n",
            "aclImdb/train/unsup/46388_0.txt\n",
            "aclImdb/train/unsup/46387_0.txt\n",
            "aclImdb/train/unsup/46386_0.txt\n",
            "aclImdb/train/unsup/46385_0.txt\n",
            "aclImdb/train/unsup/46384_0.txt\n",
            "aclImdb/train/unsup/46383_0.txt\n",
            "aclImdb/train/unsup/46382_0.txt\n",
            "aclImdb/train/unsup/46381_0.txt\n",
            "aclImdb/train/unsup/46380_0.txt\n",
            "aclImdb/train/unsup/46379_0.txt\n",
            "aclImdb/train/unsup/46378_0.txt\n",
            "aclImdb/train/unsup/46377_0.txt\n",
            "aclImdb/train/unsup/46376_0.txt\n",
            "aclImdb/train/unsup/46375_0.txt\n",
            "aclImdb/train/unsup/46374_0.txt\n",
            "aclImdb/train/unsup/46373_0.txt\n",
            "aclImdb/train/unsup/46372_0.txt\n",
            "aclImdb/train/unsup/46371_0.txt\n",
            "aclImdb/train/unsup/46370_0.txt\n",
            "aclImdb/train/unsup/46369_0.txt\n",
            "aclImdb/train/unsup/46368_0.txt\n",
            "aclImdb/train/unsup/46367_0.txt\n",
            "aclImdb/train/unsup/46366_0.txt\n",
            "aclImdb/train/unsup/46365_0.txt\n",
            "aclImdb/train/unsup/46364_0.txt\n",
            "aclImdb/train/unsup/46363_0.txt\n",
            "aclImdb/train/unsup/46362_0.txt\n",
            "aclImdb/train/unsup/46361_0.txt\n",
            "aclImdb/train/unsup/46360_0.txt\n",
            "aclImdb/train/unsup/46359_0.txt\n",
            "aclImdb/train/unsup/46358_0.txt\n",
            "aclImdb/train/unsup/46357_0.txt\n",
            "aclImdb/train/unsup/46356_0.txt\n",
            "aclImdb/train/unsup/46355_0.txt\n",
            "aclImdb/train/unsup/46354_0.txt\n",
            "aclImdb/train/unsup/46353_0.txt\n",
            "aclImdb/train/unsup/46352_0.txt\n",
            "aclImdb/train/unsup/46351_0.txt\n",
            "aclImdb/train/unsup/46350_0.txt\n",
            "aclImdb/train/unsup/46349_0.txt\n",
            "aclImdb/train/unsup/46348_0.txt\n",
            "aclImdb/train/unsup/46347_0.txt\n",
            "aclImdb/train/unsup/46346_0.txt\n",
            "aclImdb/train/unsup/46345_0.txt\n",
            "aclImdb/train/unsup/46344_0.txt\n",
            "aclImdb/train/unsup/46343_0.txt\n",
            "aclImdb/train/unsup/46342_0.txt\n",
            "aclImdb/train/unsup/46341_0.txt\n",
            "aclImdb/train/unsup/46340_0.txt\n",
            "aclImdb/train/unsup/46339_0.txt\n",
            "aclImdb/train/unsup/46338_0.txt\n",
            "aclImdb/train/unsup/46337_0.txt\n",
            "aclImdb/train/unsup/46336_0.txt\n",
            "aclImdb/train/unsup/46591_0.txt\n",
            "aclImdb/train/unsup/46590_0.txt\n",
            "aclImdb/train/unsup/46589_0.txt\n",
            "aclImdb/train/unsup/46588_0.txt\n",
            "aclImdb/train/unsup/46587_0.txt\n",
            "aclImdb/train/unsup/46586_0.txt\n",
            "aclImdb/train/unsup/46585_0.txt\n",
            "aclImdb/train/unsup/46584_0.txt\n",
            "aclImdb/train/unsup/46583_0.txt\n",
            "aclImdb/train/unsup/46582_0.txt\n",
            "aclImdb/train/unsup/46581_0.txt\n",
            "aclImdb/train/unsup/46580_0.txt\n",
            "aclImdb/train/unsup/46579_0.txt\n",
            "aclImdb/train/unsup/46578_0.txt\n",
            "aclImdb/train/unsup/46577_0.txt\n",
            "aclImdb/train/unsup/46576_0.txt\n",
            "aclImdb/train/unsup/46575_0.txt\n",
            "aclImdb/train/unsup/46574_0.txt\n",
            "aclImdb/train/unsup/46573_0.txt\n",
            "aclImdb/train/unsup/46572_0.txt\n",
            "aclImdb/train/unsup/46571_0.txt\n",
            "aclImdb/train/unsup/46570_0.txt\n",
            "aclImdb/train/unsup/46569_0.txt\n",
            "aclImdb/train/unsup/46568_0.txt\n",
            "aclImdb/train/unsup/46567_0.txt\n",
            "aclImdb/train/unsup/46566_0.txt\n",
            "aclImdb/train/unsup/46565_0.txt\n",
            "aclImdb/train/unsup/46564_0.txt\n",
            "aclImdb/train/unsup/46563_0.txt\n",
            "aclImdb/train/unsup/46562_0.txt\n",
            "aclImdb/train/unsup/46561_0.txt\n",
            "aclImdb/train/unsup/46560_0.txt\n",
            "aclImdb/train/unsup/46559_0.txt\n",
            "aclImdb/train/unsup/46558_0.txt\n",
            "aclImdb/train/unsup/46557_0.txt\n",
            "aclImdb/train/unsup/46556_0.txt\n",
            "aclImdb/train/unsup/46555_0.txt\n",
            "aclImdb/train/unsup/46554_0.txt\n",
            "aclImdb/train/unsup/46553_0.txt\n",
            "aclImdb/train/unsup/46552_0.txt\n",
            "aclImdb/train/unsup/46551_0.txt\n",
            "aclImdb/train/unsup/46550_0.txt\n",
            "aclImdb/train/unsup/46549_0.txt\n",
            "aclImdb/train/unsup/46548_0.txt\n",
            "aclImdb/train/unsup/46547_0.txt\n",
            "aclImdb/train/unsup/46546_0.txt\n",
            "aclImdb/train/unsup/46545_0.txt\n",
            "aclImdb/train/unsup/46544_0.txt\n",
            "aclImdb/train/unsup/46543_0.txt\n",
            "aclImdb/train/unsup/46542_0.txt\n",
            "aclImdb/train/unsup/46541_0.txt\n",
            "aclImdb/train/unsup/46540_0.txt\n",
            "aclImdb/train/unsup/46539_0.txt\n",
            "aclImdb/train/unsup/46538_0.txt\n",
            "aclImdb/train/unsup/46537_0.txt\n",
            "aclImdb/train/unsup/46536_0.txt\n",
            "aclImdb/train/unsup/46535_0.txt\n",
            "aclImdb/train/unsup/46534_0.txt\n",
            "aclImdb/train/unsup/46533_0.txt\n",
            "aclImdb/train/unsup/46532_0.txt\n",
            "aclImdb/train/unsup/46531_0.txt\n",
            "aclImdb/train/unsup/46530_0.txt\n",
            "aclImdb/train/unsup/46529_0.txt\n",
            "aclImdb/train/unsup/46528_0.txt\n",
            "aclImdb/train/unsup/46527_0.txt\n",
            "aclImdb/train/unsup/46526_0.txt\n",
            "aclImdb/train/unsup/46525_0.txt\n",
            "aclImdb/train/unsup/46524_0.txt\n",
            "aclImdb/train/unsup/46523_0.txt\n",
            "aclImdb/train/unsup/46522_0.txt\n",
            "aclImdb/train/unsup/46521_0.txt\n",
            "aclImdb/train/unsup/46520_0.txt\n",
            "aclImdb/train/unsup/46519_0.txt\n",
            "aclImdb/train/unsup/46518_0.txt\n",
            "aclImdb/train/unsup/46517_0.txt\n",
            "aclImdb/train/unsup/46516_0.txt\n",
            "aclImdb/train/unsup/46515_0.txt\n",
            "aclImdb/train/unsup/46514_0.txt\n",
            "aclImdb/train/unsup/46513_0.txt\n",
            "aclImdb/train/unsup/46512_0.txt\n",
            "aclImdb/train/unsup/46511_0.txt\n",
            "aclImdb/train/unsup/46510_0.txt\n",
            "aclImdb/train/unsup/46509_0.txt\n",
            "aclImdb/train/unsup/46508_0.txt\n",
            "aclImdb/train/unsup/46507_0.txt\n",
            "aclImdb/train/unsup/46506_0.txt\n",
            "aclImdb/train/unsup/46505_0.txt\n",
            "aclImdb/train/unsup/46504_0.txt\n",
            "aclImdb/train/unsup/46503_0.txt\n",
            "aclImdb/train/unsup/46502_0.txt\n",
            "aclImdb/train/unsup/46501_0.txt\n",
            "aclImdb/train/unsup/46500_0.txt\n",
            "aclImdb/train/unsup/46499_0.txt\n",
            "aclImdb/train/unsup/46498_0.txt\n",
            "aclImdb/train/unsup/46497_0.txt\n",
            "aclImdb/train/unsup/46496_0.txt\n",
            "aclImdb/train/unsup/46495_0.txt\n",
            "aclImdb/train/unsup/46494_0.txt\n",
            "aclImdb/train/unsup/46493_0.txt\n",
            "aclImdb/train/unsup/46492_0.txt\n",
            "aclImdb/train/unsup/46491_0.txt\n",
            "aclImdb/train/unsup/46490_0.txt\n",
            "aclImdb/train/unsup/46489_0.txt\n",
            "aclImdb/train/unsup/46488_0.txt\n",
            "aclImdb/train/unsup/46487_0.txt\n",
            "aclImdb/train/unsup/46486_0.txt\n",
            "aclImdb/train/unsup/46485_0.txt\n",
            "aclImdb/train/unsup/46484_0.txt\n",
            "aclImdb/train/unsup/46483_0.txt\n",
            "aclImdb/train/unsup/46482_0.txt\n",
            "aclImdb/train/unsup/46481_0.txt\n",
            "aclImdb/train/unsup/46480_0.txt\n",
            "aclImdb/train/unsup/46479_0.txt\n",
            "aclImdb/train/unsup/46478_0.txt\n",
            "aclImdb/train/unsup/46477_0.txt\n",
            "aclImdb/train/unsup/46476_0.txt\n",
            "aclImdb/train/unsup/46475_0.txt\n",
            "aclImdb/train/unsup/46474_0.txt\n",
            "aclImdb/train/unsup/46473_0.txt\n",
            "aclImdb/train/unsup/46472_0.txt\n",
            "aclImdb/train/unsup/46471_0.txt\n",
            "aclImdb/train/unsup/46470_0.txt\n",
            "aclImdb/train/unsup/46469_0.txt\n",
            "aclImdb/train/unsup/46468_0.txt\n",
            "aclImdb/train/unsup/46467_0.txt\n",
            "aclImdb/train/unsup/46466_0.txt\n",
            "aclImdb/train/unsup/46465_0.txt\n",
            "aclImdb/train/unsup/46464_0.txt\n",
            "aclImdb/train/unsup/46719_0.txt\n",
            "aclImdb/train/unsup/46718_0.txt\n",
            "aclImdb/train/unsup/46717_0.txt\n",
            "aclImdb/train/unsup/46716_0.txt\n",
            "aclImdb/train/unsup/46715_0.txt\n",
            "aclImdb/train/unsup/46714_0.txt\n",
            "aclImdb/train/unsup/46713_0.txt\n",
            "aclImdb/train/unsup/46712_0.txt\n",
            "aclImdb/train/unsup/46711_0.txt\n",
            "aclImdb/train/unsup/46710_0.txt\n",
            "aclImdb/train/unsup/46709_0.txt\n",
            "aclImdb/train/unsup/46708_0.txt\n",
            "aclImdb/train/unsup/46707_0.txt\n",
            "aclImdb/train/unsup/46706_0.txt\n",
            "aclImdb/train/unsup/46705_0.txt\n",
            "aclImdb/train/unsup/46704_0.txt\n",
            "aclImdb/train/unsup/46703_0.txt\n",
            "aclImdb/train/unsup/46702_0.txt\n",
            "aclImdb/train/unsup/46701_0.txt\n",
            "aclImdb/train/unsup/46700_0.txt\n",
            "aclImdb/train/unsup/46699_0.txt\n",
            "aclImdb/train/unsup/46698_0.txt\n",
            "aclImdb/train/unsup/46697_0.txt\n",
            "aclImdb/train/unsup/46696_0.txt\n",
            "aclImdb/train/unsup/46695_0.txt\n",
            "aclImdb/train/unsup/46694_0.txt\n",
            "aclImdb/train/unsup/46693_0.txt\n",
            "aclImdb/train/unsup/46692_0.txt\n",
            "aclImdb/train/unsup/46691_0.txt\n",
            "aclImdb/train/unsup/46690_0.txt\n",
            "aclImdb/train/unsup/46689_0.txt\n",
            "aclImdb/train/unsup/46688_0.txt\n",
            "aclImdb/train/unsup/46687_0.txt\n",
            "aclImdb/train/unsup/46686_0.txt\n",
            "aclImdb/train/unsup/46685_0.txt\n",
            "aclImdb/train/unsup/46684_0.txt\n",
            "aclImdb/train/unsup/46683_0.txt\n",
            "aclImdb/train/unsup/46682_0.txt\n",
            "aclImdb/train/unsup/46681_0.txt\n",
            "aclImdb/train/unsup/46680_0.txt\n",
            "aclImdb/train/unsup/46679_0.txt\n",
            "aclImdb/train/unsup/46678_0.txt\n",
            "aclImdb/train/unsup/46677_0.txt\n",
            "aclImdb/train/unsup/46676_0.txt\n",
            "aclImdb/train/unsup/46675_0.txt\n",
            "aclImdb/train/unsup/46674_0.txt\n",
            "aclImdb/train/unsup/46673_0.txt\n",
            "aclImdb/train/unsup/46672_0.txt\n",
            "aclImdb/train/unsup/46671_0.txt\n",
            "aclImdb/train/unsup/46670_0.txt\n",
            "aclImdb/train/unsup/46669_0.txt\n",
            "aclImdb/train/unsup/46668_0.txt\n",
            "aclImdb/train/unsup/46667_0.txt\n",
            "aclImdb/train/unsup/46666_0.txt\n",
            "aclImdb/train/unsup/46665_0.txt\n",
            "aclImdb/train/unsup/46664_0.txt\n",
            "aclImdb/train/unsup/46663_0.txt\n",
            "aclImdb/train/unsup/46662_0.txt\n",
            "aclImdb/train/unsup/46661_0.txt\n",
            "aclImdb/train/unsup/46660_0.txt\n",
            "aclImdb/train/unsup/46659_0.txt\n",
            "aclImdb/train/unsup/46658_0.txt\n",
            "aclImdb/train/unsup/46657_0.txt\n",
            "aclImdb/train/unsup/46656_0.txt\n",
            "aclImdb/train/unsup/46655_0.txt\n",
            "aclImdb/train/unsup/46654_0.txt\n",
            "aclImdb/train/unsup/46653_0.txt\n",
            "aclImdb/train/unsup/46652_0.txt\n",
            "aclImdb/train/unsup/46651_0.txt\n",
            "aclImdb/train/unsup/46650_0.txt\n",
            "aclImdb/train/unsup/46649_0.txt\n",
            "aclImdb/train/unsup/46648_0.txt\n",
            "aclImdb/train/unsup/46647_0.txt\n",
            "aclImdb/train/unsup/46646_0.txt\n",
            "aclImdb/train/unsup/46645_0.txt\n",
            "aclImdb/train/unsup/46644_0.txt\n",
            "aclImdb/train/unsup/46643_0.txt\n",
            "aclImdb/train/unsup/46642_0.txt\n",
            "aclImdb/train/unsup/46641_0.txt\n",
            "aclImdb/train/unsup/46640_0.txt\n",
            "aclImdb/train/unsup/46639_0.txt\n",
            "aclImdb/train/unsup/46638_0.txt\n",
            "aclImdb/train/unsup/46637_0.txt\n",
            "aclImdb/train/unsup/46636_0.txt\n",
            "aclImdb/train/unsup/46635_0.txt\n",
            "aclImdb/train/unsup/46634_0.txt\n",
            "aclImdb/train/unsup/46633_0.txt\n",
            "aclImdb/train/unsup/46632_0.txt\n",
            "aclImdb/train/unsup/46631_0.txt\n",
            "aclImdb/train/unsup/46630_0.txt\n",
            "aclImdb/train/unsup/46629_0.txt\n",
            "aclImdb/train/unsup/46628_0.txt\n",
            "aclImdb/train/unsup/46627_0.txt\n",
            "aclImdb/train/unsup/46626_0.txt\n",
            "aclImdb/train/unsup/46625_0.txt\n",
            "aclImdb/train/unsup/46624_0.txt\n",
            "aclImdb/train/unsup/46623_0.txt\n",
            "aclImdb/train/unsup/46622_0.txt\n",
            "aclImdb/train/unsup/46621_0.txt\n",
            "aclImdb/train/unsup/46620_0.txt\n",
            "aclImdb/train/unsup/46619_0.txt\n",
            "aclImdb/train/unsup/46618_0.txt\n",
            "aclImdb/train/unsup/46617_0.txt\n",
            "aclImdb/train/unsup/46616_0.txt\n",
            "aclImdb/train/unsup/46615_0.txt\n",
            "aclImdb/train/unsup/46614_0.txt\n",
            "aclImdb/train/unsup/46613_0.txt\n",
            "aclImdb/train/unsup/46612_0.txt\n",
            "aclImdb/train/unsup/46611_0.txt\n",
            "aclImdb/train/unsup/46610_0.txt\n",
            "aclImdb/train/unsup/46609_0.txt\n",
            "aclImdb/train/unsup/46608_0.txt\n",
            "aclImdb/train/unsup/46607_0.txt\n",
            "aclImdb/train/unsup/46606_0.txt\n",
            "aclImdb/train/unsup/46605_0.txt\n",
            "aclImdb/train/unsup/46604_0.txt\n",
            "aclImdb/train/unsup/46603_0.txt\n",
            "aclImdb/train/unsup/46602_0.txt\n",
            "aclImdb/train/unsup/46601_0.txt\n",
            "aclImdb/train/unsup/46600_0.txt\n",
            "aclImdb/train/unsup/46599_0.txt\n",
            "aclImdb/train/unsup/46598_0.txt\n",
            "aclImdb/train/unsup/46597_0.txt\n",
            "aclImdb/train/unsup/46596_0.txt\n",
            "aclImdb/train/unsup/46595_0.txt\n",
            "aclImdb/train/unsup/46594_0.txt\n",
            "aclImdb/train/unsup/46593_0.txt\n",
            "aclImdb/train/unsup/46592_0.txt\n",
            "aclImdb/train/unsup/46847_0.txt\n",
            "aclImdb/train/unsup/46846_0.txt\n",
            "aclImdb/train/unsup/46845_0.txt\n",
            "aclImdb/train/unsup/46844_0.txt\n",
            "aclImdb/train/unsup/46843_0.txt\n",
            "aclImdb/train/unsup/46842_0.txt\n",
            "aclImdb/train/unsup/46841_0.txt\n",
            "aclImdb/train/unsup/46840_0.txt\n",
            "aclImdb/train/unsup/46839_0.txt\n",
            "aclImdb/train/unsup/46838_0.txt\n",
            "aclImdb/train/unsup/46837_0.txt\n",
            "aclImdb/train/unsup/46836_0.txt\n",
            "aclImdb/train/unsup/46835_0.txt\n",
            "aclImdb/train/unsup/46834_0.txt\n",
            "aclImdb/train/unsup/46833_0.txt\n",
            "aclImdb/train/unsup/46832_0.txt\n",
            "aclImdb/train/unsup/46831_0.txt\n",
            "aclImdb/train/unsup/46830_0.txt\n",
            "aclImdb/train/unsup/46829_0.txt\n",
            "aclImdb/train/unsup/46828_0.txt\n",
            "aclImdb/train/unsup/46827_0.txt\n",
            "aclImdb/train/unsup/46826_0.txt\n",
            "aclImdb/train/unsup/46825_0.txt\n",
            "aclImdb/train/unsup/46824_0.txt\n",
            "aclImdb/train/unsup/46823_0.txt\n",
            "aclImdb/train/unsup/46822_0.txt\n",
            "aclImdb/train/unsup/46821_0.txt\n",
            "aclImdb/train/unsup/46820_0.txt\n",
            "aclImdb/train/unsup/46819_0.txt\n",
            "aclImdb/train/unsup/46818_0.txt\n",
            "aclImdb/train/unsup/46817_0.txt\n",
            "aclImdb/train/unsup/46816_0.txt\n",
            "aclImdb/train/unsup/46815_0.txt\n",
            "aclImdb/train/unsup/46814_0.txt\n",
            "aclImdb/train/unsup/46813_0.txt\n",
            "aclImdb/train/unsup/46812_0.txt\n",
            "aclImdb/train/unsup/46811_0.txt\n",
            "aclImdb/train/unsup/46810_0.txt\n",
            "aclImdb/train/unsup/46809_0.txt\n",
            "aclImdb/train/unsup/46808_0.txt\n",
            "aclImdb/train/unsup/46807_0.txt\n",
            "aclImdb/train/unsup/46806_0.txt\n",
            "aclImdb/train/unsup/46805_0.txt\n",
            "aclImdb/train/unsup/46804_0.txt\n",
            "aclImdb/train/unsup/46803_0.txt\n",
            "aclImdb/train/unsup/46802_0.txt\n",
            "aclImdb/train/unsup/46801_0.txt\n",
            "aclImdb/train/unsup/46800_0.txt\n",
            "aclImdb/train/unsup/46799_0.txt\n",
            "aclImdb/train/unsup/46798_0.txt\n",
            "aclImdb/train/unsup/46797_0.txt\n",
            "aclImdb/train/unsup/46796_0.txt\n",
            "aclImdb/train/unsup/46795_0.txt\n",
            "aclImdb/train/unsup/46794_0.txt\n",
            "aclImdb/train/unsup/46793_0.txt\n",
            "aclImdb/train/unsup/46792_0.txt\n",
            "aclImdb/train/unsup/46791_0.txt\n",
            "aclImdb/train/unsup/46790_0.txt\n",
            "aclImdb/train/unsup/46789_0.txt\n",
            "aclImdb/train/unsup/46788_0.txt\n",
            "aclImdb/train/unsup/46787_0.txt\n",
            "aclImdb/train/unsup/46786_0.txt\n",
            "aclImdb/train/unsup/46785_0.txt\n",
            "aclImdb/train/unsup/46784_0.txt\n",
            "aclImdb/train/unsup/46783_0.txt\n",
            "aclImdb/train/unsup/46782_0.txt\n",
            "aclImdb/train/unsup/46781_0.txt\n",
            "aclImdb/train/unsup/46780_0.txt\n",
            "aclImdb/train/unsup/46779_0.txt\n",
            "aclImdb/train/unsup/46778_0.txt\n",
            "aclImdb/train/unsup/46777_0.txt\n",
            "aclImdb/train/unsup/46776_0.txt\n",
            "aclImdb/train/unsup/46775_0.txt\n",
            "aclImdb/train/unsup/46774_0.txt\n",
            "aclImdb/train/unsup/46773_0.txt\n",
            "aclImdb/train/unsup/46772_0.txt\n",
            "aclImdb/train/unsup/46771_0.txt\n",
            "aclImdb/train/unsup/46770_0.txt\n",
            "aclImdb/train/unsup/46769_0.txt\n",
            "aclImdb/train/unsup/46768_0.txt\n",
            "aclImdb/train/unsup/46767_0.txt\n",
            "aclImdb/train/unsup/46766_0.txt\n",
            "aclImdb/train/unsup/46765_0.txt\n",
            "aclImdb/train/unsup/46764_0.txt\n",
            "aclImdb/train/unsup/46763_0.txt\n",
            "aclImdb/train/unsup/46762_0.txt\n",
            "aclImdb/train/unsup/46761_0.txt\n",
            "aclImdb/train/unsup/46760_0.txt\n",
            "aclImdb/train/unsup/46759_0.txt\n",
            "aclImdb/train/unsup/46758_0.txt\n",
            "aclImdb/train/unsup/46757_0.txt\n",
            "aclImdb/train/unsup/46756_0.txt\n",
            "aclImdb/train/unsup/46755_0.txt\n",
            "aclImdb/train/unsup/46754_0.txt\n",
            "aclImdb/train/unsup/46753_0.txt\n",
            "aclImdb/train/unsup/46752_0.txt\n",
            "aclImdb/train/unsup/46751_0.txt\n",
            "aclImdb/train/unsup/46750_0.txt\n",
            "aclImdb/train/unsup/46749_0.txt\n",
            "aclImdb/train/unsup/46748_0.txt\n",
            "aclImdb/train/unsup/46747_0.txt\n",
            "aclImdb/train/unsup/46746_0.txt\n",
            "aclImdb/train/unsup/46745_0.txt\n",
            "aclImdb/train/unsup/46744_0.txt\n",
            "aclImdb/train/unsup/46743_0.txt\n",
            "aclImdb/train/unsup/46742_0.txt\n",
            "aclImdb/train/unsup/46741_0.txt\n",
            "aclImdb/train/unsup/46740_0.txt\n",
            "aclImdb/train/unsup/46739_0.txt\n",
            "aclImdb/train/unsup/46738_0.txt\n",
            "aclImdb/train/unsup/46737_0.txt\n",
            "aclImdb/train/unsup/46736_0.txt\n",
            "aclImdb/train/unsup/46735_0.txt\n",
            "aclImdb/train/unsup/46734_0.txt\n",
            "aclImdb/train/unsup/46733_0.txt\n",
            "aclImdb/train/unsup/46732_0.txt\n",
            "aclImdb/train/unsup/46731_0.txt\n",
            "aclImdb/train/unsup/46730_0.txt\n",
            "aclImdb/train/unsup/46729_0.txt\n",
            "aclImdb/train/unsup/46728_0.txt\n",
            "aclImdb/train/unsup/46727_0.txt\n",
            "aclImdb/train/unsup/46726_0.txt\n",
            "aclImdb/train/unsup/46725_0.txt\n",
            "aclImdb/train/unsup/46724_0.txt\n",
            "aclImdb/train/unsup/46723_0.txt\n",
            "aclImdb/train/unsup/46722_0.txt\n",
            "aclImdb/train/unsup/46721_0.txt\n",
            "aclImdb/train/unsup/46720_0.txt\n",
            "aclImdb/train/unsup/46975_0.txt\n",
            "aclImdb/train/unsup/46974_0.txt\n",
            "aclImdb/train/unsup/46973_0.txt\n",
            "aclImdb/train/unsup/46972_0.txt\n",
            "aclImdb/train/unsup/46971_0.txt\n",
            "aclImdb/train/unsup/46970_0.txt\n",
            "aclImdb/train/unsup/46969_0.txt\n",
            "aclImdb/train/unsup/46968_0.txt\n",
            "aclImdb/train/unsup/46967_0.txt\n",
            "aclImdb/train/unsup/46966_0.txt\n",
            "aclImdb/train/unsup/46965_0.txt\n",
            "aclImdb/train/unsup/46964_0.txt\n",
            "aclImdb/train/unsup/46963_0.txt\n",
            "aclImdb/train/unsup/46962_0.txt\n",
            "aclImdb/train/unsup/46961_0.txt\n",
            "aclImdb/train/unsup/46960_0.txt\n",
            "aclImdb/train/unsup/46959_0.txt\n",
            "aclImdb/train/unsup/46958_0.txt\n",
            "aclImdb/train/unsup/46957_0.txt\n",
            "aclImdb/train/unsup/46956_0.txt\n",
            "aclImdb/train/unsup/46955_0.txt\n",
            "aclImdb/train/unsup/46954_0.txt\n",
            "aclImdb/train/unsup/46953_0.txt\n",
            "aclImdb/train/unsup/46952_0.txt\n",
            "aclImdb/train/unsup/46951_0.txt\n",
            "aclImdb/train/unsup/46950_0.txt\n",
            "aclImdb/train/unsup/46949_0.txt\n",
            "aclImdb/train/unsup/46948_0.txt\n",
            "aclImdb/train/unsup/46947_0.txt\n",
            "aclImdb/train/unsup/46946_0.txt\n",
            "aclImdb/train/unsup/46945_0.txt\n",
            "aclImdb/train/unsup/46944_0.txt\n",
            "aclImdb/train/unsup/46943_0.txt\n",
            "aclImdb/train/unsup/46942_0.txt\n",
            "aclImdb/train/unsup/46941_0.txt\n",
            "aclImdb/train/unsup/46940_0.txt\n",
            "aclImdb/train/unsup/46939_0.txt\n",
            "aclImdb/train/unsup/46938_0.txt\n",
            "aclImdb/train/unsup/46937_0.txt\n",
            "aclImdb/train/unsup/46936_0.txt\n",
            "aclImdb/train/unsup/46935_0.txt\n",
            "aclImdb/train/unsup/46934_0.txt\n",
            "aclImdb/train/unsup/46933_0.txt\n",
            "aclImdb/train/unsup/46932_0.txt\n",
            "aclImdb/train/unsup/46931_0.txt\n",
            "aclImdb/train/unsup/46930_0.txt\n",
            "aclImdb/train/unsup/46929_0.txt\n",
            "aclImdb/train/unsup/46928_0.txt\n",
            "aclImdb/train/unsup/46927_0.txt\n",
            "aclImdb/train/unsup/46926_0.txt\n",
            "aclImdb/train/unsup/46925_0.txt\n",
            "aclImdb/train/unsup/46924_0.txt\n",
            "aclImdb/train/unsup/46923_0.txt\n",
            "aclImdb/train/unsup/46922_0.txt\n",
            "aclImdb/train/unsup/46921_0.txt\n",
            "aclImdb/train/unsup/46920_0.txt\n",
            "aclImdb/train/unsup/46919_0.txt\n",
            "aclImdb/train/unsup/46918_0.txt\n",
            "aclImdb/train/unsup/46917_0.txt\n",
            "aclImdb/train/unsup/46916_0.txt\n",
            "aclImdb/train/unsup/46915_0.txt\n",
            "aclImdb/train/unsup/46914_0.txt\n",
            "aclImdb/train/unsup/46913_0.txt\n",
            "aclImdb/train/unsup/46912_0.txt\n",
            "aclImdb/train/unsup/46911_0.txt\n",
            "aclImdb/train/unsup/46910_0.txt\n",
            "aclImdb/train/unsup/46909_0.txt\n",
            "aclImdb/train/unsup/46908_0.txt\n",
            "aclImdb/train/unsup/46907_0.txt\n",
            "aclImdb/train/unsup/46906_0.txt\n",
            "aclImdb/train/unsup/46905_0.txt\n",
            "aclImdb/train/unsup/46904_0.txt\n",
            "aclImdb/train/unsup/46903_0.txt\n",
            "aclImdb/train/unsup/46902_0.txt\n",
            "aclImdb/train/unsup/46901_0.txt\n",
            "aclImdb/train/unsup/46900_0.txt\n",
            "aclImdb/train/unsup/46899_0.txt\n",
            "aclImdb/train/unsup/46898_0.txt\n",
            "aclImdb/train/unsup/46897_0.txt\n",
            "aclImdb/train/unsup/46896_0.txt\n",
            "aclImdb/train/unsup/46895_0.txt\n",
            "aclImdb/train/unsup/46894_0.txt\n",
            "aclImdb/train/unsup/46893_0.txt\n",
            "aclImdb/train/unsup/46892_0.txt\n",
            "aclImdb/train/unsup/46891_0.txt\n",
            "aclImdb/train/unsup/46890_0.txt\n",
            "aclImdb/train/unsup/46889_0.txt\n",
            "aclImdb/train/unsup/46888_0.txt\n",
            "aclImdb/train/unsup/46887_0.txt\n",
            "aclImdb/train/unsup/46886_0.txt\n",
            "aclImdb/train/unsup/46885_0.txt\n",
            "aclImdb/train/unsup/46884_0.txt\n",
            "aclImdb/train/unsup/46883_0.txt\n",
            "aclImdb/train/unsup/46882_0.txt\n",
            "aclImdb/train/unsup/46881_0.txt\n",
            "aclImdb/train/unsup/46880_0.txt\n",
            "aclImdb/train/unsup/46879_0.txt\n",
            "aclImdb/train/unsup/46878_0.txt\n",
            "aclImdb/train/unsup/46877_0.txt\n",
            "aclImdb/train/unsup/46876_0.txt\n",
            "aclImdb/train/unsup/46875_0.txt\n",
            "aclImdb/train/unsup/46874_0.txt\n",
            "aclImdb/train/unsup/46873_0.txt\n",
            "aclImdb/train/unsup/46872_0.txt\n",
            "aclImdb/train/unsup/46871_0.txt\n",
            "aclImdb/train/unsup/46870_0.txt\n",
            "aclImdb/train/unsup/46869_0.txt\n",
            "aclImdb/train/unsup/46868_0.txt\n",
            "aclImdb/train/unsup/46867_0.txt\n",
            "aclImdb/train/unsup/46866_0.txt\n",
            "aclImdb/train/unsup/46865_0.txt\n",
            "aclImdb/train/unsup/46864_0.txt\n",
            "aclImdb/train/unsup/46863_0.txt\n",
            "aclImdb/train/unsup/46862_0.txt\n",
            "aclImdb/train/unsup/46861_0.txt\n",
            "aclImdb/train/unsup/46860_0.txt\n",
            "aclImdb/train/unsup/46859_0.txt\n",
            "aclImdb/train/unsup/46858_0.txt\n",
            "aclImdb/train/unsup/46857_0.txt\n",
            "aclImdb/train/unsup/46856_0.txt\n",
            "aclImdb/train/unsup/46855_0.txt\n",
            "aclImdb/train/unsup/46854_0.txt\n",
            "aclImdb/train/unsup/46853_0.txt\n",
            "aclImdb/train/unsup/46852_0.txt\n",
            "aclImdb/train/unsup/46851_0.txt\n",
            "aclImdb/train/unsup/46850_0.txt\n",
            "aclImdb/train/unsup/46849_0.txt\n",
            "aclImdb/train/unsup/46848_0.txt\n",
            "aclImdb/train/unsup/47103_0.txt\n",
            "aclImdb/train/unsup/47102_0.txt\n",
            "aclImdb/train/unsup/47101_0.txt\n",
            "aclImdb/train/unsup/47100_0.txt\n",
            "aclImdb/train/unsup/47099_0.txt\n",
            "aclImdb/train/unsup/47098_0.txt\n",
            "aclImdb/train/unsup/47097_0.txt\n",
            "aclImdb/train/unsup/47096_0.txt\n",
            "aclImdb/train/unsup/47095_0.txt\n",
            "aclImdb/train/unsup/47094_0.txt\n",
            "aclImdb/train/unsup/47093_0.txt\n",
            "aclImdb/train/unsup/47092_0.txt\n",
            "aclImdb/train/unsup/47091_0.txt\n",
            "aclImdb/train/unsup/47090_0.txt\n",
            "aclImdb/train/unsup/47089_0.txt\n",
            "aclImdb/train/unsup/47088_0.txt\n",
            "aclImdb/train/unsup/47087_0.txt\n",
            "aclImdb/train/unsup/47086_0.txt\n",
            "aclImdb/train/unsup/47085_0.txt\n",
            "aclImdb/train/unsup/47084_0.txt\n",
            "aclImdb/train/unsup/47083_0.txt\n",
            "aclImdb/train/unsup/47082_0.txt\n",
            "aclImdb/train/unsup/47081_0.txt\n",
            "aclImdb/train/unsup/47080_0.txt\n",
            "aclImdb/train/unsup/47079_0.txt\n",
            "aclImdb/train/unsup/47078_0.txt\n",
            "aclImdb/train/unsup/47077_0.txt\n",
            "aclImdb/train/unsup/47076_0.txt\n",
            "aclImdb/train/unsup/47075_0.txt\n",
            "aclImdb/train/unsup/47074_0.txt\n",
            "aclImdb/train/unsup/47073_0.txt\n",
            "aclImdb/train/unsup/47072_0.txt\n",
            "aclImdb/train/unsup/47071_0.txt\n",
            "aclImdb/train/unsup/47070_0.txt\n",
            "aclImdb/train/unsup/47069_0.txt\n",
            "aclImdb/train/unsup/47068_0.txt\n",
            "aclImdb/train/unsup/47067_0.txt\n",
            "aclImdb/train/unsup/47066_0.txt\n",
            "aclImdb/train/unsup/47065_0.txt\n",
            "aclImdb/train/unsup/47064_0.txt\n",
            "aclImdb/train/unsup/47063_0.txt\n",
            "aclImdb/train/unsup/47062_0.txt\n",
            "aclImdb/train/unsup/47061_0.txt\n",
            "aclImdb/train/unsup/47060_0.txt\n",
            "aclImdb/train/unsup/47059_0.txt\n",
            "aclImdb/train/unsup/47058_0.txt\n",
            "aclImdb/train/unsup/47057_0.txt\n",
            "aclImdb/train/unsup/47056_0.txt\n",
            "aclImdb/train/unsup/47055_0.txt\n",
            "aclImdb/train/unsup/47054_0.txt\n",
            "aclImdb/train/unsup/47053_0.txt\n",
            "aclImdb/train/unsup/47052_0.txt\n",
            "aclImdb/train/unsup/47051_0.txt\n",
            "aclImdb/train/unsup/47050_0.txt\n",
            "aclImdb/train/unsup/47049_0.txt\n",
            "aclImdb/train/unsup/47048_0.txt\n",
            "aclImdb/train/unsup/47047_0.txt\n",
            "aclImdb/train/unsup/47046_0.txt\n",
            "aclImdb/train/unsup/47045_0.txt\n",
            "aclImdb/train/unsup/47044_0.txt\n",
            "aclImdb/train/unsup/47043_0.txt\n",
            "aclImdb/train/unsup/47042_0.txt\n",
            "aclImdb/train/unsup/47041_0.txt\n",
            "aclImdb/train/unsup/47040_0.txt\n",
            "aclImdb/train/unsup/47039_0.txt\n",
            "aclImdb/train/unsup/47038_0.txt\n",
            "aclImdb/train/unsup/47037_0.txt\n",
            "aclImdb/train/unsup/47036_0.txt\n",
            "aclImdb/train/unsup/47035_0.txt\n",
            "aclImdb/train/unsup/47034_0.txt\n",
            "aclImdb/train/unsup/47033_0.txt\n",
            "aclImdb/train/unsup/47032_0.txt\n",
            "aclImdb/train/unsup/47031_0.txt\n",
            "aclImdb/train/unsup/47030_0.txt\n",
            "aclImdb/train/unsup/47029_0.txt\n",
            "aclImdb/train/unsup/47028_0.txt\n",
            "aclImdb/train/unsup/47027_0.txt\n",
            "aclImdb/train/unsup/47026_0.txt\n",
            "aclImdb/train/unsup/47025_0.txt\n",
            "aclImdb/train/unsup/47024_0.txt\n",
            "aclImdb/train/unsup/47023_0.txt\n",
            "aclImdb/train/unsup/47022_0.txt\n",
            "aclImdb/train/unsup/47021_0.txt\n",
            "aclImdb/train/unsup/47020_0.txt\n",
            "aclImdb/train/unsup/47019_0.txt\n",
            "aclImdb/train/unsup/47018_0.txt\n",
            "aclImdb/train/unsup/47017_0.txt\n",
            "aclImdb/train/unsup/47016_0.txt\n",
            "aclImdb/train/unsup/47015_0.txt\n",
            "aclImdb/train/unsup/47014_0.txt\n",
            "aclImdb/train/unsup/47013_0.txt\n",
            "aclImdb/train/unsup/47012_0.txt\n",
            "aclImdb/train/unsup/47011_0.txt\n",
            "aclImdb/train/unsup/47010_0.txt\n",
            "aclImdb/train/unsup/47009_0.txt\n",
            "aclImdb/train/unsup/47008_0.txt\n",
            "aclImdb/train/unsup/47007_0.txt\n",
            "aclImdb/train/unsup/47006_0.txt\n",
            "aclImdb/train/unsup/47005_0.txt\n",
            "aclImdb/train/unsup/47004_0.txt\n",
            "aclImdb/train/unsup/47003_0.txt\n",
            "aclImdb/train/unsup/47002_0.txt\n",
            "aclImdb/train/unsup/47001_0.txt\n",
            "aclImdb/train/unsup/47000_0.txt\n",
            "aclImdb/train/unsup/46999_0.txt\n",
            "aclImdb/train/unsup/46998_0.txt\n",
            "aclImdb/train/unsup/46997_0.txt\n",
            "aclImdb/train/unsup/46996_0.txt\n",
            "aclImdb/train/unsup/46995_0.txt\n",
            "aclImdb/train/unsup/46994_0.txt\n",
            "aclImdb/train/unsup/46993_0.txt\n",
            "aclImdb/train/unsup/46992_0.txt\n",
            "aclImdb/train/unsup/46991_0.txt\n",
            "aclImdb/train/unsup/46990_0.txt\n",
            "aclImdb/train/unsup/46989_0.txt\n",
            "aclImdb/train/unsup/46988_0.txt\n",
            "aclImdb/train/unsup/46987_0.txt\n",
            "aclImdb/train/unsup/46986_0.txt\n",
            "aclImdb/train/unsup/46985_0.txt\n",
            "aclImdb/train/unsup/46984_0.txt\n",
            "aclImdb/train/unsup/46983_0.txt\n",
            "aclImdb/train/unsup/46982_0.txt\n",
            "aclImdb/train/unsup/46981_0.txt\n",
            "aclImdb/train/unsup/46980_0.txt\n",
            "aclImdb/train/unsup/46979_0.txt\n",
            "aclImdb/train/unsup/46978_0.txt\n",
            "aclImdb/train/unsup/46977_0.txt\n",
            "aclImdb/train/unsup/46976_0.txt\n",
            "aclImdb/train/unsup/47231_0.txt\n",
            "aclImdb/train/unsup/47230_0.txt\n",
            "aclImdb/train/unsup/47229_0.txt\n",
            "aclImdb/train/unsup/47228_0.txt\n",
            "aclImdb/train/unsup/47227_0.txt\n",
            "aclImdb/train/unsup/47226_0.txt\n",
            "aclImdb/train/unsup/47225_0.txt\n",
            "aclImdb/train/unsup/47224_0.txt\n",
            "aclImdb/train/unsup/47223_0.txt\n",
            "aclImdb/train/unsup/47222_0.txt\n",
            "aclImdb/train/unsup/47221_0.txt\n",
            "aclImdb/train/unsup/47220_0.txt\n",
            "aclImdb/train/unsup/47219_0.txt\n",
            "aclImdb/train/unsup/47218_0.txt\n",
            "aclImdb/train/unsup/47217_0.txt\n",
            "aclImdb/train/unsup/47216_0.txt\n",
            "aclImdb/train/unsup/47215_0.txt\n",
            "aclImdb/train/unsup/47214_0.txt\n",
            "aclImdb/train/unsup/47213_0.txt\n",
            "aclImdb/train/unsup/47212_0.txt\n",
            "aclImdb/train/unsup/47211_0.txt\n",
            "aclImdb/train/unsup/47210_0.txt\n",
            "aclImdb/train/unsup/47209_0.txt\n",
            "aclImdb/train/unsup/47208_0.txt\n",
            "aclImdb/train/unsup/47207_0.txt\n",
            "aclImdb/train/unsup/47206_0.txt\n",
            "aclImdb/train/unsup/47205_0.txt\n",
            "aclImdb/train/unsup/47204_0.txt\n",
            "aclImdb/train/unsup/47203_0.txt\n",
            "aclImdb/train/unsup/47202_0.txt\n",
            "aclImdb/train/unsup/47201_0.txt\n",
            "aclImdb/train/unsup/47200_0.txt\n",
            "aclImdb/train/unsup/47199_0.txt\n",
            "aclImdb/train/unsup/47198_0.txt\n",
            "aclImdb/train/unsup/47197_0.txt\n",
            "aclImdb/train/unsup/47196_0.txt\n",
            "aclImdb/train/unsup/47195_0.txt\n",
            "aclImdb/train/unsup/47194_0.txt\n",
            "aclImdb/train/unsup/47193_0.txt\n",
            "aclImdb/train/unsup/47192_0.txt\n",
            "aclImdb/train/unsup/47191_0.txt\n",
            "aclImdb/train/unsup/47190_0.txt\n",
            "aclImdb/train/unsup/47189_0.txt\n",
            "aclImdb/train/unsup/47188_0.txt\n",
            "aclImdb/train/unsup/47187_0.txt\n",
            "aclImdb/train/unsup/47186_0.txt\n",
            "aclImdb/train/unsup/47185_0.txt\n",
            "aclImdb/train/unsup/47184_0.txt\n",
            "aclImdb/train/unsup/47183_0.txt\n",
            "aclImdb/train/unsup/47182_0.txt\n",
            "aclImdb/train/unsup/47181_0.txt\n",
            "aclImdb/train/unsup/47180_0.txt\n",
            "aclImdb/train/unsup/47179_0.txt\n",
            "aclImdb/train/unsup/47178_0.txt\n",
            "aclImdb/train/unsup/47177_0.txt\n",
            "aclImdb/train/unsup/47176_0.txt\n",
            "aclImdb/train/unsup/47175_0.txt\n",
            "aclImdb/train/unsup/47174_0.txt\n",
            "aclImdb/train/unsup/47173_0.txt\n",
            "aclImdb/train/unsup/47172_0.txt\n",
            "aclImdb/train/unsup/47171_0.txt\n",
            "aclImdb/train/unsup/47170_0.txt\n",
            "aclImdb/train/unsup/47169_0.txt\n",
            "aclImdb/train/unsup/47168_0.txt\n",
            "aclImdb/train/unsup/47167_0.txt\n",
            "aclImdb/train/unsup/47166_0.txt\n",
            "aclImdb/train/unsup/47165_0.txt\n",
            "aclImdb/train/unsup/47164_0.txt\n",
            "aclImdb/train/unsup/47163_0.txt\n",
            "aclImdb/train/unsup/47162_0.txt\n",
            "aclImdb/train/unsup/47161_0.txt\n",
            "aclImdb/train/unsup/47160_0.txt\n",
            "aclImdb/train/unsup/47159_0.txt\n",
            "aclImdb/train/unsup/47158_0.txt\n",
            "aclImdb/train/unsup/47157_0.txt\n",
            "aclImdb/train/unsup/47156_0.txt\n",
            "aclImdb/train/unsup/47155_0.txt\n",
            "aclImdb/train/unsup/47154_0.txt\n",
            "aclImdb/train/unsup/47153_0.txt\n",
            "aclImdb/train/unsup/47152_0.txt\n",
            "aclImdb/train/unsup/47151_0.txt\n",
            "aclImdb/train/unsup/47150_0.txt\n",
            "aclImdb/train/unsup/47149_0.txt\n",
            "aclImdb/train/unsup/47148_0.txt\n",
            "aclImdb/train/unsup/47147_0.txt\n",
            "aclImdb/train/unsup/47146_0.txt\n",
            "aclImdb/train/unsup/47145_0.txt\n",
            "aclImdb/train/unsup/47144_0.txt\n",
            "aclImdb/train/unsup/47143_0.txt\n",
            "aclImdb/train/unsup/47142_0.txt\n",
            "aclImdb/train/unsup/47141_0.txt\n",
            "aclImdb/train/unsup/47140_0.txt\n",
            "aclImdb/train/unsup/47139_0.txt\n",
            "aclImdb/train/unsup/47138_0.txt\n",
            "aclImdb/train/unsup/47137_0.txt\n",
            "aclImdb/train/unsup/47136_0.txt\n",
            "aclImdb/train/unsup/47135_0.txt\n",
            "aclImdb/train/unsup/47134_0.txt\n",
            "aclImdb/train/unsup/47133_0.txt\n",
            "aclImdb/train/unsup/47132_0.txt\n",
            "aclImdb/train/unsup/47131_0.txt\n",
            "aclImdb/train/unsup/47130_0.txt\n",
            "aclImdb/train/unsup/47129_0.txt\n",
            "aclImdb/train/unsup/47128_0.txt\n",
            "aclImdb/train/unsup/47127_0.txt\n",
            "aclImdb/train/unsup/47126_0.txt\n",
            "aclImdb/train/unsup/47125_0.txt\n",
            "aclImdb/train/unsup/47124_0.txt\n",
            "aclImdb/train/unsup/47123_0.txt\n",
            "aclImdb/train/unsup/47122_0.txt\n",
            "aclImdb/train/unsup/47121_0.txt\n",
            "aclImdb/train/unsup/47120_0.txt\n",
            "aclImdb/train/unsup/47119_0.txt\n",
            "aclImdb/train/unsup/47118_0.txt\n",
            "aclImdb/train/unsup/47117_0.txt\n",
            "aclImdb/train/unsup/47116_0.txt\n",
            "aclImdb/train/unsup/47115_0.txt\n",
            "aclImdb/train/unsup/47114_0.txt\n",
            "aclImdb/train/unsup/47113_0.txt\n",
            "aclImdb/train/unsup/47112_0.txt\n",
            "aclImdb/train/unsup/47111_0.txt\n",
            "aclImdb/train/unsup/47110_0.txt\n",
            "aclImdb/train/unsup/47109_0.txt\n",
            "aclImdb/train/unsup/47108_0.txt\n",
            "aclImdb/train/unsup/47107_0.txt\n",
            "aclImdb/train/unsup/47106_0.txt\n",
            "aclImdb/train/unsup/47105_0.txt\n",
            "aclImdb/train/unsup/47104_0.txt\n",
            "aclImdb/train/unsup/47359_0.txt\n",
            "aclImdb/train/unsup/47358_0.txt\n",
            "aclImdb/train/unsup/47357_0.txt\n",
            "aclImdb/train/unsup/47356_0.txt\n",
            "aclImdb/train/unsup/47355_0.txt\n",
            "aclImdb/train/unsup/47354_0.txt\n",
            "aclImdb/train/unsup/47353_0.txt\n",
            "aclImdb/train/unsup/47352_0.txt\n",
            "aclImdb/train/unsup/47351_0.txt\n",
            "aclImdb/train/unsup/47350_0.txt\n",
            "aclImdb/train/unsup/47349_0.txt\n",
            "aclImdb/train/unsup/47348_0.txt\n",
            "aclImdb/train/unsup/47347_0.txt\n",
            "aclImdb/train/unsup/47346_0.txt\n",
            "aclImdb/train/unsup/47345_0.txt\n",
            "aclImdb/train/unsup/47344_0.txt\n",
            "aclImdb/train/unsup/47343_0.txt\n",
            "aclImdb/train/unsup/47342_0.txt\n",
            "aclImdb/train/unsup/47341_0.txt\n",
            "aclImdb/train/unsup/47340_0.txt\n",
            "aclImdb/train/unsup/47339_0.txt\n",
            "aclImdb/train/unsup/47338_0.txt\n",
            "aclImdb/train/unsup/47337_0.txt\n",
            "aclImdb/train/unsup/47336_0.txt\n",
            "aclImdb/train/unsup/47335_0.txt\n",
            "aclImdb/train/unsup/47334_0.txt\n",
            "aclImdb/train/unsup/47333_0.txt\n",
            "aclImdb/train/unsup/47332_0.txt\n",
            "aclImdb/train/unsup/47331_0.txt\n",
            "aclImdb/train/unsup/47330_0.txt\n",
            "aclImdb/train/unsup/47329_0.txt\n",
            "aclImdb/train/unsup/47328_0.txt\n",
            "aclImdb/train/unsup/47327_0.txt\n",
            "aclImdb/train/unsup/47326_0.txt\n",
            "aclImdb/train/unsup/47325_0.txt\n",
            "aclImdb/train/unsup/47324_0.txt\n",
            "aclImdb/train/unsup/47323_0.txt\n",
            "aclImdb/train/unsup/47322_0.txt\n",
            "aclImdb/train/unsup/47321_0.txt\n",
            "aclImdb/train/unsup/47320_0.txt\n",
            "aclImdb/train/unsup/47319_0.txt\n",
            "aclImdb/train/unsup/47318_0.txt\n",
            "aclImdb/train/unsup/47317_0.txt\n",
            "aclImdb/train/unsup/47316_0.txt\n",
            "aclImdb/train/unsup/47315_0.txt\n",
            "aclImdb/train/unsup/47314_0.txt\n",
            "aclImdb/train/unsup/47313_0.txt\n",
            "aclImdb/train/unsup/47312_0.txt\n",
            "aclImdb/train/unsup/47311_0.txt\n",
            "aclImdb/train/unsup/47310_0.txt\n",
            "aclImdb/train/unsup/47309_0.txt\n",
            "aclImdb/train/unsup/47308_0.txt\n",
            "aclImdb/train/unsup/47307_0.txt\n",
            "aclImdb/train/unsup/47306_0.txt\n",
            "aclImdb/train/unsup/47305_0.txt\n",
            "aclImdb/train/unsup/47304_0.txt\n",
            "aclImdb/train/unsup/47303_0.txt\n",
            "aclImdb/train/unsup/47302_0.txt\n",
            "aclImdb/train/unsup/47301_0.txt\n",
            "aclImdb/train/unsup/47300_0.txt\n",
            "aclImdb/train/unsup/47299_0.txt\n",
            "aclImdb/train/unsup/47298_0.txt\n",
            "aclImdb/train/unsup/47297_0.txt\n",
            "aclImdb/train/unsup/47296_0.txt\n",
            "aclImdb/train/unsup/47295_0.txt\n",
            "aclImdb/train/unsup/47294_0.txt\n",
            "aclImdb/train/unsup/47293_0.txt\n",
            "aclImdb/train/unsup/47292_0.txt\n",
            "aclImdb/train/unsup/47291_0.txt\n",
            "aclImdb/train/unsup/47290_0.txt\n",
            "aclImdb/train/unsup/47289_0.txt\n",
            "aclImdb/train/unsup/47288_0.txt\n",
            "aclImdb/train/unsup/47287_0.txt\n",
            "aclImdb/train/unsup/47286_0.txt\n",
            "aclImdb/train/unsup/47285_0.txt\n",
            "aclImdb/train/unsup/47284_0.txt\n",
            "aclImdb/train/unsup/47283_0.txt\n",
            "aclImdb/train/unsup/47282_0.txt\n",
            "aclImdb/train/unsup/47281_0.txt\n",
            "aclImdb/train/unsup/47280_0.txt\n",
            "aclImdb/train/unsup/47279_0.txt\n",
            "aclImdb/train/unsup/47278_0.txt\n",
            "aclImdb/train/unsup/47277_0.txt\n",
            "aclImdb/train/unsup/47276_0.txt\n",
            "aclImdb/train/unsup/47275_0.txt\n",
            "aclImdb/train/unsup/47274_0.txt\n",
            "aclImdb/train/unsup/47273_0.txt\n",
            "aclImdb/train/unsup/47272_0.txt\n",
            "aclImdb/train/unsup/47271_0.txt\n",
            "aclImdb/train/unsup/47270_0.txt\n",
            "aclImdb/train/unsup/47269_0.txt\n",
            "aclImdb/train/unsup/47268_0.txt\n",
            "aclImdb/train/unsup/47267_0.txt\n",
            "aclImdb/train/unsup/47266_0.txt\n",
            "aclImdb/train/unsup/47265_0.txt\n",
            "aclImdb/train/unsup/47264_0.txt\n",
            "aclImdb/train/unsup/47263_0.txt\n",
            "aclImdb/train/unsup/47262_0.txt\n",
            "aclImdb/train/unsup/47261_0.txt\n",
            "aclImdb/train/unsup/47260_0.txt\n",
            "aclImdb/train/unsup/47259_0.txt\n",
            "aclImdb/train/unsup/47258_0.txt\n",
            "aclImdb/train/unsup/47257_0.txt\n",
            "aclImdb/train/unsup/47256_0.txt\n",
            "aclImdb/train/unsup/47255_0.txt\n",
            "aclImdb/train/unsup/47254_0.txt\n",
            "aclImdb/train/unsup/47253_0.txt\n",
            "aclImdb/train/unsup/47252_0.txt\n",
            "aclImdb/train/unsup/47251_0.txt\n",
            "aclImdb/train/unsup/47250_0.txt\n",
            "aclImdb/train/unsup/47249_0.txt\n",
            "aclImdb/train/unsup/47248_0.txt\n",
            "aclImdb/train/unsup/47247_0.txt\n",
            "aclImdb/train/unsup/47246_0.txt\n",
            "aclImdb/train/unsup/47245_0.txt\n",
            "aclImdb/train/unsup/47244_0.txt\n",
            "aclImdb/train/unsup/47243_0.txt\n",
            "aclImdb/train/unsup/47242_0.txt\n",
            "aclImdb/train/unsup/47241_0.txt\n",
            "aclImdb/train/unsup/47240_0.txt\n",
            "aclImdb/train/unsup/47239_0.txt\n",
            "aclImdb/train/unsup/47238_0.txt\n",
            "aclImdb/train/unsup/47237_0.txt\n",
            "aclImdb/train/unsup/47236_0.txt\n",
            "aclImdb/train/unsup/47235_0.txt\n",
            "aclImdb/train/unsup/47234_0.txt\n",
            "aclImdb/train/unsup/47233_0.txt\n",
            "aclImdb/train/unsup/47232_0.txt\n",
            "aclImdb/train/unsup/47487_0.txt\n",
            "aclImdb/train/unsup/47486_0.txt\n",
            "aclImdb/train/unsup/47485_0.txt\n",
            "aclImdb/train/unsup/47484_0.txt\n",
            "aclImdb/train/unsup/47483_0.txt\n",
            "aclImdb/train/unsup/47482_0.txt\n",
            "aclImdb/train/unsup/47481_0.txt\n",
            "aclImdb/train/unsup/47480_0.txt\n",
            "aclImdb/train/unsup/47479_0.txt\n",
            "aclImdb/train/unsup/47478_0.txt\n",
            "aclImdb/train/unsup/47477_0.txt\n",
            "aclImdb/train/unsup/47476_0.txt\n",
            "aclImdb/train/unsup/47475_0.txt\n",
            "aclImdb/train/unsup/47474_0.txt\n",
            "aclImdb/train/unsup/47473_0.txt\n",
            "aclImdb/train/unsup/47472_0.txt\n",
            "aclImdb/train/unsup/47471_0.txt\n",
            "aclImdb/train/unsup/47470_0.txt\n",
            "aclImdb/train/unsup/47469_0.txt\n",
            "aclImdb/train/unsup/47468_0.txt\n",
            "aclImdb/train/unsup/47467_0.txt\n",
            "aclImdb/train/unsup/47466_0.txt\n",
            "aclImdb/train/unsup/47465_0.txt\n",
            "aclImdb/train/unsup/47464_0.txt\n",
            "aclImdb/train/unsup/47463_0.txt\n",
            "aclImdb/train/unsup/47462_0.txt\n",
            "aclImdb/train/unsup/47461_0.txt\n",
            "aclImdb/train/unsup/47460_0.txt\n",
            "aclImdb/train/unsup/47459_0.txt\n",
            "aclImdb/train/unsup/47458_0.txt\n",
            "aclImdb/train/unsup/47457_0.txt\n",
            "aclImdb/train/unsup/47456_0.txt\n",
            "aclImdb/train/unsup/47455_0.txt\n",
            "aclImdb/train/unsup/47454_0.txt\n",
            "aclImdb/train/unsup/47453_0.txt\n",
            "aclImdb/train/unsup/47452_0.txt\n",
            "aclImdb/train/unsup/47451_0.txt\n",
            "aclImdb/train/unsup/47450_0.txt\n",
            "aclImdb/train/unsup/47449_0.txt\n",
            "aclImdb/train/unsup/47448_0.txt\n",
            "aclImdb/train/unsup/47447_0.txt\n",
            "aclImdb/train/unsup/47446_0.txt\n",
            "aclImdb/train/unsup/47445_0.txt\n",
            "aclImdb/train/unsup/47444_0.txt\n",
            "aclImdb/train/unsup/47443_0.txt\n",
            "aclImdb/train/unsup/47442_0.txt\n",
            "aclImdb/train/unsup/47441_0.txt\n",
            "aclImdb/train/unsup/47440_0.txt\n",
            "aclImdb/train/unsup/47439_0.txt\n",
            "aclImdb/train/unsup/47438_0.txt\n",
            "aclImdb/train/unsup/47437_0.txt\n",
            "aclImdb/train/unsup/47436_0.txt\n",
            "aclImdb/train/unsup/47435_0.txt\n",
            "aclImdb/train/unsup/47434_0.txt\n",
            "aclImdb/train/unsup/47433_0.txt\n",
            "aclImdb/train/unsup/47432_0.txt\n",
            "aclImdb/train/unsup/47431_0.txt\n",
            "aclImdb/train/unsup/47430_0.txt\n",
            "aclImdb/train/unsup/47429_0.txt\n",
            "aclImdb/train/unsup/47428_0.txt\n",
            "aclImdb/train/unsup/47427_0.txt\n",
            "aclImdb/train/unsup/47426_0.txt\n",
            "aclImdb/train/unsup/47425_0.txt\n",
            "aclImdb/train/unsup/47424_0.txt\n",
            "aclImdb/train/unsup/47423_0.txt\n",
            "aclImdb/train/unsup/47422_0.txt\n",
            "aclImdb/train/unsup/47421_0.txt\n",
            "aclImdb/train/unsup/47420_0.txt\n",
            "aclImdb/train/unsup/47419_0.txt\n",
            "aclImdb/train/unsup/47418_0.txt\n",
            "aclImdb/train/unsup/47417_0.txt\n",
            "aclImdb/train/unsup/47416_0.txt\n",
            "aclImdb/train/unsup/47415_0.txt\n",
            "aclImdb/train/unsup/47414_0.txt\n",
            "aclImdb/train/unsup/47413_0.txt\n",
            "aclImdb/train/unsup/47412_0.txt\n",
            "aclImdb/train/unsup/47411_0.txt\n",
            "aclImdb/train/unsup/47410_0.txt\n",
            "aclImdb/train/unsup/47409_0.txt\n",
            "aclImdb/train/unsup/47408_0.txt\n",
            "aclImdb/train/unsup/47407_0.txt\n",
            "aclImdb/train/unsup/47406_0.txt\n",
            "aclImdb/train/unsup/47405_0.txt\n",
            "aclImdb/train/unsup/47404_0.txt\n",
            "aclImdb/train/unsup/47403_0.txt\n",
            "aclImdb/train/unsup/47402_0.txt\n",
            "aclImdb/train/unsup/47401_0.txt\n",
            "aclImdb/train/unsup/47400_0.txt\n",
            "aclImdb/train/unsup/47399_0.txt\n",
            "aclImdb/train/unsup/47398_0.txt\n",
            "aclImdb/train/unsup/47397_0.txt\n",
            "aclImdb/train/unsup/47396_0.txt\n",
            "aclImdb/train/unsup/47395_0.txt\n",
            "aclImdb/train/unsup/47394_0.txt\n",
            "aclImdb/train/unsup/47393_0.txt\n",
            "aclImdb/train/unsup/47392_0.txt\n",
            "aclImdb/train/unsup/47391_0.txt\n",
            "aclImdb/train/unsup/47390_0.txt\n",
            "aclImdb/train/unsup/47389_0.txt\n",
            "aclImdb/train/unsup/47388_0.txt\n",
            "aclImdb/train/unsup/47387_0.txt\n",
            "aclImdb/train/unsup/47386_0.txt\n",
            "aclImdb/train/unsup/47385_0.txt\n",
            "aclImdb/train/unsup/47384_0.txt\n",
            "aclImdb/train/unsup/47383_0.txt\n",
            "aclImdb/train/unsup/47382_0.txt\n",
            "aclImdb/train/unsup/47381_0.txt\n",
            "aclImdb/train/unsup/47380_0.txt\n",
            "aclImdb/train/unsup/47379_0.txt\n",
            "aclImdb/train/unsup/47378_0.txt\n",
            "aclImdb/train/unsup/47377_0.txt\n",
            "aclImdb/train/unsup/47376_0.txt\n",
            "aclImdb/train/unsup/47375_0.txt\n",
            "aclImdb/train/unsup/47374_0.txt\n",
            "aclImdb/train/unsup/47373_0.txt\n",
            "aclImdb/train/unsup/47372_0.txt\n",
            "aclImdb/train/unsup/47371_0.txt\n",
            "aclImdb/train/unsup/47370_0.txt\n",
            "aclImdb/train/unsup/47369_0.txt\n",
            "aclImdb/train/unsup/47368_0.txt\n",
            "aclImdb/train/unsup/47367_0.txt\n",
            "aclImdb/train/unsup/47366_0.txt\n",
            "aclImdb/train/unsup/47365_0.txt\n",
            "aclImdb/train/unsup/47364_0.txt\n",
            "aclImdb/train/unsup/47363_0.txt\n",
            "aclImdb/train/unsup/47362_0.txt\n",
            "aclImdb/train/unsup/47361_0.txt\n",
            "aclImdb/train/unsup/47360_0.txt\n",
            "aclImdb/train/unsup/47615_0.txt\n",
            "aclImdb/train/unsup/47614_0.txt\n",
            "aclImdb/train/unsup/47613_0.txt\n",
            "aclImdb/train/unsup/47612_0.txt\n",
            "aclImdb/train/unsup/47611_0.txt\n",
            "aclImdb/train/unsup/47610_0.txt\n",
            "aclImdb/train/unsup/47609_0.txt\n",
            "aclImdb/train/unsup/47608_0.txt\n",
            "aclImdb/train/unsup/47607_0.txt\n",
            "aclImdb/train/unsup/47606_0.txt\n",
            "aclImdb/train/unsup/47605_0.txt\n",
            "aclImdb/train/unsup/47604_0.txt\n",
            "aclImdb/train/unsup/47603_0.txt\n",
            "aclImdb/train/unsup/47602_0.txt\n",
            "aclImdb/train/unsup/47601_0.txt\n",
            "aclImdb/train/unsup/47600_0.txt\n",
            "aclImdb/train/unsup/47599_0.txt\n",
            "aclImdb/train/unsup/47598_0.txt\n",
            "aclImdb/train/unsup/47597_0.txt\n",
            "aclImdb/train/unsup/47596_0.txt\n",
            "aclImdb/train/unsup/47595_0.txt\n",
            "aclImdb/train/unsup/47594_0.txt\n",
            "aclImdb/train/unsup/47593_0.txt\n",
            "aclImdb/train/unsup/47592_0.txt\n",
            "aclImdb/train/unsup/47591_0.txt\n",
            "aclImdb/train/unsup/47590_0.txt\n",
            "aclImdb/train/unsup/47589_0.txt\n",
            "aclImdb/train/unsup/47588_0.txt\n",
            "aclImdb/train/unsup/47587_0.txt\n",
            "aclImdb/train/unsup/47586_0.txt\n",
            "aclImdb/train/unsup/47585_0.txt\n",
            "aclImdb/train/unsup/47584_0.txt\n",
            "aclImdb/train/unsup/47583_0.txt\n",
            "aclImdb/train/unsup/47582_0.txt\n",
            "aclImdb/train/unsup/47581_0.txt\n",
            "aclImdb/train/unsup/47580_0.txt\n",
            "aclImdb/train/unsup/47579_0.txt\n",
            "aclImdb/train/unsup/47578_0.txt\n",
            "aclImdb/train/unsup/47577_0.txt\n",
            "aclImdb/train/unsup/47576_0.txt\n",
            "aclImdb/train/unsup/47575_0.txt\n",
            "aclImdb/train/unsup/47574_0.txt\n",
            "aclImdb/train/unsup/47573_0.txt\n",
            "aclImdb/train/unsup/47572_0.txt\n",
            "aclImdb/train/unsup/47571_0.txt\n",
            "aclImdb/train/unsup/47570_0.txt\n",
            "aclImdb/train/unsup/47569_0.txt\n",
            "aclImdb/train/unsup/47568_0.txt\n",
            "aclImdb/train/unsup/47567_0.txt\n",
            "aclImdb/train/unsup/47566_0.txt\n",
            "aclImdb/train/unsup/47565_0.txt\n",
            "aclImdb/train/unsup/47564_0.txt\n",
            "aclImdb/train/unsup/47563_0.txt\n",
            "aclImdb/train/unsup/47562_0.txt\n",
            "aclImdb/train/unsup/47561_0.txt\n",
            "aclImdb/train/unsup/47560_0.txt\n",
            "aclImdb/train/unsup/47559_0.txt\n",
            "aclImdb/train/unsup/47558_0.txt\n",
            "aclImdb/train/unsup/47557_0.txt\n",
            "aclImdb/train/unsup/47556_0.txt\n",
            "aclImdb/train/unsup/47555_0.txt\n",
            "aclImdb/train/unsup/47554_0.txt\n",
            "aclImdb/train/unsup/47553_0.txt\n",
            "aclImdb/train/unsup/47552_0.txt\n",
            "aclImdb/train/unsup/47551_0.txt\n",
            "aclImdb/train/unsup/47550_0.txt\n",
            "aclImdb/train/unsup/47549_0.txt\n",
            "aclImdb/train/unsup/47548_0.txt\n",
            "aclImdb/train/unsup/47547_0.txt\n",
            "aclImdb/train/unsup/47546_0.txt\n",
            "aclImdb/train/unsup/47545_0.txt\n",
            "aclImdb/train/unsup/47544_0.txt\n",
            "aclImdb/train/unsup/47543_0.txt\n",
            "aclImdb/train/unsup/47542_0.txt\n",
            "aclImdb/train/unsup/47541_0.txt\n",
            "aclImdb/train/unsup/47540_0.txt\n",
            "aclImdb/train/unsup/47539_0.txt\n",
            "aclImdb/train/unsup/47538_0.txt\n",
            "aclImdb/train/unsup/47537_0.txt\n",
            "aclImdb/train/unsup/47536_0.txt\n",
            "aclImdb/train/unsup/47535_0.txt\n",
            "aclImdb/train/unsup/47534_0.txt\n",
            "aclImdb/train/unsup/47533_0.txt\n",
            "aclImdb/train/unsup/47532_0.txt\n",
            "aclImdb/train/unsup/47531_0.txt\n",
            "aclImdb/train/unsup/47530_0.txt\n",
            "aclImdb/train/unsup/47529_0.txt\n",
            "aclImdb/train/unsup/47528_0.txt\n",
            "aclImdb/train/unsup/47527_0.txt\n",
            "aclImdb/train/unsup/47526_0.txt\n",
            "aclImdb/train/unsup/47525_0.txt\n",
            "aclImdb/train/unsup/47524_0.txt\n",
            "aclImdb/train/unsup/47523_0.txt\n",
            "aclImdb/train/unsup/47522_0.txt\n",
            "aclImdb/train/unsup/47521_0.txt\n",
            "aclImdb/train/unsup/47520_0.txt\n",
            "aclImdb/train/unsup/47519_0.txt\n",
            "aclImdb/train/unsup/47518_0.txt\n",
            "aclImdb/train/unsup/47517_0.txt\n",
            "aclImdb/train/unsup/47516_0.txt\n",
            "aclImdb/train/unsup/47515_0.txt\n",
            "aclImdb/train/unsup/47514_0.txt\n",
            "aclImdb/train/unsup/47513_0.txt\n",
            "aclImdb/train/unsup/47512_0.txt\n",
            "aclImdb/train/unsup/47511_0.txt\n",
            "aclImdb/train/unsup/47510_0.txt\n",
            "aclImdb/train/unsup/47509_0.txt\n",
            "aclImdb/train/unsup/47508_0.txt\n",
            "aclImdb/train/unsup/47507_0.txt\n",
            "aclImdb/train/unsup/47506_0.txt\n",
            "aclImdb/train/unsup/47505_0.txt\n",
            "aclImdb/train/unsup/47504_0.txt\n",
            "aclImdb/train/unsup/47503_0.txt\n",
            "aclImdb/train/unsup/47502_0.txt\n",
            "aclImdb/train/unsup/47501_0.txt\n",
            "aclImdb/train/unsup/47500_0.txt\n",
            "aclImdb/train/unsup/47499_0.txt\n",
            "aclImdb/train/unsup/47498_0.txt\n",
            "aclImdb/train/unsup/47497_0.txt\n",
            "aclImdb/train/unsup/47496_0.txt\n",
            "aclImdb/train/unsup/47495_0.txt\n",
            "aclImdb/train/unsup/47494_0.txt\n",
            "aclImdb/train/unsup/47493_0.txt\n",
            "aclImdb/train/unsup/47492_0.txt\n",
            "aclImdb/train/unsup/47491_0.txt\n",
            "aclImdb/train/unsup/47490_0.txt\n",
            "aclImdb/train/unsup/47489_0.txt\n",
            "aclImdb/train/unsup/47488_0.txt\n",
            "aclImdb/train/unsup/47743_0.txt\n",
            "aclImdb/train/unsup/47742_0.txt\n",
            "aclImdb/train/unsup/47741_0.txt\n",
            "aclImdb/train/unsup/47740_0.txt\n",
            "aclImdb/train/unsup/47739_0.txt\n",
            "aclImdb/train/unsup/47738_0.txt\n",
            "aclImdb/train/unsup/47737_0.txt\n",
            "aclImdb/train/unsup/47736_0.txt\n",
            "aclImdb/train/unsup/47735_0.txt\n",
            "aclImdb/train/unsup/47734_0.txt\n",
            "aclImdb/train/unsup/47733_0.txt\n",
            "aclImdb/train/unsup/47732_0.txt\n",
            "aclImdb/train/unsup/47731_0.txt\n",
            "aclImdb/train/unsup/47730_0.txt\n",
            "aclImdb/train/unsup/47729_0.txt\n",
            "aclImdb/train/unsup/47728_0.txt\n",
            "aclImdb/train/unsup/47727_0.txt\n",
            "aclImdb/train/unsup/47726_0.txt\n",
            "aclImdb/train/unsup/47725_0.txt\n",
            "aclImdb/train/unsup/47724_0.txt\n",
            "aclImdb/train/unsup/47723_0.txt\n",
            "aclImdb/train/unsup/47722_0.txt\n",
            "aclImdb/train/unsup/47721_0.txt\n",
            "aclImdb/train/unsup/47720_0.txt\n",
            "aclImdb/train/unsup/47719_0.txt\n",
            "aclImdb/train/unsup/47718_0.txt\n",
            "aclImdb/train/unsup/47717_0.txt\n",
            "aclImdb/train/unsup/47716_0.txt\n",
            "aclImdb/train/unsup/47715_0.txt\n",
            "aclImdb/train/unsup/47714_0.txt\n",
            "aclImdb/train/unsup/47713_0.txt\n",
            "aclImdb/train/unsup/47712_0.txt\n",
            "aclImdb/train/unsup/47711_0.txt\n",
            "aclImdb/train/unsup/47710_0.txt\n",
            "aclImdb/train/unsup/47709_0.txt\n",
            "aclImdb/train/unsup/47708_0.txt\n",
            "aclImdb/train/unsup/47707_0.txt\n",
            "aclImdb/train/unsup/47706_0.txt\n",
            "aclImdb/train/unsup/47705_0.txt\n",
            "aclImdb/train/unsup/47704_0.txt\n",
            "aclImdb/train/unsup/47703_0.txt\n",
            "aclImdb/train/unsup/47702_0.txt\n",
            "aclImdb/train/unsup/47701_0.txt\n",
            "aclImdb/train/unsup/47700_0.txt\n",
            "aclImdb/train/unsup/47699_0.txt\n",
            "aclImdb/train/unsup/47698_0.txt\n",
            "aclImdb/train/unsup/47697_0.txt\n",
            "aclImdb/train/unsup/47696_0.txt\n",
            "aclImdb/train/unsup/47695_0.txt\n",
            "aclImdb/train/unsup/47694_0.txt\n",
            "aclImdb/train/unsup/47693_0.txt\n",
            "aclImdb/train/unsup/47692_0.txt\n",
            "aclImdb/train/unsup/47691_0.txt\n",
            "aclImdb/train/unsup/47690_0.txt\n",
            "aclImdb/train/unsup/47689_0.txt\n",
            "aclImdb/train/unsup/47688_0.txt\n",
            "aclImdb/train/unsup/47687_0.txt\n",
            "aclImdb/train/unsup/47686_0.txt\n",
            "aclImdb/train/unsup/47685_0.txt\n",
            "aclImdb/train/unsup/47684_0.txt\n",
            "aclImdb/train/unsup/47683_0.txt\n",
            "aclImdb/train/unsup/47682_0.txt\n",
            "aclImdb/train/unsup/47681_0.txt\n",
            "aclImdb/train/unsup/47680_0.txt\n",
            "aclImdb/train/unsup/47679_0.txt\n",
            "aclImdb/train/unsup/47678_0.txt\n",
            "aclImdb/train/unsup/47677_0.txt\n",
            "aclImdb/train/unsup/47676_0.txt\n",
            "aclImdb/train/unsup/47675_0.txt\n",
            "aclImdb/train/unsup/47674_0.txt\n",
            "aclImdb/train/unsup/47673_0.txt\n",
            "aclImdb/train/unsup/47672_0.txt\n",
            "aclImdb/train/unsup/47671_0.txt\n",
            "aclImdb/train/unsup/47670_0.txt\n",
            "aclImdb/train/unsup/47669_0.txt\n",
            "aclImdb/train/unsup/47668_0.txt\n",
            "aclImdb/train/unsup/47667_0.txt\n",
            "aclImdb/train/unsup/47666_0.txt\n",
            "aclImdb/train/unsup/47665_0.txt\n",
            "aclImdb/train/unsup/47664_0.txt\n",
            "aclImdb/train/unsup/47663_0.txt\n",
            "aclImdb/train/unsup/47662_0.txt\n",
            "aclImdb/train/unsup/47661_0.txt\n",
            "aclImdb/train/unsup/47660_0.txt\n",
            "aclImdb/train/unsup/47659_0.txt\n",
            "aclImdb/train/unsup/47658_0.txt\n",
            "aclImdb/train/unsup/47657_0.txt\n",
            "aclImdb/train/unsup/47656_0.txt\n",
            "aclImdb/train/unsup/47655_0.txt\n",
            "aclImdb/train/unsup/47654_0.txt\n",
            "aclImdb/train/unsup/47653_0.txt\n",
            "aclImdb/train/unsup/47652_0.txt\n",
            "aclImdb/train/unsup/47651_0.txt\n",
            "aclImdb/train/unsup/47650_0.txt\n",
            "aclImdb/train/unsup/47649_0.txt\n",
            "aclImdb/train/unsup/47648_0.txt\n",
            "aclImdb/train/unsup/47647_0.txt\n",
            "aclImdb/train/unsup/47646_0.txt\n",
            "aclImdb/train/unsup/47645_0.txt\n",
            "aclImdb/train/unsup/47644_0.txt\n",
            "aclImdb/train/unsup/47643_0.txt\n",
            "aclImdb/train/unsup/47642_0.txt\n",
            "aclImdb/train/unsup/47641_0.txt\n",
            "aclImdb/train/unsup/47640_0.txt\n",
            "aclImdb/train/unsup/47639_0.txt\n",
            "aclImdb/train/unsup/47638_0.txt\n",
            "aclImdb/train/unsup/47637_0.txt\n",
            "aclImdb/train/unsup/47636_0.txt\n",
            "aclImdb/train/unsup/47635_0.txt\n",
            "aclImdb/train/unsup/47634_0.txt\n",
            "aclImdb/train/unsup/47633_0.txt\n",
            "aclImdb/train/unsup/47632_0.txt\n",
            "aclImdb/train/unsup/47631_0.txt\n",
            "aclImdb/train/unsup/47630_0.txt\n",
            "aclImdb/train/unsup/47629_0.txt\n",
            "aclImdb/train/unsup/47628_0.txt\n",
            "aclImdb/train/unsup/47627_0.txt\n",
            "aclImdb/train/unsup/47626_0.txt\n",
            "aclImdb/train/unsup/47625_0.txt\n",
            "aclImdb/train/unsup/47624_0.txt\n",
            "aclImdb/train/unsup/47623_0.txt\n",
            "aclImdb/train/unsup/47622_0.txt\n",
            "aclImdb/train/unsup/47621_0.txt\n",
            "aclImdb/train/unsup/47620_0.txt\n",
            "aclImdb/train/unsup/47619_0.txt\n",
            "aclImdb/train/unsup/47618_0.txt\n",
            "aclImdb/train/unsup/47617_0.txt\n",
            "aclImdb/train/unsup/47616_0.txt\n",
            "aclImdb/train/unsup/47871_0.txt\n",
            "aclImdb/train/unsup/47870_0.txt\n",
            "aclImdb/train/unsup/47869_0.txt\n",
            "aclImdb/train/unsup/47868_0.txt\n",
            "aclImdb/train/unsup/47867_0.txt\n",
            "aclImdb/train/unsup/47866_0.txt\n",
            "aclImdb/train/unsup/47865_0.txt\n",
            "aclImdb/train/unsup/47864_0.txt\n",
            "aclImdb/train/unsup/47863_0.txt\n",
            "aclImdb/train/unsup/47862_0.txt\n",
            "aclImdb/train/unsup/47861_0.txt\n",
            "aclImdb/train/unsup/47860_0.txt\n",
            "aclImdb/train/unsup/47859_0.txt\n",
            "aclImdb/train/unsup/47858_0.txt\n",
            "aclImdb/train/unsup/47857_0.txt\n",
            "aclImdb/train/unsup/47856_0.txt\n",
            "aclImdb/train/unsup/47855_0.txt\n",
            "aclImdb/train/unsup/47854_0.txt\n",
            "aclImdb/train/unsup/47853_0.txt\n",
            "aclImdb/train/unsup/47852_0.txt\n",
            "aclImdb/train/unsup/47851_0.txt\n",
            "aclImdb/train/unsup/47850_0.txt\n",
            "aclImdb/train/unsup/47849_0.txt\n",
            "aclImdb/train/unsup/47848_0.txt\n",
            "aclImdb/train/unsup/47847_0.txt\n",
            "aclImdb/train/unsup/47846_0.txt\n",
            "aclImdb/train/unsup/47845_0.txt\n",
            "aclImdb/train/unsup/47844_0.txt\n",
            "aclImdb/train/unsup/47843_0.txt\n",
            "aclImdb/train/unsup/47842_0.txt\n",
            "aclImdb/train/unsup/47841_0.txt\n",
            "aclImdb/train/unsup/47840_0.txt\n",
            "aclImdb/train/unsup/47839_0.txt\n",
            "aclImdb/train/unsup/47838_0.txt\n",
            "aclImdb/train/unsup/47837_0.txt\n",
            "aclImdb/train/unsup/47836_0.txt\n",
            "aclImdb/train/unsup/47835_0.txt\n",
            "aclImdb/train/unsup/47834_0.txt\n",
            "aclImdb/train/unsup/47833_0.txt\n",
            "aclImdb/train/unsup/47832_0.txt\n",
            "aclImdb/train/unsup/47831_0.txt\n",
            "aclImdb/train/unsup/47830_0.txt\n",
            "aclImdb/train/unsup/47829_0.txt\n",
            "aclImdb/train/unsup/47828_0.txt\n",
            "aclImdb/train/unsup/47827_0.txt\n",
            "aclImdb/train/unsup/47826_0.txt\n",
            "aclImdb/train/unsup/47825_0.txt\n",
            "aclImdb/train/unsup/47824_0.txt\n",
            "aclImdb/train/unsup/47823_0.txt\n",
            "aclImdb/train/unsup/47822_0.txt\n",
            "aclImdb/train/unsup/47821_0.txt\n",
            "aclImdb/train/unsup/47820_0.txt\n",
            "aclImdb/train/unsup/47819_0.txt\n",
            "aclImdb/train/unsup/47818_0.txt\n",
            "aclImdb/train/unsup/47817_0.txt\n",
            "aclImdb/train/unsup/47816_0.txt\n",
            "aclImdb/train/unsup/47815_0.txt\n",
            "aclImdb/train/unsup/47814_0.txt\n",
            "aclImdb/train/unsup/47813_0.txt\n",
            "aclImdb/train/unsup/47812_0.txt\n",
            "aclImdb/train/unsup/47811_0.txt\n",
            "aclImdb/train/unsup/47810_0.txt\n",
            "aclImdb/train/unsup/47809_0.txt\n",
            "aclImdb/train/unsup/47808_0.txt\n",
            "aclImdb/train/unsup/47807_0.txt\n",
            "aclImdb/train/unsup/47806_0.txt\n",
            "aclImdb/train/unsup/47805_0.txt\n",
            "aclImdb/train/unsup/47804_0.txt\n",
            "aclImdb/train/unsup/47803_0.txt\n",
            "aclImdb/train/unsup/47802_0.txt\n",
            "aclImdb/train/unsup/47801_0.txt\n",
            "aclImdb/train/unsup/47800_0.txt\n",
            "aclImdb/train/unsup/47799_0.txt\n",
            "aclImdb/train/unsup/47798_0.txt\n",
            "aclImdb/train/unsup/47797_0.txt\n",
            "aclImdb/train/unsup/47796_0.txt\n",
            "aclImdb/train/unsup/47795_0.txt\n",
            "aclImdb/train/unsup/47794_0.txt\n",
            "aclImdb/train/unsup/47793_0.txt\n",
            "aclImdb/train/unsup/47792_0.txt\n",
            "aclImdb/train/unsup/47791_0.txt\n",
            "aclImdb/train/unsup/47790_0.txt\n",
            "aclImdb/train/unsup/47789_0.txt\n",
            "aclImdb/train/unsup/47788_0.txt\n",
            "aclImdb/train/unsup/47787_0.txt\n",
            "aclImdb/train/unsup/47786_0.txt\n",
            "aclImdb/train/unsup/47785_0.txt\n",
            "aclImdb/train/unsup/47784_0.txt\n",
            "aclImdb/train/unsup/47783_0.txt\n",
            "aclImdb/train/unsup/47782_0.txt\n",
            "aclImdb/train/unsup/47781_0.txt\n",
            "aclImdb/train/unsup/47780_0.txt\n",
            "aclImdb/train/unsup/47779_0.txt\n",
            "aclImdb/train/unsup/47778_0.txt\n",
            "aclImdb/train/unsup/47777_0.txt\n",
            "aclImdb/train/unsup/47776_0.txt\n",
            "aclImdb/train/unsup/47775_0.txt\n",
            "aclImdb/train/unsup/47774_0.txt\n",
            "aclImdb/train/unsup/47773_0.txt\n",
            "aclImdb/train/unsup/47772_0.txt\n",
            "aclImdb/train/unsup/47771_0.txt\n",
            "aclImdb/train/unsup/47770_0.txt\n",
            "aclImdb/train/unsup/47769_0.txt\n",
            "aclImdb/train/unsup/47768_0.txt\n",
            "aclImdb/train/unsup/47767_0.txt\n",
            "aclImdb/train/unsup/47766_0.txt\n",
            "aclImdb/train/unsup/47765_0.txt\n",
            "aclImdb/train/unsup/47764_0.txt\n",
            "aclImdb/train/unsup/47763_0.txt\n",
            "aclImdb/train/unsup/47762_0.txt\n",
            "aclImdb/train/unsup/47761_0.txt\n",
            "aclImdb/train/unsup/47760_0.txt\n",
            "aclImdb/train/unsup/47759_0.txt\n",
            "aclImdb/train/unsup/47758_0.txt\n",
            "aclImdb/train/unsup/47757_0.txt\n",
            "aclImdb/train/unsup/47756_0.txt\n",
            "aclImdb/train/unsup/47755_0.txt\n",
            "aclImdb/train/unsup/47754_0.txt\n",
            "aclImdb/train/unsup/47753_0.txt\n",
            "aclImdb/train/unsup/47752_0.txt\n",
            "aclImdb/train/unsup/47751_0.txt\n",
            "aclImdb/train/unsup/47750_0.txt\n",
            "aclImdb/train/unsup/47749_0.txt\n",
            "aclImdb/train/unsup/47748_0.txt\n",
            "aclImdb/train/unsup/47747_0.txt\n",
            "aclImdb/train/unsup/47746_0.txt\n",
            "aclImdb/train/unsup/47745_0.txt\n",
            "aclImdb/train/unsup/47744_0.txt\n",
            "aclImdb/train/unsup/47999_0.txt\n",
            "aclImdb/train/unsup/47998_0.txt\n",
            "aclImdb/train/unsup/47997_0.txt\n",
            "aclImdb/train/unsup/47996_0.txt\n",
            "aclImdb/train/unsup/47995_0.txt\n",
            "aclImdb/train/unsup/47994_0.txt\n",
            "aclImdb/train/unsup/47993_0.txt\n",
            "aclImdb/train/unsup/47992_0.txt\n",
            "aclImdb/train/unsup/47991_0.txt\n",
            "aclImdb/train/unsup/47990_0.txt\n",
            "aclImdb/train/unsup/47989_0.txt\n",
            "aclImdb/train/unsup/47988_0.txt\n",
            "aclImdb/train/unsup/47987_0.txt\n",
            "aclImdb/train/unsup/47986_0.txt\n",
            "aclImdb/train/unsup/47985_0.txt\n",
            "aclImdb/train/unsup/47984_0.txt\n",
            "aclImdb/train/unsup/47983_0.txt\n",
            "aclImdb/train/unsup/47982_0.txt\n",
            "aclImdb/train/unsup/47981_0.txt\n",
            "aclImdb/train/unsup/47980_0.txt\n",
            "aclImdb/train/unsup/47979_0.txt\n",
            "aclImdb/train/unsup/47978_0.txt\n",
            "aclImdb/train/unsup/47977_0.txt\n",
            "aclImdb/train/unsup/47976_0.txt\n",
            "aclImdb/train/unsup/47975_0.txt\n",
            "aclImdb/train/unsup/47974_0.txt\n",
            "aclImdb/train/unsup/47973_0.txt\n",
            "aclImdb/train/unsup/47972_0.txt\n",
            "aclImdb/train/unsup/47971_0.txt\n",
            "aclImdb/train/unsup/47970_0.txt\n",
            "aclImdb/train/unsup/47969_0.txt\n",
            "aclImdb/train/unsup/47968_0.txt\n",
            "aclImdb/train/unsup/47967_0.txt\n",
            "aclImdb/train/unsup/47966_0.txt\n",
            "aclImdb/train/unsup/47965_0.txt\n",
            "aclImdb/train/unsup/47964_0.txt\n",
            "aclImdb/train/unsup/47963_0.txt\n",
            "aclImdb/train/unsup/47962_0.txt\n",
            "aclImdb/train/unsup/47961_0.txt\n",
            "aclImdb/train/unsup/47960_0.txt\n",
            "aclImdb/train/unsup/47959_0.txt\n",
            "aclImdb/train/unsup/47958_0.txt\n",
            "aclImdb/train/unsup/47957_0.txt\n",
            "aclImdb/train/unsup/47956_0.txt\n",
            "aclImdb/train/unsup/47955_0.txt\n",
            "aclImdb/train/unsup/47954_0.txt\n",
            "aclImdb/train/unsup/47953_0.txt\n",
            "aclImdb/train/unsup/47952_0.txt\n",
            "aclImdb/train/unsup/47951_0.txt\n",
            "aclImdb/train/unsup/47950_0.txt\n",
            "aclImdb/train/unsup/47949_0.txt\n",
            "aclImdb/train/unsup/47948_0.txt\n",
            "aclImdb/train/unsup/47947_0.txt\n",
            "aclImdb/train/unsup/47946_0.txt\n",
            "aclImdb/train/unsup/47945_0.txt\n",
            "aclImdb/train/unsup/47944_0.txt\n",
            "aclImdb/train/unsup/47943_0.txt\n",
            "aclImdb/train/unsup/47942_0.txt\n",
            "aclImdb/train/unsup/47941_0.txt\n",
            "aclImdb/train/unsup/47940_0.txt\n",
            "aclImdb/train/unsup/47939_0.txt\n",
            "aclImdb/train/unsup/47938_0.txt\n",
            "aclImdb/train/unsup/47937_0.txt\n",
            "aclImdb/train/unsup/47936_0.txt\n",
            "aclImdb/train/unsup/47935_0.txt\n",
            "aclImdb/train/unsup/47934_0.txt\n",
            "aclImdb/train/unsup/47933_0.txt\n",
            "aclImdb/train/unsup/47932_0.txt\n",
            "aclImdb/train/unsup/47931_0.txt\n",
            "aclImdb/train/unsup/47930_0.txt\n",
            "aclImdb/train/unsup/47929_0.txt\n",
            "aclImdb/train/unsup/47928_0.txt\n",
            "aclImdb/train/unsup/47927_0.txt\n",
            "aclImdb/train/unsup/47926_0.txt\n",
            "aclImdb/train/unsup/47925_0.txt\n",
            "aclImdb/train/unsup/47924_0.txt\n",
            "aclImdb/train/unsup/47923_0.txt\n",
            "aclImdb/train/unsup/47922_0.txt\n",
            "aclImdb/train/unsup/47921_0.txt\n",
            "aclImdb/train/unsup/47920_0.txt\n",
            "aclImdb/train/unsup/47919_0.txt\n",
            "aclImdb/train/unsup/47918_0.txt\n",
            "aclImdb/train/unsup/47917_0.txt\n",
            "aclImdb/train/unsup/47916_0.txt\n",
            "aclImdb/train/unsup/47915_0.txt\n",
            "aclImdb/train/unsup/47914_0.txt\n",
            "aclImdb/train/unsup/47913_0.txt\n",
            "aclImdb/train/unsup/47912_0.txt\n",
            "aclImdb/train/unsup/47911_0.txt\n",
            "aclImdb/train/unsup/47910_0.txt\n",
            "aclImdb/train/unsup/47909_0.txt\n",
            "aclImdb/train/unsup/47908_0.txt\n",
            "aclImdb/train/unsup/47907_0.txt\n",
            "aclImdb/train/unsup/47906_0.txt\n",
            "aclImdb/train/unsup/47905_0.txt\n",
            "aclImdb/train/unsup/47904_0.txt\n",
            "aclImdb/train/unsup/47903_0.txt\n",
            "aclImdb/train/unsup/47902_0.txt\n",
            "aclImdb/train/unsup/47901_0.txt\n",
            "aclImdb/train/unsup/47900_0.txt\n",
            "aclImdb/train/unsup/47899_0.txt\n",
            "aclImdb/train/unsup/47898_0.txt\n",
            "aclImdb/train/unsup/47897_0.txt\n",
            "aclImdb/train/unsup/47896_0.txt\n",
            "aclImdb/train/unsup/47895_0.txt\n",
            "aclImdb/train/unsup/47894_0.txt\n",
            "aclImdb/train/unsup/47893_0.txt\n",
            "aclImdb/train/unsup/47892_0.txt\n",
            "aclImdb/train/unsup/47891_0.txt\n",
            "aclImdb/train/unsup/47890_0.txt\n",
            "aclImdb/train/unsup/47889_0.txt\n",
            "aclImdb/train/unsup/47888_0.txt\n",
            "aclImdb/train/unsup/47887_0.txt\n",
            "aclImdb/train/unsup/47886_0.txt\n",
            "aclImdb/train/unsup/47885_0.txt\n",
            "aclImdb/train/unsup/47884_0.txt\n",
            "aclImdb/train/unsup/47883_0.txt\n",
            "aclImdb/train/unsup/47882_0.txt\n",
            "aclImdb/train/unsup/47881_0.txt\n",
            "aclImdb/train/unsup/47880_0.txt\n",
            "aclImdb/train/unsup/47879_0.txt\n",
            "aclImdb/train/unsup/47878_0.txt\n",
            "aclImdb/train/unsup/47877_0.txt\n",
            "aclImdb/train/unsup/47876_0.txt\n",
            "aclImdb/train/unsup/47875_0.txt\n",
            "aclImdb/train/unsup/47874_0.txt\n",
            "aclImdb/train/unsup/47873_0.txt\n",
            "aclImdb/train/unsup/47872_0.txt\n",
            "aclImdb/train/unsup/48127_0.txt\n",
            "aclImdb/train/unsup/48126_0.txt\n",
            "aclImdb/train/unsup/48125_0.txt\n",
            "aclImdb/train/unsup/48124_0.txt\n",
            "aclImdb/train/unsup/48123_0.txt\n",
            "aclImdb/train/unsup/48122_0.txt\n",
            "aclImdb/train/unsup/48121_0.txt\n",
            "aclImdb/train/unsup/48120_0.txt\n",
            "aclImdb/train/unsup/48119_0.txt\n",
            "aclImdb/train/unsup/48118_0.txt\n",
            "aclImdb/train/unsup/48117_0.txt\n",
            "aclImdb/train/unsup/48116_0.txt\n",
            "aclImdb/train/unsup/48115_0.txt\n",
            "aclImdb/train/unsup/48114_0.txt\n",
            "aclImdb/train/unsup/48113_0.txt\n",
            "aclImdb/train/unsup/48112_0.txt\n",
            "aclImdb/train/unsup/48111_0.txt\n",
            "aclImdb/train/unsup/48110_0.txt\n",
            "aclImdb/train/unsup/48109_0.txt\n",
            "aclImdb/train/unsup/48108_0.txt\n",
            "aclImdb/train/unsup/48107_0.txt\n",
            "aclImdb/train/unsup/48106_0.txt\n",
            "aclImdb/train/unsup/48105_0.txt\n",
            "aclImdb/train/unsup/48104_0.txt\n",
            "aclImdb/train/unsup/48103_0.txt\n",
            "aclImdb/train/unsup/48102_0.txt\n",
            "aclImdb/train/unsup/48101_0.txt\n",
            "aclImdb/train/unsup/48100_0.txt\n",
            "aclImdb/train/unsup/48099_0.txt\n",
            "aclImdb/train/unsup/48098_0.txt\n",
            "aclImdb/train/unsup/48097_0.txt\n",
            "aclImdb/train/unsup/48096_0.txt\n",
            "aclImdb/train/unsup/48095_0.txt\n",
            "aclImdb/train/unsup/48094_0.txt\n",
            "aclImdb/train/unsup/48093_0.txt\n",
            "aclImdb/train/unsup/48092_0.txt\n",
            "aclImdb/train/unsup/48091_0.txt\n",
            "aclImdb/train/unsup/48090_0.txt\n",
            "aclImdb/train/unsup/48089_0.txt\n",
            "aclImdb/train/unsup/48088_0.txt\n",
            "aclImdb/train/unsup/48087_0.txt\n",
            "aclImdb/train/unsup/48086_0.txt\n",
            "aclImdb/train/unsup/48085_0.txt\n",
            "aclImdb/train/unsup/48084_0.txt\n",
            "aclImdb/train/unsup/48083_0.txt\n",
            "aclImdb/train/unsup/48082_0.txt\n",
            "aclImdb/train/unsup/48081_0.txt\n",
            "aclImdb/train/unsup/48080_0.txt\n",
            "aclImdb/train/unsup/48079_0.txt\n",
            "aclImdb/train/unsup/48078_0.txt\n",
            "aclImdb/train/unsup/48077_0.txt\n",
            "aclImdb/train/unsup/48076_0.txt\n",
            "aclImdb/train/unsup/48075_0.txt\n",
            "aclImdb/train/unsup/48074_0.txt\n",
            "aclImdb/train/unsup/48073_0.txt\n",
            "aclImdb/train/unsup/48072_0.txt\n",
            "aclImdb/train/unsup/48071_0.txt\n",
            "aclImdb/train/unsup/48070_0.txt\n",
            "aclImdb/train/unsup/48069_0.txt\n",
            "aclImdb/train/unsup/48068_0.txt\n",
            "aclImdb/train/unsup/48067_0.txt\n",
            "aclImdb/train/unsup/48066_0.txt\n",
            "aclImdb/train/unsup/48065_0.txt\n",
            "aclImdb/train/unsup/48064_0.txt\n",
            "aclImdb/train/unsup/48063_0.txt\n",
            "aclImdb/train/unsup/48062_0.txt\n",
            "aclImdb/train/unsup/48061_0.txt\n",
            "aclImdb/train/unsup/48060_0.txt\n",
            "aclImdb/train/unsup/48059_0.txt\n",
            "aclImdb/train/unsup/48058_0.txt\n",
            "aclImdb/train/unsup/48057_0.txt\n",
            "aclImdb/train/unsup/48056_0.txt\n",
            "aclImdb/train/unsup/48055_0.txt\n",
            "aclImdb/train/unsup/48054_0.txt\n",
            "aclImdb/train/unsup/48053_0.txt\n",
            "aclImdb/train/unsup/48052_0.txt\n",
            "aclImdb/train/unsup/48051_0.txt\n",
            "aclImdb/train/unsup/48050_0.txt\n",
            "aclImdb/train/unsup/48049_0.txt\n",
            "aclImdb/train/unsup/48048_0.txt\n",
            "aclImdb/train/unsup/48047_0.txt\n",
            "aclImdb/train/unsup/48046_0.txt\n",
            "aclImdb/train/unsup/48045_0.txt\n",
            "aclImdb/train/unsup/48044_0.txt\n",
            "aclImdb/train/unsup/48043_0.txt\n",
            "aclImdb/train/unsup/48042_0.txt\n",
            "aclImdb/train/unsup/48041_0.txt\n",
            "aclImdb/train/unsup/48040_0.txt\n",
            "aclImdb/train/unsup/48039_0.txt\n",
            "aclImdb/train/unsup/48038_0.txt\n",
            "aclImdb/train/unsup/48037_0.txt\n",
            "aclImdb/train/unsup/48036_0.txt\n",
            "aclImdb/train/unsup/48035_0.txt\n",
            "aclImdb/train/unsup/48034_0.txt\n",
            "aclImdb/train/unsup/48033_0.txt\n",
            "aclImdb/train/unsup/48032_0.txt\n",
            "aclImdb/train/unsup/48031_0.txt\n",
            "aclImdb/train/unsup/48030_0.txt\n",
            "aclImdb/train/unsup/48029_0.txt\n",
            "aclImdb/train/unsup/48028_0.txt\n",
            "aclImdb/train/unsup/48027_0.txt\n",
            "aclImdb/train/unsup/48026_0.txt\n",
            "aclImdb/train/unsup/48025_0.txt\n",
            "aclImdb/train/unsup/48024_0.txt\n",
            "aclImdb/train/unsup/48023_0.txt\n",
            "aclImdb/train/unsup/48022_0.txt\n",
            "aclImdb/train/unsup/48021_0.txt\n",
            "aclImdb/train/unsup/48020_0.txt\n",
            "aclImdb/train/unsup/48019_0.txt\n",
            "aclImdb/train/unsup/48018_0.txt\n",
            "aclImdb/train/unsup/48017_0.txt\n",
            "aclImdb/train/unsup/48016_0.txt\n",
            "aclImdb/train/unsup/48015_0.txt\n",
            "aclImdb/train/unsup/48014_0.txt\n",
            "aclImdb/train/unsup/48013_0.txt\n",
            "aclImdb/train/unsup/48012_0.txt\n",
            "aclImdb/train/unsup/48011_0.txt\n",
            "aclImdb/train/unsup/48010_0.txt\n",
            "aclImdb/train/unsup/48009_0.txt\n",
            "aclImdb/train/unsup/48008_0.txt\n",
            "aclImdb/train/unsup/48007_0.txt\n",
            "aclImdb/train/unsup/48006_0.txt\n",
            "aclImdb/train/unsup/48005_0.txt\n",
            "aclImdb/train/unsup/48004_0.txt\n",
            "aclImdb/train/unsup/48003_0.txt\n",
            "aclImdb/train/unsup/48002_0.txt\n",
            "aclImdb/train/unsup/48001_0.txt\n",
            "aclImdb/train/unsup/48000_0.txt\n",
            "aclImdb/train/unsup/48255_0.txt\n",
            "aclImdb/train/unsup/48254_0.txt\n",
            "aclImdb/train/unsup/48253_0.txt\n",
            "aclImdb/train/unsup/48252_0.txt\n",
            "aclImdb/train/unsup/48251_0.txt\n",
            "aclImdb/train/unsup/48250_0.txt\n",
            "aclImdb/train/unsup/48249_0.txt\n",
            "aclImdb/train/unsup/48248_0.txt\n",
            "aclImdb/train/unsup/48247_0.txt\n",
            "aclImdb/train/unsup/48246_0.txt\n",
            "aclImdb/train/unsup/48245_0.txt\n",
            "aclImdb/train/unsup/48244_0.txt\n",
            "aclImdb/train/unsup/48243_0.txt\n",
            "aclImdb/train/unsup/48242_0.txt\n",
            "aclImdb/train/unsup/48241_0.txt\n",
            "aclImdb/train/unsup/48240_0.txt\n",
            "aclImdb/train/unsup/48239_0.txt\n",
            "aclImdb/train/unsup/48238_0.txt\n",
            "aclImdb/train/unsup/48237_0.txt\n",
            "aclImdb/train/unsup/48236_0.txt\n",
            "aclImdb/train/unsup/48235_0.txt\n",
            "aclImdb/train/unsup/48234_0.txt\n",
            "aclImdb/train/unsup/48233_0.txt\n",
            "aclImdb/train/unsup/48232_0.txt\n",
            "aclImdb/train/unsup/48231_0.txt\n",
            "aclImdb/train/unsup/48230_0.txt\n",
            "aclImdb/train/unsup/48229_0.txt\n",
            "aclImdb/train/unsup/48228_0.txt\n",
            "aclImdb/train/unsup/48227_0.txt\n",
            "aclImdb/train/unsup/48226_0.txt\n",
            "aclImdb/train/unsup/48225_0.txt\n",
            "aclImdb/train/unsup/48224_0.txt\n",
            "aclImdb/train/unsup/48223_0.txt\n",
            "aclImdb/train/unsup/48222_0.txt\n",
            "aclImdb/train/unsup/48221_0.txt\n",
            "aclImdb/train/unsup/48220_0.txt\n",
            "aclImdb/train/unsup/48219_0.txt\n",
            "aclImdb/train/unsup/48218_0.txt\n",
            "aclImdb/train/unsup/48217_0.txt\n",
            "aclImdb/train/unsup/48216_0.txt\n",
            "aclImdb/train/unsup/48215_0.txt\n",
            "aclImdb/train/unsup/48214_0.txt\n",
            "aclImdb/train/unsup/48213_0.txt\n",
            "aclImdb/train/unsup/48212_0.txt\n",
            "aclImdb/train/unsup/48211_0.txt\n",
            "aclImdb/train/unsup/48210_0.txt\n",
            "aclImdb/train/unsup/48209_0.txt\n",
            "aclImdb/train/unsup/48208_0.txt\n",
            "aclImdb/train/unsup/48207_0.txt\n",
            "aclImdb/train/unsup/48206_0.txt\n",
            "aclImdb/train/unsup/48205_0.txt\n",
            "aclImdb/train/unsup/48204_0.txt\n",
            "aclImdb/train/unsup/48203_0.txt\n",
            "aclImdb/train/unsup/48202_0.txt\n",
            "aclImdb/train/unsup/48201_0.txt\n",
            "aclImdb/train/unsup/48200_0.txt\n",
            "aclImdb/train/unsup/48199_0.txt\n",
            "aclImdb/train/unsup/48198_0.txt\n",
            "aclImdb/train/unsup/48197_0.txt\n",
            "aclImdb/train/unsup/48196_0.txt\n",
            "aclImdb/train/unsup/48195_0.txt\n",
            "aclImdb/train/unsup/48194_0.txt\n",
            "aclImdb/train/unsup/48193_0.txt\n",
            "aclImdb/train/unsup/48192_0.txt\n",
            "aclImdb/train/unsup/48191_0.txt\n",
            "aclImdb/train/unsup/48190_0.txt\n",
            "aclImdb/train/unsup/48189_0.txt\n",
            "aclImdb/train/unsup/48188_0.txt\n",
            "aclImdb/train/unsup/48187_0.txt\n",
            "aclImdb/train/unsup/48186_0.txt\n",
            "aclImdb/train/unsup/48185_0.txt\n",
            "aclImdb/train/unsup/48184_0.txt\n",
            "aclImdb/train/unsup/48183_0.txt\n",
            "aclImdb/train/unsup/48182_0.txt\n",
            "aclImdb/train/unsup/48181_0.txt\n",
            "aclImdb/train/unsup/48180_0.txt\n",
            "aclImdb/train/unsup/48179_0.txt\n",
            "aclImdb/train/unsup/48178_0.txt\n",
            "aclImdb/train/unsup/48177_0.txt\n",
            "aclImdb/train/unsup/48176_0.txt\n",
            "aclImdb/train/unsup/48175_0.txt\n",
            "aclImdb/train/unsup/48174_0.txt\n",
            "aclImdb/train/unsup/48173_0.txt\n",
            "aclImdb/train/unsup/48172_0.txt\n",
            "aclImdb/train/unsup/48171_0.txt\n",
            "aclImdb/train/unsup/48170_0.txt\n",
            "aclImdb/train/unsup/48169_0.txt\n",
            "aclImdb/train/unsup/48168_0.txt\n",
            "aclImdb/train/unsup/48167_0.txt\n",
            "aclImdb/train/unsup/48166_0.txt\n",
            "aclImdb/train/unsup/48165_0.txt\n",
            "aclImdb/train/unsup/48164_0.txt\n",
            "aclImdb/train/unsup/48163_0.txt\n",
            "aclImdb/train/unsup/48162_0.txt\n",
            "aclImdb/train/unsup/48161_0.txt\n",
            "aclImdb/train/unsup/48160_0.txt\n",
            "aclImdb/train/unsup/48159_0.txt\n",
            "aclImdb/train/unsup/48158_0.txt\n",
            "aclImdb/train/unsup/48157_0.txt\n",
            "aclImdb/train/unsup/48156_0.txt\n",
            "aclImdb/train/unsup/48155_0.txt\n",
            "aclImdb/train/unsup/48154_0.txt\n",
            "aclImdb/train/unsup/48153_0.txt\n",
            "aclImdb/train/unsup/48152_0.txt\n",
            "aclImdb/train/unsup/48151_0.txt\n",
            "aclImdb/train/unsup/48150_0.txt\n",
            "aclImdb/train/unsup/48149_0.txt\n",
            "aclImdb/train/unsup/48148_0.txt\n",
            "aclImdb/train/unsup/48147_0.txt\n",
            "aclImdb/train/unsup/48146_0.txt\n",
            "aclImdb/train/unsup/48145_0.txt\n",
            "aclImdb/train/unsup/48144_0.txt\n",
            "aclImdb/train/unsup/48143_0.txt\n",
            "aclImdb/train/unsup/48142_0.txt\n",
            "aclImdb/train/unsup/48141_0.txt\n",
            "aclImdb/train/unsup/48140_0.txt\n",
            "aclImdb/train/unsup/48139_0.txt\n",
            "aclImdb/train/unsup/48138_0.txt\n",
            "aclImdb/train/unsup/48137_0.txt\n",
            "aclImdb/train/unsup/48136_0.txt\n",
            "aclImdb/train/unsup/48135_0.txt\n",
            "aclImdb/train/unsup/48134_0.txt\n",
            "aclImdb/train/unsup/48133_0.txt\n",
            "aclImdb/train/unsup/48132_0.txt\n",
            "aclImdb/train/unsup/48131_0.txt\n",
            "aclImdb/train/unsup/48130_0.txt\n",
            "aclImdb/train/unsup/48129_0.txt\n",
            "aclImdb/train/unsup/48128_0.txt\n",
            "aclImdb/train/unsup/48383_0.txt\n",
            "aclImdb/train/unsup/48382_0.txt\n",
            "aclImdb/train/unsup/48381_0.txt\n",
            "aclImdb/train/unsup/48380_0.txt\n",
            "aclImdb/train/unsup/48379_0.txt\n",
            "aclImdb/train/unsup/48378_0.txt\n",
            "aclImdb/train/unsup/48377_0.txt\n",
            "aclImdb/train/unsup/48376_0.txt\n",
            "aclImdb/train/unsup/48375_0.txt\n",
            "aclImdb/train/unsup/48374_0.txt\n",
            "aclImdb/train/unsup/48373_0.txt\n",
            "aclImdb/train/unsup/48372_0.txt\n",
            "aclImdb/train/unsup/48371_0.txt\n",
            "aclImdb/train/unsup/48370_0.txt\n",
            "aclImdb/train/unsup/48369_0.txt\n",
            "aclImdb/train/unsup/48368_0.txt\n",
            "aclImdb/train/unsup/48367_0.txt\n",
            "aclImdb/train/unsup/48366_0.txt\n",
            "aclImdb/train/unsup/48365_0.txt\n",
            "aclImdb/train/unsup/48364_0.txt\n",
            "aclImdb/train/unsup/48363_0.txt\n",
            "aclImdb/train/unsup/48362_0.txt\n",
            "aclImdb/train/unsup/48361_0.txt\n",
            "aclImdb/train/unsup/48360_0.txt\n",
            "aclImdb/train/unsup/48359_0.txt\n",
            "aclImdb/train/unsup/48358_0.txt\n",
            "aclImdb/train/unsup/48357_0.txt\n",
            "aclImdb/train/unsup/48356_0.txt\n",
            "aclImdb/train/unsup/48355_0.txt\n",
            "aclImdb/train/unsup/48354_0.txt\n",
            "aclImdb/train/unsup/48353_0.txt\n",
            "aclImdb/train/unsup/48352_0.txt\n",
            "aclImdb/train/unsup/48351_0.txt\n",
            "aclImdb/train/unsup/48350_0.txt\n",
            "aclImdb/train/unsup/48349_0.txt\n",
            "aclImdb/train/unsup/48348_0.txt\n",
            "aclImdb/train/unsup/48347_0.txt\n",
            "aclImdb/train/unsup/48346_0.txt\n",
            "aclImdb/train/unsup/48345_0.txt\n",
            "aclImdb/train/unsup/48344_0.txt\n",
            "aclImdb/train/unsup/48343_0.txt\n",
            "aclImdb/train/unsup/48342_0.txt\n",
            "aclImdb/train/unsup/48341_0.txt\n",
            "aclImdb/train/unsup/48340_0.txt\n",
            "aclImdb/train/unsup/48339_0.txt\n",
            "aclImdb/train/unsup/48338_0.txt\n",
            "aclImdb/train/unsup/48337_0.txt\n",
            "aclImdb/train/unsup/48336_0.txt\n",
            "aclImdb/train/unsup/48335_0.txt\n",
            "aclImdb/train/unsup/48334_0.txt\n",
            "aclImdb/train/unsup/48333_0.txt\n",
            "aclImdb/train/unsup/48332_0.txt\n",
            "aclImdb/train/unsup/48331_0.txt\n",
            "aclImdb/train/unsup/48330_0.txt\n",
            "aclImdb/train/unsup/48329_0.txt\n",
            "aclImdb/train/unsup/48328_0.txt\n",
            "aclImdb/train/unsup/48327_0.txt\n",
            "aclImdb/train/unsup/48326_0.txt\n",
            "aclImdb/train/unsup/48325_0.txt\n",
            "aclImdb/train/unsup/48324_0.txt\n",
            "aclImdb/train/unsup/48323_0.txt\n",
            "aclImdb/train/unsup/48322_0.txt\n",
            "aclImdb/train/unsup/48321_0.txt\n",
            "aclImdb/train/unsup/48320_0.txt\n",
            "aclImdb/train/unsup/48319_0.txt\n",
            "aclImdb/train/unsup/48318_0.txt\n",
            "aclImdb/train/unsup/48317_0.txt\n",
            "aclImdb/train/unsup/48316_0.txt\n",
            "aclImdb/train/unsup/48315_0.txt\n",
            "aclImdb/train/unsup/48314_0.txt\n",
            "aclImdb/train/unsup/48313_0.txt\n",
            "aclImdb/train/unsup/48312_0.txt\n",
            "aclImdb/train/unsup/48311_0.txt\n",
            "aclImdb/train/unsup/48310_0.txt\n",
            "aclImdb/train/unsup/48309_0.txt\n",
            "aclImdb/train/unsup/48308_0.txt\n",
            "aclImdb/train/unsup/48307_0.txt\n",
            "aclImdb/train/unsup/48306_0.txt\n",
            "aclImdb/train/unsup/48305_0.txt\n",
            "aclImdb/train/unsup/48304_0.txt\n",
            "aclImdb/train/unsup/48303_0.txt\n",
            "aclImdb/train/unsup/48302_0.txt\n",
            "aclImdb/train/unsup/48301_0.txt\n",
            "aclImdb/train/unsup/48300_0.txt\n",
            "aclImdb/train/unsup/48299_0.txt\n",
            "aclImdb/train/unsup/48298_0.txt\n",
            "aclImdb/train/unsup/48297_0.txt\n",
            "aclImdb/train/unsup/48296_0.txt\n",
            "aclImdb/train/unsup/48295_0.txt\n",
            "aclImdb/train/unsup/48294_0.txt\n",
            "aclImdb/train/unsup/48293_0.txt\n",
            "aclImdb/train/unsup/48292_0.txt\n",
            "aclImdb/train/unsup/48291_0.txt\n",
            "aclImdb/train/unsup/48290_0.txt\n",
            "aclImdb/train/unsup/48289_0.txt\n",
            "aclImdb/train/unsup/48288_0.txt\n",
            "aclImdb/train/unsup/48287_0.txt\n",
            "aclImdb/train/unsup/48286_0.txt\n",
            "aclImdb/train/unsup/48285_0.txt\n",
            "aclImdb/train/unsup/48284_0.txt\n",
            "aclImdb/train/unsup/48283_0.txt\n",
            "aclImdb/train/unsup/48282_0.txt\n",
            "aclImdb/train/unsup/48281_0.txt\n",
            "aclImdb/train/unsup/48280_0.txt\n",
            "aclImdb/train/unsup/48279_0.txt\n",
            "aclImdb/train/unsup/48278_0.txt\n",
            "aclImdb/train/unsup/48277_0.txt\n",
            "aclImdb/train/unsup/48276_0.txt\n",
            "aclImdb/train/unsup/48275_0.txt\n",
            "aclImdb/train/unsup/48274_0.txt\n",
            "aclImdb/train/unsup/48273_0.txt\n",
            "aclImdb/train/unsup/48272_0.txt\n",
            "aclImdb/train/unsup/48271_0.txt\n",
            "aclImdb/train/unsup/48270_0.txt\n",
            "aclImdb/train/unsup/48269_0.txt\n",
            "aclImdb/train/unsup/48268_0.txt\n",
            "aclImdb/train/unsup/48267_0.txt\n",
            "aclImdb/train/unsup/48266_0.txt\n",
            "aclImdb/train/unsup/48265_0.txt\n",
            "aclImdb/train/unsup/48264_0.txt\n",
            "aclImdb/train/unsup/48263_0.txt\n",
            "aclImdb/train/unsup/48262_0.txt\n",
            "aclImdb/train/unsup/48261_0.txt\n",
            "aclImdb/train/unsup/48260_0.txt\n",
            "aclImdb/train/unsup/48259_0.txt\n",
            "aclImdb/train/unsup/48258_0.txt\n",
            "aclImdb/train/unsup/48257_0.txt\n",
            "aclImdb/train/unsup/48256_0.txt\n",
            "aclImdb/train/unsup/48511_0.txt\n",
            "aclImdb/train/unsup/48510_0.txt\n",
            "aclImdb/train/unsup/48509_0.txt\n",
            "aclImdb/train/unsup/48508_0.txt\n",
            "aclImdb/train/unsup/48507_0.txt\n",
            "aclImdb/train/unsup/48506_0.txt\n",
            "aclImdb/train/unsup/48505_0.txt\n",
            "aclImdb/train/unsup/48504_0.txt\n",
            "aclImdb/train/unsup/48503_0.txt\n",
            "aclImdb/train/unsup/48502_0.txt\n",
            "aclImdb/train/unsup/48501_0.txt\n",
            "aclImdb/train/unsup/48500_0.txt\n",
            "aclImdb/train/unsup/48499_0.txt\n",
            "aclImdb/train/unsup/48498_0.txt\n",
            "aclImdb/train/unsup/48497_0.txt\n",
            "aclImdb/train/unsup/48496_0.txt\n",
            "aclImdb/train/unsup/48495_0.txt\n",
            "aclImdb/train/unsup/48494_0.txt\n",
            "aclImdb/train/unsup/48493_0.txt\n",
            "aclImdb/train/unsup/48492_0.txt\n",
            "aclImdb/train/unsup/48491_0.txt\n",
            "aclImdb/train/unsup/48490_0.txt\n",
            "aclImdb/train/unsup/48489_0.txt\n",
            "aclImdb/train/unsup/48488_0.txt\n",
            "aclImdb/train/unsup/48487_0.txt\n",
            "aclImdb/train/unsup/48486_0.txt\n",
            "aclImdb/train/unsup/48485_0.txt\n",
            "aclImdb/train/unsup/48484_0.txt\n",
            "aclImdb/train/unsup/48483_0.txt\n",
            "aclImdb/train/unsup/48482_0.txt\n",
            "aclImdb/train/unsup/48481_0.txt\n",
            "aclImdb/train/unsup/48480_0.txt\n",
            "aclImdb/train/unsup/48479_0.txt\n",
            "aclImdb/train/unsup/48478_0.txt\n",
            "aclImdb/train/unsup/48477_0.txt\n",
            "aclImdb/train/unsup/48476_0.txt\n",
            "aclImdb/train/unsup/48475_0.txt\n",
            "aclImdb/train/unsup/48474_0.txt\n",
            "aclImdb/train/unsup/48473_0.txt\n",
            "aclImdb/train/unsup/48472_0.txt\n",
            "aclImdb/train/unsup/48471_0.txt\n",
            "aclImdb/train/unsup/48470_0.txt\n",
            "aclImdb/train/unsup/48469_0.txt\n",
            "aclImdb/train/unsup/48468_0.txt\n",
            "aclImdb/train/unsup/48467_0.txt\n",
            "aclImdb/train/unsup/48466_0.txt\n",
            "aclImdb/train/unsup/48465_0.txt\n",
            "aclImdb/train/unsup/48464_0.txt\n",
            "aclImdb/train/unsup/48463_0.txt\n",
            "aclImdb/train/unsup/48462_0.txt\n",
            "aclImdb/train/unsup/48461_0.txt\n",
            "aclImdb/train/unsup/48460_0.txt\n",
            "aclImdb/train/unsup/48459_0.txt\n",
            "aclImdb/train/unsup/48458_0.txt\n",
            "aclImdb/train/unsup/48457_0.txt\n",
            "aclImdb/train/unsup/48456_0.txt\n",
            "aclImdb/train/unsup/48455_0.txt\n",
            "aclImdb/train/unsup/48454_0.txt\n",
            "aclImdb/train/unsup/48453_0.txt\n",
            "aclImdb/train/unsup/48452_0.txt\n",
            "aclImdb/train/unsup/48451_0.txt\n",
            "aclImdb/train/unsup/48450_0.txt\n",
            "aclImdb/train/unsup/48449_0.txt\n",
            "aclImdb/train/unsup/48448_0.txt\n",
            "aclImdb/train/unsup/48447_0.txt\n",
            "aclImdb/train/unsup/48446_0.txt\n",
            "aclImdb/train/unsup/48445_0.txt\n",
            "aclImdb/train/unsup/48444_0.txt\n",
            "aclImdb/train/unsup/48443_0.txt\n",
            "aclImdb/train/unsup/48442_0.txt\n",
            "aclImdb/train/unsup/48441_0.txt\n",
            "aclImdb/train/unsup/48440_0.txt\n",
            "aclImdb/train/unsup/48439_0.txt\n",
            "aclImdb/train/unsup/48438_0.txt\n",
            "aclImdb/train/unsup/48437_0.txt\n",
            "aclImdb/train/unsup/48436_0.txt\n",
            "aclImdb/train/unsup/48435_0.txt\n",
            "aclImdb/train/unsup/48434_0.txt\n",
            "aclImdb/train/unsup/48433_0.txt\n",
            "aclImdb/train/unsup/48432_0.txt\n",
            "aclImdb/train/unsup/48431_0.txt\n",
            "aclImdb/train/unsup/48430_0.txt\n",
            "aclImdb/train/unsup/48429_0.txt\n",
            "aclImdb/train/unsup/48428_0.txt\n",
            "aclImdb/train/unsup/48427_0.txt\n",
            "aclImdb/train/unsup/48426_0.txt\n",
            "aclImdb/train/unsup/48425_0.txt\n",
            "aclImdb/train/unsup/48424_0.txt\n",
            "aclImdb/train/unsup/48423_0.txt\n",
            "aclImdb/train/unsup/48422_0.txt\n",
            "aclImdb/train/unsup/48421_0.txt\n",
            "aclImdb/train/unsup/48420_0.txt\n",
            "aclImdb/train/unsup/48419_0.txt\n",
            "aclImdb/train/unsup/48418_0.txt\n",
            "aclImdb/train/unsup/48417_0.txt\n",
            "aclImdb/train/unsup/48416_0.txt\n",
            "aclImdb/train/unsup/48415_0.txt\n",
            "aclImdb/train/unsup/48414_0.txt\n",
            "aclImdb/train/unsup/48413_0.txt\n",
            "aclImdb/train/unsup/48412_0.txt\n",
            "aclImdb/train/unsup/48411_0.txt\n",
            "aclImdb/train/unsup/48410_0.txt\n",
            "aclImdb/train/unsup/48409_0.txt\n",
            "aclImdb/train/unsup/48408_0.txt\n",
            "aclImdb/train/unsup/48407_0.txt\n",
            "aclImdb/train/unsup/48406_0.txt\n",
            "aclImdb/train/unsup/48405_0.txt\n",
            "aclImdb/train/unsup/48404_0.txt\n",
            "aclImdb/train/unsup/48403_0.txt\n",
            "aclImdb/train/unsup/48402_0.txt\n",
            "aclImdb/train/unsup/48401_0.txt\n",
            "aclImdb/train/unsup/48400_0.txt\n",
            "aclImdb/train/unsup/48399_0.txt\n",
            "aclImdb/train/unsup/48398_0.txt\n",
            "aclImdb/train/unsup/48397_0.txt\n",
            "aclImdb/train/unsup/48396_0.txt\n",
            "aclImdb/train/unsup/48395_0.txt\n",
            "aclImdb/train/unsup/48394_0.txt\n",
            "aclImdb/train/unsup/48393_0.txt\n",
            "aclImdb/train/unsup/48392_0.txt\n",
            "aclImdb/train/unsup/48391_0.txt\n",
            "aclImdb/train/unsup/48390_0.txt\n",
            "aclImdb/train/unsup/48389_0.txt\n",
            "aclImdb/train/unsup/48388_0.txt\n",
            "aclImdb/train/unsup/48387_0.txt\n",
            "aclImdb/train/unsup/48386_0.txt\n",
            "aclImdb/train/unsup/48385_0.txt\n",
            "aclImdb/train/unsup/48384_0.txt\n",
            "aclImdb/train/unsup/48639_0.txt\n",
            "aclImdb/train/unsup/48638_0.txt\n",
            "aclImdb/train/unsup/48637_0.txt\n",
            "aclImdb/train/unsup/48636_0.txt\n",
            "aclImdb/train/unsup/48635_0.txt\n",
            "aclImdb/train/unsup/48634_0.txt\n",
            "aclImdb/train/unsup/48633_0.txt\n",
            "aclImdb/train/unsup/48632_0.txt\n",
            "aclImdb/train/unsup/48631_0.txt\n",
            "aclImdb/train/unsup/48630_0.txt\n",
            "aclImdb/train/unsup/48629_0.txt\n",
            "aclImdb/train/unsup/48628_0.txt\n",
            "aclImdb/train/unsup/48627_0.txt\n",
            "aclImdb/train/unsup/48626_0.txt\n",
            "aclImdb/train/unsup/48625_0.txt\n",
            "aclImdb/train/unsup/48624_0.txt\n",
            "aclImdb/train/unsup/48623_0.txt\n",
            "aclImdb/train/unsup/48622_0.txt\n",
            "aclImdb/train/unsup/48621_0.txt\n",
            "aclImdb/train/unsup/48620_0.txt\n",
            "aclImdb/train/unsup/48619_0.txt\n",
            "aclImdb/train/unsup/48618_0.txt\n",
            "aclImdb/train/unsup/48617_0.txt\n",
            "aclImdb/train/unsup/48616_0.txt\n",
            "aclImdb/train/unsup/48615_0.txt\n",
            "aclImdb/train/unsup/48614_0.txt\n",
            "aclImdb/train/unsup/48613_0.txt\n",
            "aclImdb/train/unsup/48612_0.txt\n",
            "aclImdb/train/unsup/48611_0.txt\n",
            "aclImdb/train/unsup/48610_0.txt\n",
            "aclImdb/train/unsup/48609_0.txt\n",
            "aclImdb/train/unsup/48608_0.txt\n",
            "aclImdb/train/unsup/48607_0.txt\n",
            "aclImdb/train/unsup/48606_0.txt\n",
            "aclImdb/train/unsup/48605_0.txt\n",
            "aclImdb/train/unsup/48604_0.txt\n",
            "aclImdb/train/unsup/48603_0.txt\n",
            "aclImdb/train/unsup/48602_0.txt\n",
            "aclImdb/train/unsup/48601_0.txt\n",
            "aclImdb/train/unsup/48600_0.txt\n",
            "aclImdb/train/unsup/48599_0.txt\n",
            "aclImdb/train/unsup/48598_0.txt\n",
            "aclImdb/train/unsup/48597_0.txt\n",
            "aclImdb/train/unsup/48596_0.txt\n",
            "aclImdb/train/unsup/48595_0.txt\n",
            "aclImdb/train/unsup/48594_0.txt\n",
            "aclImdb/train/unsup/48593_0.txt\n",
            "aclImdb/train/unsup/48592_0.txt\n",
            "aclImdb/train/unsup/48591_0.txt\n",
            "aclImdb/train/unsup/48590_0.txt\n",
            "aclImdb/train/unsup/48589_0.txt\n",
            "aclImdb/train/unsup/48588_0.txt\n",
            "aclImdb/train/unsup/48587_0.txt\n",
            "aclImdb/train/unsup/48586_0.txt\n",
            "aclImdb/train/unsup/48585_0.txt\n",
            "aclImdb/train/unsup/48584_0.txt\n",
            "aclImdb/train/unsup/48583_0.txt\n",
            "aclImdb/train/unsup/48582_0.txt\n",
            "aclImdb/train/unsup/48581_0.txt\n",
            "aclImdb/train/unsup/48580_0.txt\n",
            "aclImdb/train/unsup/48579_0.txt\n",
            "aclImdb/train/unsup/48578_0.txt\n",
            "aclImdb/train/unsup/48577_0.txt\n",
            "aclImdb/train/unsup/48576_0.txt\n",
            "aclImdb/train/unsup/48575_0.txt\n",
            "aclImdb/train/unsup/48574_0.txt\n",
            "aclImdb/train/unsup/48573_0.txt\n",
            "aclImdb/train/unsup/48572_0.txt\n",
            "aclImdb/train/unsup/48571_0.txt\n",
            "aclImdb/train/unsup/48570_0.txt\n",
            "aclImdb/train/unsup/48569_0.txt\n",
            "aclImdb/train/unsup/48568_0.txt\n",
            "aclImdb/train/unsup/48567_0.txt\n",
            "aclImdb/train/unsup/48566_0.txt\n",
            "aclImdb/train/unsup/48565_0.txt\n",
            "aclImdb/train/unsup/48564_0.txt\n",
            "aclImdb/train/unsup/48563_0.txt\n",
            "aclImdb/train/unsup/48562_0.txt\n",
            "aclImdb/train/unsup/48561_0.txt\n",
            "aclImdb/train/unsup/48560_0.txt\n",
            "aclImdb/train/unsup/48559_0.txt\n",
            "aclImdb/train/unsup/48558_0.txt\n",
            "aclImdb/train/unsup/48557_0.txt\n",
            "aclImdb/train/unsup/48556_0.txt\n",
            "aclImdb/train/unsup/48555_0.txt\n",
            "aclImdb/train/unsup/48554_0.txt\n",
            "aclImdb/train/unsup/48553_0.txt\n",
            "aclImdb/train/unsup/48552_0.txt\n",
            "aclImdb/train/unsup/48551_0.txt\n",
            "aclImdb/train/unsup/48550_0.txt\n",
            "aclImdb/train/unsup/48549_0.txt\n",
            "aclImdb/train/unsup/48548_0.txt\n",
            "aclImdb/train/unsup/48547_0.txt\n",
            "aclImdb/train/unsup/48546_0.txt\n",
            "aclImdb/train/unsup/48545_0.txt\n",
            "aclImdb/train/unsup/48544_0.txt\n",
            "aclImdb/train/unsup/48543_0.txt\n",
            "aclImdb/train/unsup/48542_0.txt\n",
            "aclImdb/train/unsup/48541_0.txt\n",
            "aclImdb/train/unsup/48540_0.txt\n",
            "aclImdb/train/unsup/48539_0.txt\n",
            "aclImdb/train/unsup/48538_0.txt\n",
            "aclImdb/train/unsup/48537_0.txt\n",
            "aclImdb/train/unsup/48536_0.txt\n",
            "aclImdb/train/unsup/48535_0.txt\n",
            "aclImdb/train/unsup/48534_0.txt\n",
            "aclImdb/train/unsup/48533_0.txt\n",
            "aclImdb/train/unsup/48532_0.txt\n",
            "aclImdb/train/unsup/48531_0.txt\n",
            "aclImdb/train/unsup/48530_0.txt\n",
            "aclImdb/train/unsup/48529_0.txt\n",
            "aclImdb/train/unsup/48528_0.txt\n",
            "aclImdb/train/unsup/48527_0.txt\n",
            "aclImdb/train/unsup/48526_0.txt\n",
            "aclImdb/train/unsup/48525_0.txt\n",
            "aclImdb/train/unsup/48524_0.txt\n",
            "aclImdb/train/unsup/48523_0.txt\n",
            "aclImdb/train/unsup/48522_0.txt\n",
            "aclImdb/train/unsup/48521_0.txt\n",
            "aclImdb/train/unsup/48520_0.txt\n",
            "aclImdb/train/unsup/48519_0.txt\n",
            "aclImdb/train/unsup/48518_0.txt\n",
            "aclImdb/train/unsup/48517_0.txt\n",
            "aclImdb/train/unsup/48516_0.txt\n",
            "aclImdb/train/unsup/48515_0.txt\n",
            "aclImdb/train/unsup/48514_0.txt\n",
            "aclImdb/train/unsup/48513_0.txt\n",
            "aclImdb/train/unsup/48512_0.txt\n",
            "aclImdb/train/unsup/48767_0.txt\n",
            "aclImdb/train/unsup/48766_0.txt\n",
            "aclImdb/train/unsup/48765_0.txt\n",
            "aclImdb/train/unsup/48764_0.txt\n",
            "aclImdb/train/unsup/48763_0.txt\n",
            "aclImdb/train/unsup/48762_0.txt\n",
            "aclImdb/train/unsup/48761_0.txt\n",
            "aclImdb/train/unsup/48760_0.txt\n",
            "aclImdb/train/unsup/48759_0.txt\n",
            "aclImdb/train/unsup/48758_0.txt\n",
            "aclImdb/train/unsup/48757_0.txt\n",
            "aclImdb/train/unsup/48756_0.txt\n",
            "aclImdb/train/unsup/48755_0.txt\n",
            "aclImdb/train/unsup/48754_0.txt\n",
            "aclImdb/train/unsup/48753_0.txt\n",
            "aclImdb/train/unsup/48752_0.txt\n",
            "aclImdb/train/unsup/48751_0.txt\n",
            "aclImdb/train/unsup/48750_0.txt\n",
            "aclImdb/train/unsup/48749_0.txt\n",
            "aclImdb/train/unsup/48748_0.txt\n",
            "aclImdb/train/unsup/48747_0.txt\n",
            "aclImdb/train/unsup/48746_0.txt\n",
            "aclImdb/train/unsup/48745_0.txt\n",
            "aclImdb/train/unsup/48744_0.txt\n",
            "aclImdb/train/unsup/48743_0.txt\n",
            "aclImdb/train/unsup/48742_0.txt\n",
            "aclImdb/train/unsup/48741_0.txt\n",
            "aclImdb/train/unsup/48740_0.txt\n",
            "aclImdb/train/unsup/48739_0.txt\n",
            "aclImdb/train/unsup/48738_0.txt\n",
            "aclImdb/train/unsup/48737_0.txt\n",
            "aclImdb/train/unsup/48736_0.txt\n",
            "aclImdb/train/unsup/48735_0.txt\n",
            "aclImdb/train/unsup/48734_0.txt\n",
            "aclImdb/train/unsup/48733_0.txt\n",
            "aclImdb/train/unsup/48732_0.txt\n",
            "aclImdb/train/unsup/48731_0.txt\n",
            "aclImdb/train/unsup/48730_0.txt\n",
            "aclImdb/train/unsup/48729_0.txt\n",
            "aclImdb/train/unsup/48728_0.txt\n",
            "aclImdb/train/unsup/48727_0.txt\n",
            "aclImdb/train/unsup/48726_0.txt\n",
            "aclImdb/train/unsup/48725_0.txt\n",
            "aclImdb/train/unsup/48724_0.txt\n",
            "aclImdb/train/unsup/48723_0.txt\n",
            "aclImdb/train/unsup/48722_0.txt\n",
            "aclImdb/train/unsup/48721_0.txt\n",
            "aclImdb/train/unsup/48720_0.txt\n",
            "aclImdb/train/unsup/48719_0.txt\n",
            "aclImdb/train/unsup/48718_0.txt\n",
            "aclImdb/train/unsup/48717_0.txt\n",
            "aclImdb/train/unsup/48716_0.txt\n",
            "aclImdb/train/unsup/48715_0.txt\n",
            "aclImdb/train/unsup/48714_0.txt\n",
            "aclImdb/train/unsup/48713_0.txt\n",
            "aclImdb/train/unsup/48712_0.txt\n",
            "aclImdb/train/unsup/48711_0.txt\n",
            "aclImdb/train/unsup/48710_0.txt\n",
            "aclImdb/train/unsup/48709_0.txt\n",
            "aclImdb/train/unsup/48708_0.txt\n",
            "aclImdb/train/unsup/48707_0.txt\n",
            "aclImdb/train/unsup/48706_0.txt\n",
            "aclImdb/train/unsup/48705_0.txt\n",
            "aclImdb/train/unsup/48704_0.txt\n",
            "aclImdb/train/unsup/48703_0.txt\n",
            "aclImdb/train/unsup/48702_0.txt\n",
            "aclImdb/train/unsup/48701_0.txt\n",
            "aclImdb/train/unsup/48700_0.txt\n",
            "aclImdb/train/unsup/48699_0.txt\n",
            "aclImdb/train/unsup/48698_0.txt\n",
            "aclImdb/train/unsup/48697_0.txt\n",
            "aclImdb/train/unsup/48696_0.txt\n",
            "aclImdb/train/unsup/48695_0.txt\n",
            "aclImdb/train/unsup/48694_0.txt\n",
            "aclImdb/train/unsup/48693_0.txt\n",
            "aclImdb/train/unsup/48692_0.txt\n",
            "aclImdb/train/unsup/48691_0.txt\n",
            "aclImdb/train/unsup/48690_0.txt\n",
            "aclImdb/train/unsup/48689_0.txt\n",
            "aclImdb/train/unsup/48688_0.txt\n",
            "aclImdb/train/unsup/48687_0.txt\n",
            "aclImdb/train/unsup/48686_0.txt\n",
            "aclImdb/train/unsup/48685_0.txt\n",
            "aclImdb/train/unsup/48684_0.txt\n",
            "aclImdb/train/unsup/48683_0.txt\n",
            "aclImdb/train/unsup/48682_0.txt\n",
            "aclImdb/train/unsup/48681_0.txt\n",
            "aclImdb/train/unsup/48680_0.txt\n",
            "aclImdb/train/unsup/48679_0.txt\n",
            "aclImdb/train/unsup/48678_0.txt\n",
            "aclImdb/train/unsup/48677_0.txt\n",
            "aclImdb/train/unsup/48676_0.txt\n",
            "aclImdb/train/unsup/48675_0.txt\n",
            "aclImdb/train/unsup/48674_0.txt\n",
            "aclImdb/train/unsup/48673_0.txt\n",
            "aclImdb/train/unsup/48672_0.txt\n",
            "aclImdb/train/unsup/48671_0.txt\n",
            "aclImdb/train/unsup/48670_0.txt\n",
            "aclImdb/train/unsup/48669_0.txt\n",
            "aclImdb/train/unsup/48668_0.txt\n",
            "aclImdb/train/unsup/48667_0.txt\n",
            "aclImdb/train/unsup/48666_0.txt\n",
            "aclImdb/train/unsup/48665_0.txt\n",
            "aclImdb/train/unsup/48664_0.txt\n",
            "aclImdb/train/unsup/48663_0.txt\n",
            "aclImdb/train/unsup/48662_0.txt\n",
            "aclImdb/train/unsup/48661_0.txt\n",
            "aclImdb/train/unsup/48660_0.txt\n",
            "aclImdb/train/unsup/48659_0.txt\n",
            "aclImdb/train/unsup/48658_0.txt\n",
            "aclImdb/train/unsup/48657_0.txt\n",
            "aclImdb/train/unsup/48656_0.txt\n",
            "aclImdb/train/unsup/48655_0.txt\n",
            "aclImdb/train/unsup/48654_0.txt\n",
            "aclImdb/train/unsup/48653_0.txt\n",
            "aclImdb/train/unsup/48652_0.txt\n",
            "aclImdb/train/unsup/48651_0.txt\n",
            "aclImdb/train/unsup/48650_0.txt\n",
            "aclImdb/train/unsup/48649_0.txt\n",
            "aclImdb/train/unsup/48648_0.txt\n",
            "aclImdb/train/unsup/48647_0.txt\n",
            "aclImdb/train/unsup/48646_0.txt\n",
            "aclImdb/train/unsup/48645_0.txt\n",
            "aclImdb/train/unsup/48644_0.txt\n",
            "aclImdb/train/unsup/48643_0.txt\n",
            "aclImdb/train/unsup/48642_0.txt\n",
            "aclImdb/train/unsup/48641_0.txt\n",
            "aclImdb/train/unsup/48640_0.txt\n",
            "aclImdb/train/unsup/48895_0.txt\n",
            "aclImdb/train/unsup/48894_0.txt\n",
            "aclImdb/train/unsup/48893_0.txt\n",
            "aclImdb/train/unsup/48892_0.txt\n",
            "aclImdb/train/unsup/48891_0.txt\n",
            "aclImdb/train/unsup/48890_0.txt\n",
            "aclImdb/train/unsup/48889_0.txt\n",
            "aclImdb/train/unsup/48888_0.txt\n",
            "aclImdb/train/unsup/48887_0.txt\n",
            "aclImdb/train/unsup/48886_0.txt\n",
            "aclImdb/train/unsup/48885_0.txt\n",
            "aclImdb/train/unsup/48884_0.txt\n",
            "aclImdb/train/unsup/48883_0.txt\n",
            "aclImdb/train/unsup/48882_0.txt\n",
            "aclImdb/train/unsup/48881_0.txt\n",
            "aclImdb/train/unsup/48880_0.txt\n",
            "aclImdb/train/unsup/48879_0.txt\n",
            "aclImdb/train/unsup/48878_0.txt\n",
            "aclImdb/train/unsup/48877_0.txt\n",
            "aclImdb/train/unsup/48876_0.txt\n",
            "aclImdb/train/unsup/48875_0.txt\n",
            "aclImdb/train/unsup/48874_0.txt\n",
            "aclImdb/train/unsup/48873_0.txt\n",
            "aclImdb/train/unsup/48872_0.txt\n",
            "aclImdb/train/unsup/48871_0.txt\n",
            "aclImdb/train/unsup/48870_0.txt\n",
            "aclImdb/train/unsup/48869_0.txt\n",
            "aclImdb/train/unsup/48868_0.txt\n",
            "aclImdb/train/unsup/48867_0.txt\n",
            "aclImdb/train/unsup/48866_0.txt\n",
            "aclImdb/train/unsup/48865_0.txt\n",
            "aclImdb/train/unsup/48864_0.txt\n",
            "aclImdb/train/unsup/48863_0.txt\n",
            "aclImdb/train/unsup/48862_0.txt\n",
            "aclImdb/train/unsup/48861_0.txt\n",
            "aclImdb/train/unsup/48860_0.txt\n",
            "aclImdb/train/unsup/48859_0.txt\n",
            "aclImdb/train/unsup/48858_0.txt\n",
            "aclImdb/train/unsup/48857_0.txt\n",
            "aclImdb/train/unsup/48856_0.txt\n",
            "aclImdb/train/unsup/48855_0.txt\n",
            "aclImdb/train/unsup/48854_0.txt\n",
            "aclImdb/train/unsup/48853_0.txt\n",
            "aclImdb/train/unsup/48852_0.txt\n",
            "aclImdb/train/unsup/48851_0.txt\n",
            "aclImdb/train/unsup/48850_0.txt\n",
            "aclImdb/train/unsup/48849_0.txt\n",
            "aclImdb/train/unsup/48848_0.txt\n",
            "aclImdb/train/unsup/48847_0.txt\n",
            "aclImdb/train/unsup/48846_0.txt\n",
            "aclImdb/train/unsup/48845_0.txt\n",
            "aclImdb/train/unsup/48844_0.txt\n",
            "aclImdb/train/unsup/48843_0.txt\n",
            "aclImdb/train/unsup/48842_0.txt\n",
            "aclImdb/train/unsup/48841_0.txt\n",
            "aclImdb/train/unsup/48840_0.txt\n",
            "aclImdb/train/unsup/48839_0.txt\n",
            "aclImdb/train/unsup/48838_0.txt\n",
            "aclImdb/train/unsup/48837_0.txt\n",
            "aclImdb/train/unsup/48836_0.txt\n",
            "aclImdb/train/unsup/48835_0.txt\n",
            "aclImdb/train/unsup/48834_0.txt\n",
            "aclImdb/train/unsup/48833_0.txt\n",
            "aclImdb/train/unsup/48832_0.txt\n",
            "aclImdb/train/unsup/48831_0.txt\n",
            "aclImdb/train/unsup/48830_0.txt\n",
            "aclImdb/train/unsup/48829_0.txt\n",
            "aclImdb/train/unsup/48828_0.txt\n",
            "aclImdb/train/unsup/48827_0.txt\n",
            "aclImdb/train/unsup/48826_0.txt\n",
            "aclImdb/train/unsup/48825_0.txt\n",
            "aclImdb/train/unsup/48824_0.txt\n",
            "aclImdb/train/unsup/48823_0.txt\n",
            "aclImdb/train/unsup/48822_0.txt\n",
            "aclImdb/train/unsup/48821_0.txt\n",
            "aclImdb/train/unsup/48820_0.txt\n",
            "aclImdb/train/unsup/48819_0.txt\n",
            "aclImdb/train/unsup/48818_0.txt\n",
            "aclImdb/train/unsup/48817_0.txt\n",
            "aclImdb/train/unsup/48816_0.txt\n",
            "aclImdb/train/unsup/48815_0.txt\n",
            "aclImdb/train/unsup/48814_0.txt\n",
            "aclImdb/train/unsup/48813_0.txt\n",
            "aclImdb/train/unsup/48812_0.txt\n",
            "aclImdb/train/unsup/48811_0.txt\n",
            "aclImdb/train/unsup/48810_0.txt\n",
            "aclImdb/train/unsup/48809_0.txt\n",
            "aclImdb/train/unsup/48808_0.txt\n",
            "aclImdb/train/unsup/48807_0.txt\n",
            "aclImdb/train/unsup/48806_0.txt\n",
            "aclImdb/train/unsup/48805_0.txt\n",
            "aclImdb/train/unsup/48804_0.txt\n",
            "aclImdb/train/unsup/48803_0.txt\n",
            "aclImdb/train/unsup/48802_0.txt\n",
            "aclImdb/train/unsup/48801_0.txt\n",
            "aclImdb/train/unsup/48800_0.txt\n",
            "aclImdb/train/unsup/48799_0.txt\n",
            "aclImdb/train/unsup/48798_0.txt\n",
            "aclImdb/train/unsup/48797_0.txt\n",
            "aclImdb/train/unsup/48796_0.txt\n",
            "aclImdb/train/unsup/48795_0.txt\n",
            "aclImdb/train/unsup/48794_0.txt\n",
            "aclImdb/train/unsup/48793_0.txt\n",
            "aclImdb/train/unsup/48792_0.txt\n",
            "aclImdb/train/unsup/48791_0.txt\n",
            "aclImdb/train/unsup/48790_0.txt\n",
            "aclImdb/train/unsup/48789_0.txt\n",
            "aclImdb/train/unsup/48788_0.txt\n",
            "aclImdb/train/unsup/48787_0.txt\n",
            "aclImdb/train/unsup/48786_0.txt\n",
            "aclImdb/train/unsup/48785_0.txt\n",
            "aclImdb/train/unsup/48784_0.txt\n",
            "aclImdb/train/unsup/48783_0.txt\n",
            "aclImdb/train/unsup/48782_0.txt\n",
            "aclImdb/train/unsup/48781_0.txt\n",
            "aclImdb/train/unsup/48780_0.txt\n",
            "aclImdb/train/unsup/48779_0.txt\n",
            "aclImdb/train/unsup/48778_0.txt\n",
            "aclImdb/train/unsup/48777_0.txt\n",
            "aclImdb/train/unsup/48776_0.txt\n",
            "aclImdb/train/unsup/48775_0.txt\n",
            "aclImdb/train/unsup/48774_0.txt\n",
            "aclImdb/train/unsup/48773_0.txt\n",
            "aclImdb/train/unsup/48772_0.txt\n",
            "aclImdb/train/unsup/48771_0.txt\n",
            "aclImdb/train/unsup/48770_0.txt\n",
            "aclImdb/train/unsup/48769_0.txt\n",
            "aclImdb/train/unsup/48768_0.txt\n",
            "aclImdb/train/unsup/49023_0.txt\n",
            "aclImdb/train/unsup/49022_0.txt\n",
            "aclImdb/train/unsup/49021_0.txt\n",
            "aclImdb/train/unsup/49020_0.txt\n",
            "aclImdb/train/unsup/49019_0.txt\n",
            "aclImdb/train/unsup/49018_0.txt\n",
            "aclImdb/train/unsup/49017_0.txt\n",
            "aclImdb/train/unsup/49016_0.txt\n",
            "aclImdb/train/unsup/49015_0.txt\n",
            "aclImdb/train/unsup/49014_0.txt\n",
            "aclImdb/train/unsup/49013_0.txt\n",
            "aclImdb/train/unsup/49012_0.txt\n",
            "aclImdb/train/unsup/49011_0.txt\n",
            "aclImdb/train/unsup/49010_0.txt\n",
            "aclImdb/train/unsup/49009_0.txt\n",
            "aclImdb/train/unsup/49008_0.txt\n",
            "aclImdb/train/unsup/49007_0.txt\n",
            "aclImdb/train/unsup/49006_0.txt\n",
            "aclImdb/train/unsup/49005_0.txt\n",
            "aclImdb/train/unsup/49004_0.txt\n",
            "aclImdb/train/unsup/49003_0.txt\n",
            "aclImdb/train/unsup/49002_0.txt\n",
            "aclImdb/train/unsup/49001_0.txt\n",
            "aclImdb/train/unsup/49000_0.txt\n",
            "aclImdb/train/unsup/48999_0.txt\n",
            "aclImdb/train/unsup/48998_0.txt\n",
            "aclImdb/train/unsup/48997_0.txt\n",
            "aclImdb/train/unsup/48996_0.txt\n",
            "aclImdb/train/unsup/48995_0.txt\n",
            "aclImdb/train/unsup/48994_0.txt\n",
            "aclImdb/train/unsup/48993_0.txt\n",
            "aclImdb/train/unsup/48992_0.txt\n",
            "aclImdb/train/unsup/48991_0.txt\n",
            "aclImdb/train/unsup/48990_0.txt\n",
            "aclImdb/train/unsup/48989_0.txt\n",
            "aclImdb/train/unsup/48988_0.txt\n",
            "aclImdb/train/unsup/48987_0.txt\n",
            "aclImdb/train/unsup/48986_0.txt\n",
            "aclImdb/train/unsup/48985_0.txt\n",
            "aclImdb/train/unsup/48984_0.txt\n",
            "aclImdb/train/unsup/48983_0.txt\n",
            "aclImdb/train/unsup/48982_0.txt\n",
            "aclImdb/train/unsup/48981_0.txt\n",
            "aclImdb/train/unsup/48980_0.txt\n",
            "aclImdb/train/unsup/48979_0.txt\n",
            "aclImdb/train/unsup/48978_0.txt\n",
            "aclImdb/train/unsup/48977_0.txt\n",
            "aclImdb/train/unsup/48976_0.txt\n",
            "aclImdb/train/unsup/48975_0.txt\n",
            "aclImdb/train/unsup/48974_0.txt\n",
            "aclImdb/train/unsup/48973_0.txt\n",
            "aclImdb/train/unsup/48972_0.txt\n",
            "aclImdb/train/unsup/48971_0.txt\n",
            "aclImdb/train/unsup/48970_0.txt\n",
            "aclImdb/train/unsup/48969_0.txt\n",
            "aclImdb/train/unsup/48968_0.txt\n",
            "aclImdb/train/unsup/48967_0.txt\n",
            "aclImdb/train/unsup/48966_0.txt\n",
            "aclImdb/train/unsup/48965_0.txt\n",
            "aclImdb/train/unsup/48964_0.txt\n",
            "aclImdb/train/unsup/48963_0.txt\n",
            "aclImdb/train/unsup/48962_0.txt\n",
            "aclImdb/train/unsup/48961_0.txt\n",
            "aclImdb/train/unsup/48960_0.txt\n",
            "aclImdb/train/unsup/48959_0.txt\n",
            "aclImdb/train/unsup/48958_0.txt\n",
            "aclImdb/train/unsup/48957_0.txt\n",
            "aclImdb/train/unsup/48956_0.txt\n",
            "aclImdb/train/unsup/48955_0.txt\n",
            "aclImdb/train/unsup/48954_0.txt\n",
            "aclImdb/train/unsup/48953_0.txt\n",
            "aclImdb/train/unsup/48952_0.txt\n",
            "aclImdb/train/unsup/48951_0.txt\n",
            "aclImdb/train/unsup/48950_0.txt\n",
            "aclImdb/train/unsup/48949_0.txt\n",
            "aclImdb/train/unsup/48948_0.txt\n",
            "aclImdb/train/unsup/48947_0.txt\n",
            "aclImdb/train/unsup/48946_0.txt\n",
            "aclImdb/train/unsup/48945_0.txt\n",
            "aclImdb/train/unsup/48944_0.txt\n",
            "aclImdb/train/unsup/48943_0.txt\n",
            "aclImdb/train/unsup/48942_0.txt\n",
            "aclImdb/train/unsup/48941_0.txt\n",
            "aclImdb/train/unsup/48940_0.txt\n",
            "aclImdb/train/unsup/48939_0.txt\n",
            "aclImdb/train/unsup/48938_0.txt\n",
            "aclImdb/train/unsup/48937_0.txt\n",
            "aclImdb/train/unsup/48936_0.txt\n",
            "aclImdb/train/unsup/48935_0.txt\n",
            "aclImdb/train/unsup/48934_0.txt\n",
            "aclImdb/train/unsup/48933_0.txt\n",
            "aclImdb/train/unsup/48932_0.txt\n",
            "aclImdb/train/unsup/48931_0.txt\n",
            "aclImdb/train/unsup/48930_0.txt\n",
            "aclImdb/train/unsup/48929_0.txt\n",
            "aclImdb/train/unsup/48928_0.txt\n",
            "aclImdb/train/unsup/48927_0.txt\n",
            "aclImdb/train/unsup/48926_0.txt\n",
            "aclImdb/train/unsup/48925_0.txt\n",
            "aclImdb/train/unsup/48924_0.txt\n",
            "aclImdb/train/unsup/48923_0.txt\n",
            "aclImdb/train/unsup/48922_0.txt\n",
            "aclImdb/train/unsup/48921_0.txt\n",
            "aclImdb/train/unsup/48920_0.txt\n",
            "aclImdb/train/unsup/48919_0.txt\n",
            "aclImdb/train/unsup/48918_0.txt\n",
            "aclImdb/train/unsup/48917_0.txt\n",
            "aclImdb/train/unsup/48916_0.txt\n",
            "aclImdb/train/unsup/48915_0.txt\n",
            "aclImdb/train/unsup/48914_0.txt\n",
            "aclImdb/train/unsup/48913_0.txt\n",
            "aclImdb/train/unsup/48912_0.txt\n",
            "aclImdb/train/unsup/48911_0.txt\n",
            "aclImdb/train/unsup/48910_0.txt\n",
            "aclImdb/train/unsup/48909_0.txt\n",
            "aclImdb/train/unsup/48908_0.txt\n",
            "aclImdb/train/unsup/48907_0.txt\n",
            "aclImdb/train/unsup/48906_0.txt\n",
            "aclImdb/train/unsup/48905_0.txt\n",
            "aclImdb/train/unsup/48904_0.txt\n",
            "aclImdb/train/unsup/48903_0.txt\n",
            "aclImdb/train/unsup/48902_0.txt\n",
            "aclImdb/train/unsup/48901_0.txt\n",
            "aclImdb/train/unsup/48900_0.txt\n",
            "aclImdb/train/unsup/48899_0.txt\n",
            "aclImdb/train/unsup/48898_0.txt\n",
            "aclImdb/train/unsup/48897_0.txt\n",
            "aclImdb/train/unsup/48896_0.txt\n",
            "aclImdb/train/unsup/49151_0.txt\n",
            "aclImdb/train/unsup/49150_0.txt\n",
            "aclImdb/train/unsup/49149_0.txt\n",
            "aclImdb/train/unsup/49148_0.txt\n",
            "aclImdb/train/unsup/49147_0.txt\n",
            "aclImdb/train/unsup/49146_0.txt\n",
            "aclImdb/train/unsup/49145_0.txt\n",
            "aclImdb/train/unsup/49144_0.txt\n",
            "aclImdb/train/unsup/49143_0.txt\n",
            "aclImdb/train/unsup/49142_0.txt\n",
            "aclImdb/train/unsup/49141_0.txt\n",
            "aclImdb/train/unsup/49140_0.txt\n",
            "aclImdb/train/unsup/49139_0.txt\n",
            "aclImdb/train/unsup/49138_0.txt\n",
            "aclImdb/train/unsup/49137_0.txt\n",
            "aclImdb/train/unsup/49136_0.txt\n",
            "aclImdb/train/unsup/49135_0.txt\n",
            "aclImdb/train/unsup/49134_0.txt\n",
            "aclImdb/train/unsup/49133_0.txt\n",
            "aclImdb/train/unsup/49132_0.txt\n",
            "aclImdb/train/unsup/49131_0.txt\n",
            "aclImdb/train/unsup/49130_0.txt\n",
            "aclImdb/train/unsup/49129_0.txt\n",
            "aclImdb/train/unsup/49128_0.txt\n",
            "aclImdb/train/unsup/49127_0.txt\n",
            "aclImdb/train/unsup/49126_0.txt\n",
            "aclImdb/train/unsup/49125_0.txt\n",
            "aclImdb/train/unsup/49124_0.txt\n",
            "aclImdb/train/unsup/49123_0.txt\n",
            "aclImdb/train/unsup/49122_0.txt\n",
            "aclImdb/train/unsup/49121_0.txt\n",
            "aclImdb/train/unsup/49120_0.txt\n",
            "aclImdb/train/unsup/49119_0.txt\n",
            "aclImdb/train/unsup/49118_0.txt\n",
            "aclImdb/train/unsup/49117_0.txt\n",
            "aclImdb/train/unsup/49116_0.txt\n",
            "aclImdb/train/unsup/49115_0.txt\n",
            "aclImdb/train/unsup/49114_0.txt\n",
            "aclImdb/train/unsup/49113_0.txt\n",
            "aclImdb/train/unsup/49112_0.txt\n",
            "aclImdb/train/unsup/49111_0.txt\n",
            "aclImdb/train/unsup/49110_0.txt\n",
            "aclImdb/train/unsup/49109_0.txt\n",
            "aclImdb/train/unsup/49108_0.txt\n",
            "aclImdb/train/unsup/49107_0.txt\n",
            "aclImdb/train/unsup/49106_0.txt\n",
            "aclImdb/train/unsup/49105_0.txt\n",
            "aclImdb/train/unsup/49104_0.txt\n",
            "aclImdb/train/unsup/49103_0.txt\n",
            "aclImdb/train/unsup/49102_0.txt\n",
            "aclImdb/train/unsup/49101_0.txt\n",
            "aclImdb/train/unsup/49100_0.txt\n",
            "aclImdb/train/unsup/49099_0.txt\n",
            "aclImdb/train/unsup/49098_0.txt\n",
            "aclImdb/train/unsup/49097_0.txt\n",
            "aclImdb/train/unsup/49096_0.txt\n",
            "aclImdb/train/unsup/49095_0.txt\n",
            "aclImdb/train/unsup/49094_0.txt\n",
            "aclImdb/train/unsup/49093_0.txt\n",
            "aclImdb/train/unsup/49092_0.txt\n",
            "aclImdb/train/unsup/49091_0.txt\n",
            "aclImdb/train/unsup/49090_0.txt\n",
            "aclImdb/train/unsup/49089_0.txt\n",
            "aclImdb/train/unsup/49088_0.txt\n",
            "aclImdb/train/unsup/49087_0.txt\n",
            "aclImdb/train/unsup/49086_0.txt\n",
            "aclImdb/train/unsup/49085_0.txt\n",
            "aclImdb/train/unsup/49084_0.txt\n",
            "aclImdb/train/unsup/49083_0.txt\n",
            "aclImdb/train/unsup/49082_0.txt\n",
            "aclImdb/train/unsup/49081_0.txt\n",
            "aclImdb/train/unsup/49080_0.txt\n",
            "aclImdb/train/unsup/49079_0.txt\n",
            "aclImdb/train/unsup/49078_0.txt\n",
            "aclImdb/train/unsup/49077_0.txt\n",
            "aclImdb/train/unsup/49076_0.txt\n",
            "aclImdb/train/unsup/49075_0.txt\n",
            "aclImdb/train/unsup/49074_0.txt\n",
            "aclImdb/train/unsup/49073_0.txt\n",
            "aclImdb/train/unsup/49072_0.txt\n",
            "aclImdb/train/unsup/49071_0.txt\n",
            "aclImdb/train/unsup/49070_0.txt\n",
            "aclImdb/train/unsup/49069_0.txt\n",
            "aclImdb/train/unsup/49068_0.txt\n",
            "aclImdb/train/unsup/49067_0.txt\n",
            "aclImdb/train/unsup/49066_0.txt\n",
            "aclImdb/train/unsup/49065_0.txt\n",
            "aclImdb/train/unsup/49064_0.txt\n",
            "aclImdb/train/unsup/49063_0.txt\n",
            "aclImdb/train/unsup/49062_0.txt\n",
            "aclImdb/train/unsup/49061_0.txt\n",
            "aclImdb/train/unsup/49060_0.txt\n",
            "aclImdb/train/unsup/49059_0.txt\n",
            "aclImdb/train/unsup/49058_0.txt\n",
            "aclImdb/train/unsup/49057_0.txt\n",
            "aclImdb/train/unsup/49056_0.txt\n",
            "aclImdb/train/unsup/49055_0.txt\n",
            "aclImdb/train/unsup/49054_0.txt\n",
            "aclImdb/train/unsup/49053_0.txt\n",
            "aclImdb/train/unsup/49052_0.txt\n",
            "aclImdb/train/unsup/49051_0.txt\n",
            "aclImdb/train/unsup/49050_0.txt\n",
            "aclImdb/train/unsup/49049_0.txt\n",
            "aclImdb/train/unsup/49048_0.txt\n",
            "aclImdb/train/unsup/49047_0.txt\n",
            "aclImdb/train/unsup/49046_0.txt\n",
            "aclImdb/train/unsup/49045_0.txt\n",
            "aclImdb/train/unsup/49044_0.txt\n",
            "aclImdb/train/unsup/49043_0.txt\n",
            "aclImdb/train/unsup/49042_0.txt\n",
            "aclImdb/train/unsup/49041_0.txt\n",
            "aclImdb/train/unsup/49040_0.txt\n",
            "aclImdb/train/unsup/49039_0.txt\n",
            "aclImdb/train/unsup/49038_0.txt\n",
            "aclImdb/train/unsup/49037_0.txt\n",
            "aclImdb/train/unsup/49036_0.txt\n",
            "aclImdb/train/unsup/49035_0.txt\n",
            "aclImdb/train/unsup/49034_0.txt\n",
            "aclImdb/train/unsup/49033_0.txt\n",
            "aclImdb/train/unsup/49032_0.txt\n",
            "aclImdb/train/unsup/49031_0.txt\n",
            "aclImdb/train/unsup/49030_0.txt\n",
            "aclImdb/train/unsup/49029_0.txt\n",
            "aclImdb/train/unsup/49028_0.txt\n",
            "aclImdb/train/unsup/49027_0.txt\n",
            "aclImdb/train/unsup/49026_0.txt\n",
            "aclImdb/train/unsup/49025_0.txt\n",
            "aclImdb/train/unsup/49024_0.txt\n",
            "aclImdb/train/unsup/49279_0.txt\n",
            "aclImdb/train/unsup/49278_0.txt\n",
            "aclImdb/train/unsup/49277_0.txt\n",
            "aclImdb/train/unsup/49276_0.txt\n",
            "aclImdb/train/unsup/49275_0.txt\n",
            "aclImdb/train/unsup/49274_0.txt\n",
            "aclImdb/train/unsup/49273_0.txt\n",
            "aclImdb/train/unsup/49272_0.txt\n",
            "aclImdb/train/unsup/49271_0.txt\n",
            "aclImdb/train/unsup/49270_0.txt\n",
            "aclImdb/train/unsup/49269_0.txt\n",
            "aclImdb/train/unsup/49268_0.txt\n",
            "aclImdb/train/unsup/49267_0.txt\n",
            "aclImdb/train/unsup/49266_0.txt\n",
            "aclImdb/train/unsup/49265_0.txt\n",
            "aclImdb/train/unsup/49264_0.txt\n",
            "aclImdb/train/unsup/49263_0.txt\n",
            "aclImdb/train/unsup/49262_0.txt\n",
            "aclImdb/train/unsup/49261_0.txt\n",
            "aclImdb/train/unsup/49260_0.txt\n",
            "aclImdb/train/unsup/49259_0.txt\n",
            "aclImdb/train/unsup/49258_0.txt\n",
            "aclImdb/train/unsup/49257_0.txt\n",
            "aclImdb/train/unsup/49256_0.txt\n",
            "aclImdb/train/unsup/49255_0.txt\n",
            "aclImdb/train/unsup/49254_0.txt\n",
            "aclImdb/train/unsup/49253_0.txt\n",
            "aclImdb/train/unsup/49252_0.txt\n",
            "aclImdb/train/unsup/49251_0.txt\n",
            "aclImdb/train/unsup/49250_0.txt\n",
            "aclImdb/train/unsup/49249_0.txt\n",
            "aclImdb/train/unsup/49248_0.txt\n",
            "aclImdb/train/unsup/49247_0.txt\n",
            "aclImdb/train/unsup/49246_0.txt\n",
            "aclImdb/train/unsup/49245_0.txt\n",
            "aclImdb/train/unsup/49244_0.txt\n",
            "aclImdb/train/unsup/49243_0.txt\n",
            "aclImdb/train/unsup/49242_0.txt\n",
            "aclImdb/train/unsup/49241_0.txt\n",
            "aclImdb/train/unsup/49240_0.txt\n",
            "aclImdb/train/unsup/49239_0.txt\n",
            "aclImdb/train/unsup/49238_0.txt\n",
            "aclImdb/train/unsup/49237_0.txt\n",
            "aclImdb/train/unsup/49236_0.txt\n",
            "aclImdb/train/unsup/49235_0.txt\n",
            "aclImdb/train/unsup/49234_0.txt\n",
            "aclImdb/train/unsup/49233_0.txt\n",
            "aclImdb/train/unsup/49232_0.txt\n",
            "aclImdb/train/unsup/49231_0.txt\n",
            "aclImdb/train/unsup/49230_0.txt\n",
            "aclImdb/train/unsup/49229_0.txt\n",
            "aclImdb/train/unsup/49228_0.txt\n",
            "aclImdb/train/unsup/49227_0.txt\n",
            "aclImdb/train/unsup/49226_0.txt\n",
            "aclImdb/train/unsup/49225_0.txt\n",
            "aclImdb/train/unsup/49224_0.txt\n",
            "aclImdb/train/unsup/49223_0.txt\n",
            "aclImdb/train/unsup/49222_0.txt\n",
            "aclImdb/train/unsup/49221_0.txt\n",
            "aclImdb/train/unsup/49220_0.txt\n",
            "aclImdb/train/unsup/49219_0.txt\n",
            "aclImdb/train/unsup/49218_0.txt\n",
            "aclImdb/train/unsup/49217_0.txt\n",
            "aclImdb/train/unsup/49216_0.txt\n",
            "aclImdb/train/unsup/49215_0.txt\n",
            "aclImdb/train/unsup/49214_0.txt\n",
            "aclImdb/train/unsup/49213_0.txt\n",
            "aclImdb/train/unsup/49212_0.txt\n",
            "aclImdb/train/unsup/49211_0.txt\n",
            "aclImdb/train/unsup/49210_0.txt\n",
            "aclImdb/train/unsup/49209_0.txt\n",
            "aclImdb/train/unsup/49208_0.txt\n",
            "aclImdb/train/unsup/49207_0.txt\n",
            "aclImdb/train/unsup/49206_0.txt\n",
            "aclImdb/train/unsup/49205_0.txt\n",
            "aclImdb/train/unsup/49204_0.txt\n",
            "aclImdb/train/unsup/49203_0.txt\n",
            "aclImdb/train/unsup/49202_0.txt\n",
            "aclImdb/train/unsup/49201_0.txt\n",
            "aclImdb/train/unsup/49200_0.txt\n",
            "aclImdb/train/unsup/49199_0.txt\n",
            "aclImdb/train/unsup/49198_0.txt\n",
            "aclImdb/train/unsup/49197_0.txt\n",
            "aclImdb/train/unsup/49196_0.txt\n",
            "aclImdb/train/unsup/49195_0.txt\n",
            "aclImdb/train/unsup/49194_0.txt\n",
            "aclImdb/train/unsup/49193_0.txt\n",
            "aclImdb/train/unsup/49192_0.txt\n",
            "aclImdb/train/unsup/49191_0.txt\n",
            "aclImdb/train/unsup/49190_0.txt\n",
            "aclImdb/train/unsup/49189_0.txt\n",
            "aclImdb/train/unsup/49188_0.txt\n",
            "aclImdb/train/unsup/49187_0.txt\n",
            "aclImdb/train/unsup/49186_0.txt\n",
            "aclImdb/train/unsup/49185_0.txt\n",
            "aclImdb/train/unsup/49184_0.txt\n",
            "aclImdb/train/unsup/49183_0.txt\n",
            "aclImdb/train/unsup/49182_0.txt\n",
            "aclImdb/train/unsup/49181_0.txt\n",
            "aclImdb/train/unsup/49180_0.txt\n",
            "aclImdb/train/unsup/49179_0.txt\n",
            "aclImdb/train/unsup/49178_0.txt\n",
            "aclImdb/train/unsup/49177_0.txt\n",
            "aclImdb/train/unsup/49176_0.txt\n",
            "aclImdb/train/unsup/49175_0.txt\n",
            "aclImdb/train/unsup/49174_0.txt\n",
            "aclImdb/train/unsup/49173_0.txt\n",
            "aclImdb/train/unsup/49172_0.txt\n",
            "aclImdb/train/unsup/49171_0.txt\n",
            "aclImdb/train/unsup/49170_0.txt\n",
            "aclImdb/train/unsup/49169_0.txt\n",
            "aclImdb/train/unsup/49168_0.txt\n",
            "aclImdb/train/unsup/49167_0.txt\n",
            "aclImdb/train/unsup/49166_0.txt\n",
            "aclImdb/train/unsup/49165_0.txt\n",
            "aclImdb/train/unsup/49164_0.txt\n",
            "aclImdb/train/unsup/49163_0.txt\n",
            "aclImdb/train/unsup/49162_0.txt\n",
            "aclImdb/train/unsup/49161_0.txt\n",
            "aclImdb/train/unsup/49160_0.txt\n",
            "aclImdb/train/unsup/49159_0.txt\n",
            "aclImdb/train/unsup/49158_0.txt\n",
            "aclImdb/train/unsup/49157_0.txt\n",
            "aclImdb/train/unsup/49156_0.txt\n",
            "aclImdb/train/unsup/49155_0.txt\n",
            "aclImdb/train/unsup/49154_0.txt\n",
            "aclImdb/train/unsup/49153_0.txt\n",
            "aclImdb/train/unsup/49152_0.txt\n",
            "aclImdb/train/unsup/49407_0.txt\n",
            "aclImdb/train/unsup/49406_0.txt\n",
            "aclImdb/train/unsup/49405_0.txt\n",
            "aclImdb/train/unsup/49404_0.txt\n",
            "aclImdb/train/unsup/49403_0.txt\n",
            "aclImdb/train/unsup/49402_0.txt\n",
            "aclImdb/train/unsup/49401_0.txt\n",
            "aclImdb/train/unsup/49400_0.txt\n",
            "aclImdb/train/unsup/49399_0.txt\n",
            "aclImdb/train/unsup/49398_0.txt\n",
            "aclImdb/train/unsup/49397_0.txt\n",
            "aclImdb/train/unsup/49396_0.txt\n",
            "aclImdb/train/unsup/49395_0.txt\n",
            "aclImdb/train/unsup/49394_0.txt\n",
            "aclImdb/train/unsup/49393_0.txt\n",
            "aclImdb/train/unsup/49392_0.txt\n",
            "aclImdb/train/unsup/49391_0.txt\n",
            "aclImdb/train/unsup/49390_0.txt\n",
            "aclImdb/train/unsup/49389_0.txt\n",
            "aclImdb/train/unsup/49388_0.txt\n",
            "aclImdb/train/unsup/49387_0.txt\n",
            "aclImdb/train/unsup/49386_0.txt\n",
            "aclImdb/train/unsup/49385_0.txt\n",
            "aclImdb/train/unsup/49384_0.txt\n",
            "aclImdb/train/unsup/49383_0.txt\n",
            "aclImdb/train/unsup/49382_0.txt\n",
            "aclImdb/train/unsup/49381_0.txt\n",
            "aclImdb/train/unsup/49380_0.txt\n",
            "aclImdb/train/unsup/49379_0.txt\n",
            "aclImdb/train/unsup/49378_0.txt\n",
            "aclImdb/train/unsup/49377_0.txt\n",
            "aclImdb/train/unsup/49376_0.txt\n",
            "aclImdb/train/unsup/49375_0.txt\n",
            "aclImdb/train/unsup/49374_0.txt\n",
            "aclImdb/train/unsup/49373_0.txt\n",
            "aclImdb/train/unsup/49372_0.txt\n",
            "aclImdb/train/unsup/49371_0.txt\n",
            "aclImdb/train/unsup/49370_0.txt\n",
            "aclImdb/train/unsup/49369_0.txt\n",
            "aclImdb/train/unsup/49368_0.txt\n",
            "aclImdb/train/unsup/49367_0.txt\n",
            "aclImdb/train/unsup/49366_0.txt\n",
            "aclImdb/train/unsup/49365_0.txt\n",
            "aclImdb/train/unsup/49364_0.txt\n",
            "aclImdb/train/unsup/49363_0.txt\n",
            "aclImdb/train/unsup/49362_0.txt\n",
            "aclImdb/train/unsup/49361_0.txt\n",
            "aclImdb/train/unsup/49360_0.txt\n",
            "aclImdb/train/unsup/49359_0.txt\n",
            "aclImdb/train/unsup/49358_0.txt\n",
            "aclImdb/train/unsup/49357_0.txt\n",
            "aclImdb/train/unsup/49356_0.txt\n",
            "aclImdb/train/unsup/49355_0.txt\n",
            "aclImdb/train/unsup/49354_0.txt\n",
            "aclImdb/train/unsup/49353_0.txt\n",
            "aclImdb/train/unsup/49352_0.txt\n",
            "aclImdb/train/unsup/49351_0.txt\n",
            "aclImdb/train/unsup/49350_0.txt\n",
            "aclImdb/train/unsup/49349_0.txt\n",
            "aclImdb/train/unsup/49348_0.txt\n",
            "aclImdb/train/unsup/49347_0.txt\n",
            "aclImdb/train/unsup/49346_0.txt\n",
            "aclImdb/train/unsup/49345_0.txt\n",
            "aclImdb/train/unsup/49344_0.txt\n",
            "aclImdb/train/unsup/49343_0.txt\n",
            "aclImdb/train/unsup/49342_0.txt\n",
            "aclImdb/train/unsup/49341_0.txt\n",
            "aclImdb/train/unsup/49340_0.txt\n",
            "aclImdb/train/unsup/49339_0.txt\n",
            "aclImdb/train/unsup/49338_0.txt\n",
            "aclImdb/train/unsup/49337_0.txt\n",
            "aclImdb/train/unsup/49336_0.txt\n",
            "aclImdb/train/unsup/49335_0.txt\n",
            "aclImdb/train/unsup/49334_0.txt\n",
            "aclImdb/train/unsup/49333_0.txt\n",
            "aclImdb/train/unsup/49332_0.txt\n",
            "aclImdb/train/unsup/49331_0.txt\n",
            "aclImdb/train/unsup/49330_0.txt\n",
            "aclImdb/train/unsup/49329_0.txt\n",
            "aclImdb/train/unsup/49328_0.txt\n",
            "aclImdb/train/unsup/49327_0.txt\n",
            "aclImdb/train/unsup/49326_0.txt\n",
            "aclImdb/train/unsup/49325_0.txt\n",
            "aclImdb/train/unsup/49324_0.txt\n",
            "aclImdb/train/unsup/49323_0.txt\n",
            "aclImdb/train/unsup/49322_0.txt\n",
            "aclImdb/train/unsup/49321_0.txt\n",
            "aclImdb/train/unsup/49320_0.txt\n",
            "aclImdb/train/unsup/49319_0.txt\n",
            "aclImdb/train/unsup/49318_0.txt\n",
            "aclImdb/train/unsup/49317_0.txt\n",
            "aclImdb/train/unsup/49316_0.txt\n",
            "aclImdb/train/unsup/49315_0.txt\n",
            "aclImdb/train/unsup/49314_0.txt\n",
            "aclImdb/train/unsup/49313_0.txt\n",
            "aclImdb/train/unsup/49312_0.txt\n",
            "aclImdb/train/unsup/49311_0.txt\n",
            "aclImdb/train/unsup/49310_0.txt\n",
            "aclImdb/train/unsup/49309_0.txt\n",
            "aclImdb/train/unsup/49308_0.txt\n",
            "aclImdb/train/unsup/49307_0.txt\n",
            "aclImdb/train/unsup/49306_0.txt\n",
            "aclImdb/train/unsup/49305_0.txt\n",
            "aclImdb/train/unsup/49304_0.txt\n",
            "aclImdb/train/unsup/49303_0.txt\n",
            "aclImdb/train/unsup/49302_0.txt\n",
            "aclImdb/train/unsup/49301_0.txt\n",
            "aclImdb/train/unsup/49300_0.txt\n",
            "aclImdb/train/unsup/49299_0.txt\n",
            "aclImdb/train/unsup/49298_0.txt\n",
            "aclImdb/train/unsup/49297_0.txt\n",
            "aclImdb/train/unsup/49296_0.txt\n",
            "aclImdb/train/unsup/49295_0.txt\n",
            "aclImdb/train/unsup/49294_0.txt\n",
            "aclImdb/train/unsup/49293_0.txt\n",
            "aclImdb/train/unsup/49292_0.txt\n",
            "aclImdb/train/unsup/49291_0.txt\n",
            "aclImdb/train/unsup/49290_0.txt\n",
            "aclImdb/train/unsup/49289_0.txt\n",
            "aclImdb/train/unsup/49288_0.txt\n",
            "aclImdb/train/unsup/49287_0.txt\n",
            "aclImdb/train/unsup/49286_0.txt\n",
            "aclImdb/train/unsup/49285_0.txt\n",
            "aclImdb/train/unsup/49284_0.txt\n",
            "aclImdb/train/unsup/49283_0.txt\n",
            "aclImdb/train/unsup/49282_0.txt\n",
            "aclImdb/train/unsup/49281_0.txt\n",
            "aclImdb/train/unsup/49280_0.txt\n",
            "aclImdb/train/unsup/49535_0.txt\n",
            "aclImdb/train/unsup/49534_0.txt\n",
            "aclImdb/train/unsup/49533_0.txt\n",
            "aclImdb/train/unsup/49532_0.txt\n",
            "aclImdb/train/unsup/49531_0.txt\n",
            "aclImdb/train/unsup/49530_0.txt\n",
            "aclImdb/train/unsup/49529_0.txt\n",
            "aclImdb/train/unsup/49528_0.txt\n",
            "aclImdb/train/unsup/49527_0.txt\n",
            "aclImdb/train/unsup/49526_0.txt\n",
            "aclImdb/train/unsup/49525_0.txt\n",
            "aclImdb/train/unsup/49524_0.txt\n",
            "aclImdb/train/unsup/49523_0.txt\n",
            "aclImdb/train/unsup/49522_0.txt\n",
            "aclImdb/train/unsup/49521_0.txt\n",
            "aclImdb/train/unsup/49520_0.txt\n",
            "aclImdb/train/unsup/49519_0.txt\n",
            "aclImdb/train/unsup/49518_0.txt\n",
            "aclImdb/train/unsup/49517_0.txt\n",
            "aclImdb/train/unsup/49516_0.txt\n",
            "aclImdb/train/unsup/49515_0.txt\n",
            "aclImdb/train/unsup/49514_0.txt\n",
            "aclImdb/train/unsup/49513_0.txt\n",
            "aclImdb/train/unsup/49512_0.txt\n",
            "aclImdb/train/unsup/49511_0.txt\n",
            "aclImdb/train/unsup/49510_0.txt\n",
            "aclImdb/train/unsup/49509_0.txt\n",
            "aclImdb/train/unsup/49508_0.txt\n",
            "aclImdb/train/unsup/49507_0.txt\n",
            "aclImdb/train/unsup/49506_0.txt\n",
            "aclImdb/train/unsup/49505_0.txt\n",
            "aclImdb/train/unsup/49504_0.txt\n",
            "aclImdb/train/unsup/49503_0.txt\n",
            "aclImdb/train/unsup/49502_0.txt\n",
            "aclImdb/train/unsup/49501_0.txt\n",
            "aclImdb/train/unsup/49500_0.txt\n",
            "aclImdb/train/unsup/49499_0.txt\n",
            "aclImdb/train/unsup/49498_0.txt\n",
            "aclImdb/train/unsup/49497_0.txt\n",
            "aclImdb/train/unsup/49496_0.txt\n",
            "aclImdb/train/unsup/49495_0.txt\n",
            "aclImdb/train/unsup/49494_0.txt\n",
            "aclImdb/train/unsup/49493_0.txt\n",
            "aclImdb/train/unsup/49492_0.txt\n",
            "aclImdb/train/unsup/49491_0.txt\n",
            "aclImdb/train/unsup/49490_0.txt\n",
            "aclImdb/train/unsup/49489_0.txt\n",
            "aclImdb/train/unsup/49488_0.txt\n",
            "aclImdb/train/unsup/49487_0.txt\n",
            "aclImdb/train/unsup/49486_0.txt\n",
            "aclImdb/train/unsup/49485_0.txt\n",
            "aclImdb/train/unsup/49484_0.txt\n",
            "aclImdb/train/unsup/49483_0.txt\n",
            "aclImdb/train/unsup/49482_0.txt\n",
            "aclImdb/train/unsup/49481_0.txt\n",
            "aclImdb/train/unsup/49480_0.txt\n",
            "aclImdb/train/unsup/49479_0.txt\n",
            "aclImdb/train/unsup/49478_0.txt\n",
            "aclImdb/train/unsup/49477_0.txt\n",
            "aclImdb/train/unsup/49476_0.txt\n",
            "aclImdb/train/unsup/49475_0.txt\n",
            "aclImdb/train/unsup/49474_0.txt\n",
            "aclImdb/train/unsup/49473_0.txt\n",
            "aclImdb/train/unsup/49472_0.txt\n",
            "aclImdb/train/unsup/49471_0.txt\n",
            "aclImdb/train/unsup/49470_0.txt\n",
            "aclImdb/train/unsup/49469_0.txt\n",
            "aclImdb/train/unsup/49468_0.txt\n",
            "aclImdb/train/unsup/49467_0.txt\n",
            "aclImdb/train/unsup/49466_0.txt\n",
            "aclImdb/train/unsup/49465_0.txt\n",
            "aclImdb/train/unsup/49464_0.txt\n",
            "aclImdb/train/unsup/49463_0.txt\n",
            "aclImdb/train/unsup/49462_0.txt\n",
            "aclImdb/train/unsup/49461_0.txt\n",
            "aclImdb/train/unsup/49460_0.txt\n",
            "aclImdb/train/unsup/49459_0.txt\n",
            "aclImdb/train/unsup/49458_0.txt\n",
            "aclImdb/train/unsup/49457_0.txt\n",
            "aclImdb/train/unsup/49456_0.txt\n",
            "aclImdb/train/unsup/49455_0.txt\n",
            "aclImdb/train/unsup/49454_0.txt\n",
            "aclImdb/train/unsup/49453_0.txt\n",
            "aclImdb/train/unsup/49452_0.txt\n",
            "aclImdb/train/unsup/49451_0.txt\n",
            "aclImdb/train/unsup/49450_0.txt\n",
            "aclImdb/train/unsup/49449_0.txt\n",
            "aclImdb/train/unsup/49448_0.txt\n",
            "aclImdb/train/unsup/49447_0.txt\n",
            "aclImdb/train/unsup/49446_0.txt\n",
            "aclImdb/train/unsup/49445_0.txt\n",
            "aclImdb/train/unsup/49444_0.txt\n",
            "aclImdb/train/unsup/49443_0.txt\n",
            "aclImdb/train/unsup/49442_0.txt\n",
            "aclImdb/train/unsup/49441_0.txt\n",
            "aclImdb/train/unsup/49440_0.txt\n",
            "aclImdb/train/unsup/49439_0.txt\n",
            "aclImdb/train/unsup/49438_0.txt\n",
            "aclImdb/train/unsup/49437_0.txt\n",
            "aclImdb/train/unsup/49436_0.txt\n",
            "aclImdb/train/unsup/49435_0.txt\n",
            "aclImdb/train/unsup/49434_0.txt\n",
            "aclImdb/train/unsup/49433_0.txt\n",
            "aclImdb/train/unsup/49432_0.txt\n",
            "aclImdb/train/unsup/49431_0.txt\n",
            "aclImdb/train/unsup/49430_0.txt\n",
            "aclImdb/train/unsup/49429_0.txt\n",
            "aclImdb/train/unsup/49428_0.txt\n",
            "aclImdb/train/unsup/49427_0.txt\n",
            "aclImdb/train/unsup/49426_0.txt\n",
            "aclImdb/train/unsup/49425_0.txt\n",
            "aclImdb/train/unsup/49424_0.txt\n",
            "aclImdb/train/unsup/49423_0.txt\n",
            "aclImdb/train/unsup/49422_0.txt\n",
            "aclImdb/train/unsup/49421_0.txt\n",
            "aclImdb/train/unsup/49420_0.txt\n",
            "aclImdb/train/unsup/49419_0.txt\n",
            "aclImdb/train/unsup/49418_0.txt\n",
            "aclImdb/train/unsup/49417_0.txt\n",
            "aclImdb/train/unsup/49416_0.txt\n",
            "aclImdb/train/unsup/49415_0.txt\n",
            "aclImdb/train/unsup/49414_0.txt\n",
            "aclImdb/train/unsup/49413_0.txt\n",
            "aclImdb/train/unsup/49412_0.txt\n",
            "aclImdb/train/unsup/49411_0.txt\n",
            "aclImdb/train/unsup/49410_0.txt\n",
            "aclImdb/train/unsup/49409_0.txt\n",
            "aclImdb/train/unsup/49408_0.txt\n",
            "aclImdb/train/unsup/49663_0.txt\n",
            "aclImdb/train/unsup/49662_0.txt\n",
            "aclImdb/train/unsup/49661_0.txt\n",
            "aclImdb/train/unsup/49660_0.txt\n",
            "aclImdb/train/unsup/49659_0.txt\n",
            "aclImdb/train/unsup/49658_0.txt\n",
            "aclImdb/train/unsup/49657_0.txt\n",
            "aclImdb/train/unsup/49656_0.txt\n",
            "aclImdb/train/unsup/49655_0.txt\n",
            "aclImdb/train/unsup/49654_0.txt\n",
            "aclImdb/train/unsup/49653_0.txt\n",
            "aclImdb/train/unsup/49652_0.txt\n",
            "aclImdb/train/unsup/49651_0.txt\n",
            "aclImdb/train/unsup/49650_0.txt\n",
            "aclImdb/train/unsup/49649_0.txt\n",
            "aclImdb/train/unsup/49648_0.txt\n",
            "aclImdb/train/unsup/49647_0.txt\n",
            "aclImdb/train/unsup/49646_0.txt\n",
            "aclImdb/train/unsup/49645_0.txt\n",
            "aclImdb/train/unsup/49644_0.txt\n",
            "aclImdb/train/unsup/49643_0.txt\n",
            "aclImdb/train/unsup/49642_0.txt\n",
            "aclImdb/train/unsup/49641_0.txt\n",
            "aclImdb/train/unsup/49640_0.txt\n",
            "aclImdb/train/unsup/49639_0.txt\n",
            "aclImdb/train/unsup/49638_0.txt\n",
            "aclImdb/train/unsup/49637_0.txt\n",
            "aclImdb/train/unsup/49636_0.txt\n",
            "aclImdb/train/unsup/49635_0.txt\n",
            "aclImdb/train/unsup/49634_0.txt\n",
            "aclImdb/train/unsup/49633_0.txt\n",
            "aclImdb/train/unsup/49632_0.txt\n",
            "aclImdb/train/unsup/49631_0.txt\n",
            "aclImdb/train/unsup/49630_0.txt\n",
            "aclImdb/train/unsup/49629_0.txt\n",
            "aclImdb/train/unsup/49628_0.txt\n",
            "aclImdb/train/unsup/49627_0.txt\n",
            "aclImdb/train/unsup/49626_0.txt\n",
            "aclImdb/train/unsup/49625_0.txt\n",
            "aclImdb/train/unsup/49624_0.txt\n",
            "aclImdb/train/unsup/49623_0.txt\n",
            "aclImdb/train/unsup/49622_0.txt\n",
            "aclImdb/train/unsup/49621_0.txt\n",
            "aclImdb/train/unsup/49620_0.txt\n",
            "aclImdb/train/unsup/49619_0.txt\n",
            "aclImdb/train/unsup/49618_0.txt\n",
            "aclImdb/train/unsup/49617_0.txt\n",
            "aclImdb/train/unsup/49616_0.txt\n",
            "aclImdb/train/unsup/49615_0.txt\n",
            "aclImdb/train/unsup/49614_0.txt\n",
            "aclImdb/train/unsup/49613_0.txt\n",
            "aclImdb/train/unsup/49612_0.txt\n",
            "aclImdb/train/unsup/49611_0.txt\n",
            "aclImdb/train/unsup/49610_0.txt\n",
            "aclImdb/train/unsup/49609_0.txt\n",
            "aclImdb/train/unsup/49608_0.txt\n",
            "aclImdb/train/unsup/49607_0.txt\n",
            "aclImdb/train/unsup/49606_0.txt\n",
            "aclImdb/train/unsup/49605_0.txt\n",
            "aclImdb/train/unsup/49604_0.txt\n",
            "aclImdb/train/unsup/49603_0.txt\n",
            "aclImdb/train/unsup/49602_0.txt\n",
            "aclImdb/train/unsup/49601_0.txt\n",
            "aclImdb/train/unsup/49600_0.txt\n",
            "aclImdb/train/unsup/49599_0.txt\n",
            "aclImdb/train/unsup/49598_0.txt\n",
            "aclImdb/train/unsup/49597_0.txt\n",
            "aclImdb/train/unsup/49596_0.txt\n",
            "aclImdb/train/unsup/49595_0.txt\n",
            "aclImdb/train/unsup/49594_0.txt\n",
            "aclImdb/train/unsup/49593_0.txt\n",
            "aclImdb/train/unsup/49592_0.txt\n",
            "aclImdb/train/unsup/49591_0.txt\n",
            "aclImdb/train/unsup/49590_0.txt\n",
            "aclImdb/train/unsup/49589_0.txt\n",
            "aclImdb/train/unsup/49588_0.txt\n",
            "aclImdb/train/unsup/49587_0.txt\n",
            "aclImdb/train/unsup/49586_0.txt\n",
            "aclImdb/train/unsup/49585_0.txt\n",
            "aclImdb/train/unsup/49584_0.txt\n",
            "aclImdb/train/unsup/49583_0.txt\n",
            "aclImdb/train/unsup/49582_0.txt\n",
            "aclImdb/train/unsup/49581_0.txt\n",
            "aclImdb/train/unsup/49580_0.txt\n",
            "aclImdb/train/unsup/49579_0.txt\n",
            "aclImdb/train/unsup/49578_0.txt\n",
            "aclImdb/train/unsup/49577_0.txt\n",
            "aclImdb/train/unsup/49576_0.txt\n",
            "aclImdb/train/unsup/49575_0.txt\n",
            "aclImdb/train/unsup/49574_0.txt\n",
            "aclImdb/train/unsup/49573_0.txt\n",
            "aclImdb/train/unsup/49572_0.txt\n",
            "aclImdb/train/unsup/49571_0.txt\n",
            "aclImdb/train/unsup/49570_0.txt\n",
            "aclImdb/train/unsup/49569_0.txt\n",
            "aclImdb/train/unsup/49568_0.txt\n",
            "aclImdb/train/unsup/49567_0.txt\n",
            "aclImdb/train/unsup/49566_0.txt\n",
            "aclImdb/train/unsup/49565_0.txt\n",
            "aclImdb/train/unsup/49564_0.txt\n",
            "aclImdb/train/unsup/49563_0.txt\n",
            "aclImdb/train/unsup/49562_0.txt\n",
            "aclImdb/train/unsup/49561_0.txt\n",
            "aclImdb/train/unsup/49560_0.txt\n",
            "aclImdb/train/unsup/49559_0.txt\n",
            "aclImdb/train/unsup/49558_0.txt\n",
            "aclImdb/train/unsup/49557_0.txt\n",
            "aclImdb/train/unsup/49556_0.txt\n",
            "aclImdb/train/unsup/49555_0.txt\n",
            "aclImdb/train/unsup/49554_0.txt\n",
            "aclImdb/train/unsup/49553_0.txt\n",
            "aclImdb/train/unsup/49552_0.txt\n",
            "aclImdb/train/unsup/49551_0.txt\n",
            "aclImdb/train/unsup/49550_0.txt\n",
            "aclImdb/train/unsup/49549_0.txt\n",
            "aclImdb/train/unsup/49548_0.txt\n",
            "aclImdb/train/unsup/49547_0.txt\n",
            "aclImdb/train/unsup/49546_0.txt\n",
            "aclImdb/train/unsup/49545_0.txt\n",
            "aclImdb/train/unsup/49544_0.txt\n",
            "aclImdb/train/unsup/49543_0.txt\n",
            "aclImdb/train/unsup/49542_0.txt\n",
            "aclImdb/train/unsup/49541_0.txt\n",
            "aclImdb/train/unsup/49540_0.txt\n",
            "aclImdb/train/unsup/49539_0.txt\n",
            "aclImdb/train/unsup/49538_0.txt\n",
            "aclImdb/train/unsup/49537_0.txt\n",
            "aclImdb/train/unsup/49536_0.txt\n",
            "aclImdb/train/unsup/49791_0.txt\n",
            "aclImdb/train/unsup/49790_0.txt\n",
            "aclImdb/train/unsup/49789_0.txt\n",
            "aclImdb/train/unsup/49788_0.txt\n",
            "aclImdb/train/unsup/49787_0.txt\n",
            "aclImdb/train/unsup/49786_0.txt\n",
            "aclImdb/train/unsup/49785_0.txt\n",
            "aclImdb/train/unsup/49784_0.txt\n",
            "aclImdb/train/unsup/49783_0.txt\n",
            "aclImdb/train/unsup/49782_0.txt\n",
            "aclImdb/train/unsup/49781_0.txt\n",
            "aclImdb/train/unsup/49780_0.txt\n",
            "aclImdb/train/unsup/49779_0.txt\n",
            "aclImdb/train/unsup/49778_0.txt\n",
            "aclImdb/train/unsup/49777_0.txt\n",
            "aclImdb/train/unsup/49776_0.txt\n",
            "aclImdb/train/unsup/49775_0.txt\n",
            "aclImdb/train/unsup/49774_0.txt\n",
            "aclImdb/train/unsup/49773_0.txt\n",
            "aclImdb/train/unsup/49772_0.txt\n",
            "aclImdb/train/unsup/49771_0.txt\n",
            "aclImdb/train/unsup/49770_0.txt\n",
            "aclImdb/train/unsup/49769_0.txt\n",
            "aclImdb/train/unsup/49768_0.txt\n",
            "aclImdb/train/unsup/49767_0.txt\n",
            "aclImdb/train/unsup/49766_0.txt\n",
            "aclImdb/train/unsup/49765_0.txt\n",
            "aclImdb/train/unsup/49764_0.txt\n",
            "aclImdb/train/unsup/49763_0.txt\n",
            "aclImdb/train/unsup/49762_0.txt\n",
            "aclImdb/train/unsup/49761_0.txt\n",
            "aclImdb/train/unsup/49760_0.txt\n",
            "aclImdb/train/unsup/49759_0.txt\n",
            "aclImdb/train/unsup/49758_0.txt\n",
            "aclImdb/train/unsup/49757_0.txt\n",
            "aclImdb/train/unsup/49756_0.txt\n",
            "aclImdb/train/unsup/49755_0.txt\n",
            "aclImdb/train/unsup/49754_0.txt\n",
            "aclImdb/train/unsup/49753_0.txt\n",
            "aclImdb/train/unsup/49752_0.txt\n",
            "aclImdb/train/unsup/49751_0.txt\n",
            "aclImdb/train/unsup/49750_0.txt\n",
            "aclImdb/train/unsup/49749_0.txt\n",
            "aclImdb/train/unsup/49748_0.txt\n",
            "aclImdb/train/unsup/49747_0.txt\n",
            "aclImdb/train/unsup/49746_0.txt\n",
            "aclImdb/train/unsup/49745_0.txt\n",
            "aclImdb/train/unsup/49744_0.txt\n",
            "aclImdb/train/unsup/49743_0.txt\n",
            "aclImdb/train/unsup/49742_0.txt\n",
            "aclImdb/train/unsup/49741_0.txt\n",
            "aclImdb/train/unsup/49740_0.txt\n",
            "aclImdb/train/unsup/49739_0.txt\n",
            "aclImdb/train/unsup/49738_0.txt\n",
            "aclImdb/train/unsup/49737_0.txt\n",
            "aclImdb/train/unsup/49736_0.txt\n",
            "aclImdb/train/unsup/49735_0.txt\n",
            "aclImdb/train/unsup/49734_0.txt\n",
            "aclImdb/train/unsup/49733_0.txt\n",
            "aclImdb/train/unsup/49732_0.txt\n",
            "aclImdb/train/unsup/49731_0.txt\n",
            "aclImdb/train/unsup/49730_0.txt\n",
            "aclImdb/train/unsup/49729_0.txt\n",
            "aclImdb/train/unsup/49728_0.txt\n",
            "aclImdb/train/unsup/49727_0.txt\n",
            "aclImdb/train/unsup/49726_0.txt\n",
            "aclImdb/train/unsup/49725_0.txt\n",
            "aclImdb/train/unsup/49724_0.txt\n",
            "aclImdb/train/unsup/49723_0.txt\n",
            "aclImdb/train/unsup/49722_0.txt\n",
            "aclImdb/train/unsup/49721_0.txt\n",
            "aclImdb/train/unsup/49720_0.txt\n",
            "aclImdb/train/unsup/49719_0.txt\n",
            "aclImdb/train/unsup/49718_0.txt\n",
            "aclImdb/train/unsup/49717_0.txt\n",
            "aclImdb/train/unsup/49716_0.txt\n",
            "aclImdb/train/unsup/49715_0.txt\n",
            "aclImdb/train/unsup/49714_0.txt\n",
            "aclImdb/train/unsup/49713_0.txt\n",
            "aclImdb/train/unsup/49712_0.txt\n",
            "aclImdb/train/unsup/49711_0.txt\n",
            "aclImdb/train/unsup/49710_0.txt\n",
            "aclImdb/train/unsup/49709_0.txt\n",
            "aclImdb/train/unsup/49708_0.txt\n",
            "aclImdb/train/unsup/49707_0.txt\n",
            "aclImdb/train/unsup/49706_0.txt\n",
            "aclImdb/train/unsup/49705_0.txt\n",
            "aclImdb/train/unsup/49704_0.txt\n",
            "aclImdb/train/unsup/49703_0.txt\n",
            "aclImdb/train/unsup/49702_0.txt\n",
            "aclImdb/train/unsup/49701_0.txt\n",
            "aclImdb/train/unsup/49700_0.txt\n",
            "aclImdb/train/unsup/49699_0.txt\n",
            "aclImdb/train/unsup/49698_0.txt\n",
            "aclImdb/train/unsup/49697_0.txt\n",
            "aclImdb/train/unsup/49696_0.txt\n",
            "aclImdb/train/unsup/49695_0.txt\n",
            "aclImdb/train/unsup/49694_0.txt\n",
            "aclImdb/train/unsup/49693_0.txt\n",
            "aclImdb/train/unsup/49692_0.txt\n",
            "aclImdb/train/unsup/49691_0.txt\n",
            "aclImdb/train/unsup/49690_0.txt\n",
            "aclImdb/train/unsup/49689_0.txt\n",
            "aclImdb/train/unsup/49688_0.txt\n",
            "aclImdb/train/unsup/49687_0.txt\n",
            "aclImdb/train/unsup/49686_0.txt\n",
            "aclImdb/train/unsup/49685_0.txt\n",
            "aclImdb/train/unsup/49684_0.txt\n",
            "aclImdb/train/unsup/49683_0.txt\n",
            "aclImdb/train/unsup/49682_0.txt\n",
            "aclImdb/train/unsup/49681_0.txt\n",
            "aclImdb/train/unsup/49680_0.txt\n",
            "aclImdb/train/unsup/49679_0.txt\n",
            "aclImdb/train/unsup/49678_0.txt\n",
            "aclImdb/train/unsup/49677_0.txt\n",
            "aclImdb/train/unsup/49676_0.txt\n",
            "aclImdb/train/unsup/49675_0.txt\n",
            "aclImdb/train/unsup/49674_0.txt\n",
            "aclImdb/train/unsup/49673_0.txt\n",
            "aclImdb/train/unsup/49672_0.txt\n",
            "aclImdb/train/unsup/49671_0.txt\n",
            "aclImdb/train/unsup/49670_0.txt\n",
            "aclImdb/train/unsup/49669_0.txt\n",
            "aclImdb/train/unsup/49668_0.txt\n",
            "aclImdb/train/unsup/49667_0.txt\n",
            "aclImdb/train/unsup/49666_0.txt\n",
            "aclImdb/train/unsup/49665_0.txt\n",
            "aclImdb/train/unsup/49664_0.txt\n",
            "aclImdb/train/unsup/49919_0.txt\n",
            "aclImdb/train/unsup/49918_0.txt\n",
            "aclImdb/train/unsup/49917_0.txt\n",
            "aclImdb/train/unsup/49916_0.txt\n",
            "aclImdb/train/unsup/49915_0.txt\n",
            "aclImdb/train/unsup/49914_0.txt\n",
            "aclImdb/train/unsup/49913_0.txt\n",
            "aclImdb/train/unsup/49912_0.txt\n",
            "aclImdb/train/unsup/49911_0.txt\n",
            "aclImdb/train/unsup/49910_0.txt\n",
            "aclImdb/train/unsup/49909_0.txt\n",
            "aclImdb/train/unsup/49908_0.txt\n",
            "aclImdb/train/unsup/49907_0.txt\n",
            "aclImdb/train/unsup/49906_0.txt\n",
            "aclImdb/train/unsup/49905_0.txt\n",
            "aclImdb/train/unsup/49904_0.txt\n",
            "aclImdb/train/unsup/49903_0.txt\n",
            "aclImdb/train/unsup/49902_0.txt\n",
            "aclImdb/train/unsup/49901_0.txt\n",
            "aclImdb/train/unsup/49900_0.txt\n",
            "aclImdb/train/unsup/49899_0.txt\n",
            "aclImdb/train/unsup/49898_0.txt\n",
            "aclImdb/train/unsup/49897_0.txt\n",
            "aclImdb/train/unsup/49896_0.txt\n",
            "aclImdb/train/unsup/49895_0.txt\n",
            "aclImdb/train/unsup/49894_0.txt\n",
            "aclImdb/train/unsup/49893_0.txt\n",
            "aclImdb/train/unsup/49892_0.txt\n",
            "aclImdb/train/unsup/49891_0.txt\n",
            "aclImdb/train/unsup/49890_0.txt\n",
            "aclImdb/train/unsup/49889_0.txt\n",
            "aclImdb/train/unsup/49888_0.txt\n",
            "aclImdb/train/unsup/49887_0.txt\n",
            "aclImdb/train/unsup/49886_0.txt\n",
            "aclImdb/train/unsup/49885_0.txt\n",
            "aclImdb/train/unsup/49884_0.txt\n",
            "aclImdb/train/unsup/49883_0.txt\n",
            "aclImdb/train/unsup/49882_0.txt\n",
            "aclImdb/train/unsup/49881_0.txt\n",
            "aclImdb/train/unsup/49880_0.txt\n",
            "aclImdb/train/unsup/49879_0.txt\n",
            "aclImdb/train/unsup/49878_0.txt\n",
            "aclImdb/train/unsup/49877_0.txt\n",
            "aclImdb/train/unsup/49876_0.txt\n",
            "aclImdb/train/unsup/49875_0.txt\n",
            "aclImdb/train/unsup/49874_0.txt\n",
            "aclImdb/train/unsup/49873_0.txt\n",
            "aclImdb/train/unsup/49872_0.txt\n",
            "aclImdb/train/unsup/49871_0.txt\n",
            "aclImdb/train/unsup/49870_0.txt\n",
            "aclImdb/train/unsup/49869_0.txt\n",
            "aclImdb/train/unsup/49868_0.txt\n",
            "aclImdb/train/unsup/49867_0.txt\n",
            "aclImdb/train/unsup/49866_0.txt\n",
            "aclImdb/train/unsup/49865_0.txt\n",
            "aclImdb/train/unsup/49864_0.txt\n",
            "aclImdb/train/unsup/49863_0.txt\n",
            "aclImdb/train/unsup/49862_0.txt\n",
            "aclImdb/train/unsup/49861_0.txt\n",
            "aclImdb/train/unsup/49860_0.txt\n",
            "aclImdb/train/unsup/49859_0.txt\n",
            "aclImdb/train/unsup/49858_0.txt\n",
            "aclImdb/train/unsup/49857_0.txt\n",
            "aclImdb/train/unsup/49856_0.txt\n",
            "aclImdb/train/unsup/49855_0.txt\n",
            "aclImdb/train/unsup/49854_0.txt\n",
            "aclImdb/train/unsup/49853_0.txt\n",
            "aclImdb/train/unsup/49852_0.txt\n",
            "aclImdb/train/unsup/49851_0.txt\n",
            "aclImdb/train/unsup/49850_0.txt\n",
            "aclImdb/train/unsup/49849_0.txt\n",
            "aclImdb/train/unsup/49848_0.txt\n",
            "aclImdb/train/unsup/49847_0.txt\n",
            "aclImdb/train/unsup/49846_0.txt\n",
            "aclImdb/train/unsup/49845_0.txt\n",
            "aclImdb/train/unsup/49844_0.txt\n",
            "aclImdb/train/unsup/49843_0.txt\n",
            "aclImdb/train/unsup/49842_0.txt\n",
            "aclImdb/train/unsup/49841_0.txt\n",
            "aclImdb/train/unsup/49840_0.txt\n",
            "aclImdb/train/unsup/49839_0.txt\n",
            "aclImdb/train/unsup/49838_0.txt\n",
            "aclImdb/train/unsup/49837_0.txt\n",
            "aclImdb/train/unsup/49836_0.txt\n",
            "aclImdb/train/unsup/49835_0.txt\n",
            "aclImdb/train/unsup/49834_0.txt\n",
            "aclImdb/train/unsup/49833_0.txt\n",
            "aclImdb/train/unsup/49832_0.txt\n",
            "aclImdb/train/unsup/49831_0.txt\n",
            "aclImdb/train/unsup/49830_0.txt\n",
            "aclImdb/train/unsup/49829_0.txt\n",
            "aclImdb/train/unsup/49828_0.txt\n",
            "aclImdb/train/unsup/49827_0.txt\n",
            "aclImdb/train/unsup/49826_0.txt\n",
            "aclImdb/train/unsup/49825_0.txt\n",
            "aclImdb/train/unsup/49824_0.txt\n",
            "aclImdb/train/unsup/49823_0.txt\n",
            "aclImdb/train/unsup/49822_0.txt\n",
            "aclImdb/train/unsup/49821_0.txt\n",
            "aclImdb/train/unsup/49820_0.txt\n",
            "aclImdb/train/unsup/49819_0.txt\n",
            "aclImdb/train/unsup/49818_0.txt\n",
            "aclImdb/train/unsup/49817_0.txt\n",
            "aclImdb/train/unsup/49816_0.txt\n",
            "aclImdb/train/unsup/49815_0.txt\n",
            "aclImdb/train/unsup/49814_0.txt\n",
            "aclImdb/train/unsup/49813_0.txt\n",
            "aclImdb/train/unsup/49812_0.txt\n",
            "aclImdb/train/unsup/49811_0.txt\n",
            "aclImdb/train/unsup/49810_0.txt\n",
            "aclImdb/train/unsup/49809_0.txt\n",
            "aclImdb/train/unsup/49808_0.txt\n",
            "aclImdb/train/unsup/49807_0.txt\n",
            "aclImdb/train/unsup/49806_0.txt\n",
            "aclImdb/train/unsup/49805_0.txt\n",
            "aclImdb/train/unsup/49804_0.txt\n",
            "aclImdb/train/unsup/49803_0.txt\n",
            "aclImdb/train/unsup/49802_0.txt\n",
            "aclImdb/train/unsup/49801_0.txt\n",
            "aclImdb/train/unsup/49800_0.txt\n",
            "aclImdb/train/unsup/49799_0.txt\n",
            "aclImdb/train/unsup/49798_0.txt\n",
            "aclImdb/train/unsup/49797_0.txt\n",
            "aclImdb/train/unsup/49796_0.txt\n",
            "aclImdb/train/unsup/49795_0.txt\n",
            "aclImdb/train/unsup/49794_0.txt\n",
            "aclImdb/train/unsup/49793_0.txt\n",
            "aclImdb/train/unsup/49792_0.txt\n",
            "aclImdb/train/unsup/49999_0.txt\n",
            "aclImdb/train/unsup/49998_0.txt\n",
            "aclImdb/train/unsup/49997_0.txt\n",
            "aclImdb/train/unsup/49996_0.txt\n",
            "aclImdb/train/unsup/49995_0.txt\n",
            "aclImdb/train/unsup/49994_0.txt\n",
            "aclImdb/train/unsup/49993_0.txt\n",
            "aclImdb/train/unsup/49992_0.txt\n",
            "aclImdb/train/unsup/49991_0.txt\n",
            "aclImdb/train/unsup/49990_0.txt\n",
            "aclImdb/train/unsup/49989_0.txt\n",
            "aclImdb/train/unsup/49988_0.txt\n",
            "aclImdb/train/unsup/49987_0.txt\n",
            "aclImdb/train/unsup/49986_0.txt\n",
            "aclImdb/train/unsup/49985_0.txt\n",
            "aclImdb/train/unsup/49984_0.txt\n",
            "aclImdb/train/unsup/49983_0.txt\n",
            "aclImdb/train/unsup/49982_0.txt\n",
            "aclImdb/train/unsup/49981_0.txt\n",
            "aclImdb/train/unsup/49980_0.txt\n",
            "aclImdb/train/unsup/49979_0.txt\n",
            "aclImdb/train/unsup/49978_0.txt\n",
            "aclImdb/train/unsup/49977_0.txt\n",
            "aclImdb/train/unsup/49976_0.txt\n",
            "aclImdb/train/unsup/49975_0.txt\n",
            "aclImdb/train/unsup/49974_0.txt\n",
            "aclImdb/train/unsup/49973_0.txt\n",
            "aclImdb/train/unsup/49972_0.txt\n",
            "aclImdb/train/unsup/49971_0.txt\n",
            "aclImdb/train/unsup/49970_0.txt\n",
            "aclImdb/train/unsup/49969_0.txt\n",
            "aclImdb/train/unsup/49968_0.txt\n",
            "aclImdb/train/unsup/49967_0.txt\n",
            "aclImdb/train/unsup/49966_0.txt\n",
            "aclImdb/train/unsup/49965_0.txt\n",
            "aclImdb/train/unsup/49964_0.txt\n",
            "aclImdb/train/unsup/49963_0.txt\n",
            "aclImdb/train/unsup/49962_0.txt\n",
            "aclImdb/train/unsup/49961_0.txt\n",
            "aclImdb/train/unsup/49960_0.txt\n",
            "aclImdb/train/unsup/49959_0.txt\n",
            "aclImdb/train/unsup/49958_0.txt\n",
            "aclImdb/train/unsup/49957_0.txt\n",
            "aclImdb/train/unsup/49956_0.txt\n",
            "aclImdb/train/unsup/49955_0.txt\n",
            "aclImdb/train/unsup/49954_0.txt\n",
            "aclImdb/train/unsup/49953_0.txt\n",
            "aclImdb/train/unsup/49952_0.txt\n",
            "aclImdb/train/unsup/49951_0.txt\n",
            "aclImdb/train/unsup/49950_0.txt\n",
            "aclImdb/train/unsup/49949_0.txt\n",
            "aclImdb/train/unsup/49948_0.txt\n",
            "aclImdb/train/unsup/49947_0.txt\n",
            "aclImdb/train/unsup/49946_0.txt\n",
            "aclImdb/train/unsup/49945_0.txt\n",
            "aclImdb/train/unsup/49944_0.txt\n",
            "aclImdb/train/unsup/49943_0.txt\n",
            "aclImdb/train/unsup/49942_0.txt\n",
            "aclImdb/train/unsup/49941_0.txt\n",
            "aclImdb/train/unsup/49940_0.txt\n",
            "aclImdb/train/unsup/49939_0.txt\n",
            "aclImdb/train/unsup/49938_0.txt\n",
            "aclImdb/train/unsup/49937_0.txt\n",
            "aclImdb/train/unsup/49936_0.txt\n",
            "aclImdb/train/unsup/49935_0.txt\n",
            "aclImdb/train/unsup/49934_0.txt\n",
            "aclImdb/train/unsup/49933_0.txt\n",
            "aclImdb/train/unsup/49932_0.txt\n",
            "aclImdb/train/unsup/49931_0.txt\n",
            "aclImdb/train/unsup/49930_0.txt\n",
            "aclImdb/train/unsup/49929_0.txt\n",
            "aclImdb/train/unsup/49928_0.txt\n",
            "aclImdb/train/unsup/49927_0.txt\n",
            "aclImdb/train/unsup/49926_0.txt\n",
            "aclImdb/train/unsup/49925_0.txt\n",
            "aclImdb/train/unsup/49924_0.txt\n",
            "aclImdb/train/unsup/49923_0.txt\n",
            "aclImdb/train/unsup/49922_0.txt\n",
            "aclImdb/train/unsup/49921_0.txt\n",
            "aclImdb/train/unsup/49920_0.txt\n"
          ]
        }
      ],
      "source": [
        "!tar -xzvf \"/content/drive/MyDrive/aclImdb_v1.tar.gz\" #Extract The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtiW06m8i0LB",
        "outputId": "9a6d9cc5-418c-4b46-a7ff-14efc062643c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#WORD2VEC Word Embeddings\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn import Module, Embedding\n",
        "from torch.optim import Adam\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# Define the Dataset\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, root_dir, vocab_size=20000):\n",
        "        self.word_to_index = {\"<UNK>\": 0}\n",
        "        self.index_to_word = [\"<UNK>\"]\n",
        "        self.vocab_size = vocab_size\n",
        "        self.data = []\n",
        "        self.construct_dataset(root_dir)\n",
        "\n",
        "    def construct_dataset(self, root_dir):\n",
        "        word_counter = Counter()\n",
        "        for sentiment in ['pos', 'neg']:\n",
        "            dir_path = os.path.join(root_dir, sentiment)\n",
        "            for filename in os.listdir(dir_path):\n",
        "                with open(os.path.join(dir_path, filename), 'r', encoding='utf-8') as file:\n",
        "                    text = file.read().lower().replace('<br />', ' ')\n",
        "                    words = text.split()\n",
        "                    word_counter.update(words)\n",
        "                    if len(words) < 2:\n",
        "                        continue\n",
        "                    for i, word in enumerate(words):\n",
        "                        current_index = self.word_to_index.get(word, self.word_to_index[\"<UNK>\"])\n",
        "                        context_indices = [self.word_to_index.get(words[j], self.word_to_index[\"<UNK>\"])\n",
        "                                           for j in range(max(0, i-2), min(len(words), i+3)) if j != i]\n",
        "                        self.data.append((current_index, context_indices))\n",
        "        self.index_to_word = [word for word, _ in word_counter.most_common(self.vocab_size)]\n",
        "        self.word_to_index = {word: idx for idx, word in enumerate(self.index_to_word)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        center, context = self.data[idx]\n",
        "        context = random.choice(context)\n",
        "        return center, context\n",
        "\n",
        "    def get_negative_samples(self, batch_size, k=5):\n",
        "        return torch.randint(0, self.vocab_size, (batch_size, k), dtype=torch.long)\n",
        "\n",
        "# Define the Model\n",
        "class SkipGramModel(Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(SkipGramModel, self).__init__()\n",
        "        self.in_embeddings = Embedding(vocab_size, embedding_dim)\n",
        "        self.out_embeddings = Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    def forward(self, center_words, context_words, negative_samples):\n",
        "        center_embeds = self.in_embeddings(center_words)\n",
        "        context_embeds = self.out_embeddings(context_words)\n",
        "        negative_embeds = self.out_embeddings(negative_samples)\n",
        "\n",
        "        positive_score = torch.sum(center_embeds * context_embeds, dim=1)\n",
        "        negative_score = torch.sum(center_embeds.unsqueeze(1) * negative_embeds, dim=2)\n",
        "\n",
        "        positive_loss = -torch.log(torch.sigmoid(positive_score) + 1e-10)\n",
        "        negative_loss = -torch.log(1 - torch.sigmoid(negative_score) + 1e-10).mean(1)\n",
        "\n",
        "        loss = positive_loss.mean() + negative_loss.mean()\n",
        "        return loss\n",
        "\n",
        "\n",
        "def train(model, data_loader, optimizer, device, epochs=5):\n",
        "    model = model.to(device)\n",
        "    scaler = GradScaler()  # Initialize the GradScaler\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for i, (center, context) in enumerate(data_loader):\n",
        "            center = center.to(device)\n",
        "            context = context.to(device)\n",
        "            negative_samples = data_loader.dataset.get_negative_samples(center.size(0)).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with autocast():  # Run model in mixed precision\n",
        "                loss = model(center, context, negative_samples)\n",
        "            scaler.scale(loss).backward()  # Scale the loss\n",
        "            scaler.step(optimizer)  # Update optimizer\n",
        "            scaler.update()  # Update the scaler\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            if i % 100 == 0:  # Update tqdm every 100 batches\n",
        "                print(f\"Batch {i}, Loss: {loss.item()}\")\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Average Loss: {total_loss / len(data_loader)}\")\n",
        "\n",
        "\n",
        "# Setup and Run Training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dataset = ReviewDataset('/content/aclImdb/train', vocab_size=10000)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
        "model = SkipGramModel(vocab_size=10000, embedding_dim=100)\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train(model, dataloader, optimizer, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0ANdU2YZVfY",
        "outputId": "b573192b-f9d6-49ce-835a-0775962ae2e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0, Loss: 4.238705158233643\n",
            "Batch 100, Loss: 3.6941821575164795\n",
            "Batch 200, Loss: 3.272890567779541\n",
            "Batch 300, Loss: 2.123722553253174\n",
            "Batch 400, Loss: 1.8377832174301147\n",
            "Batch 500, Loss: 1.5743368864059448\n",
            "Batch 600, Loss: 1.3445556163787842\n",
            "Batch 700, Loss: 1.1807643175125122\n",
            "Batch 800, Loss: 0.6257891058921814\n",
            "Batch 900, Loss: 0.6045202016830444\n",
            "Batch 1000, Loss: 0.6723605394363403\n",
            "Batch 1100, Loss: 0.3085237741470337\n",
            "Batch 1200, Loss: 0.21806034445762634\n",
            "Batch 1300, Loss: 0.7703557014465332\n",
            "Batch 1400, Loss: 0.5587078332901001\n",
            "Batch 1500, Loss: 0.39953041076660156\n",
            "Batch 1600, Loss: 0.51900315284729\n",
            "Batch 1700, Loss: 0.5164499878883362\n",
            "Batch 1800, Loss: 0.30594199895858765\n",
            "Batch 1900, Loss: 0.4397246837615967\n",
            "Batch 2000, Loss: 0.2951381206512451\n",
            "Batch 2100, Loss: 0.3660276234149933\n",
            "Batch 2200, Loss: 0.2927224338054657\n",
            "Batch 2300, Loss: 0.436432421207428\n",
            "Batch 2400, Loss: 0.43652698397636414\n",
            "Batch 2500, Loss: 0.4357420802116394\n",
            "Batch 2600, Loss: 0.4350638687610626\n",
            "Batch 2700, Loss: 0.5065727233886719\n",
            "Batch 2800, Loss: 0.2907644212245941\n",
            "Batch 2900, Loss: 0.07456421852111816\n",
            "Batch 3000, Loss: 0.5057048797607422\n",
            "Batch 3100, Loss: 0.14593033492565155\n",
            "Batch 3200, Loss: 0.14606671035289764\n",
            "Batch 3300, Loss: 0.3618641495704651\n",
            "Batch 3400, Loss: 0.21771633625030518\n",
            "Batch 3500, Loss: 0.2894503176212311\n",
            "Batch 3600, Loss: 0.36146947741508484\n",
            "Batch 3700, Loss: 0.14516136050224304\n",
            "Batch 3800, Loss: 0.2888539433479309\n",
            "Batch 3900, Loss: 0.5050911903381348\n",
            "Batch 4000, Loss: 0.4328659474849701\n",
            "Batch 4100, Loss: 0.4327598810195923\n",
            "Batch 4200, Loss: 0.2886074185371399\n",
            "Batch 4300, Loss: 0.46221235394477844\n",
            "Batch 4400, Loss: 0.5045093894004822\n",
            "Batch 4500, Loss: 0.46137547492980957\n",
            "Batch 4600, Loss: 0.21668657660484314\n",
            "Batch 4700, Loss: 0.43256303668022156\n",
            "Batch 4800, Loss: 0.14459341764450073\n",
            "Batch 4900, Loss: 0.43234488368034363\n",
            "Batch 5000, Loss: 0.4323209524154663\n",
            "Batch 5100, Loss: 0.3603636622428894\n",
            "Batch 5200, Loss: 0.4321603775024414\n",
            "Batch 5300, Loss: 0.648131251335144\n",
            "Batch 5400, Loss: 0.2883526384830475\n",
            "Batch 5500, Loss: 0.4322062134742737\n",
            "Batch 5600, Loss: 0.3602232336997986\n",
            "Batch 5700, Loss: 0.3601425588130951\n",
            "Batch 5800, Loss: 0.43209266662597656\n",
            "Batch 5900, Loss: 0.14426356554031372\n",
            "Batch 6000, Loss: 0.28820550441741943\n",
            "Batch 6100, Loss: 0.3600982427597046\n",
            "Batch 6200, Loss: 0.288247674703598\n",
            "Batch 6300, Loss: 0.5040733814239502\n",
            "Batch 6400, Loss: 0.3603408932685852\n",
            "Batch 6500, Loss: 0.5040356516838074\n",
            "Batch 6600, Loss: 0.6061065196990967\n",
            "Batch 6700, Loss: 0.5759367942810059\n",
            "Batch 6800, Loss: 0.7199171185493469\n",
            "Batch 6900, Loss: 0.3600115180015564\n",
            "Batch 7000, Loss: 0.4319879114627838\n",
            "Batch 7100, Loss: 0.576245903968811\n",
            "Batch 7200, Loss: 0.7202109694480896\n",
            "Batch 7300, Loss: 0.5431752800941467\n",
            "Batch 7400, Loss: 0.3599841296672821\n",
            "Batch 7500, Loss: 0.28800463676452637\n",
            "Batch 7600, Loss: 0.00016128191782627255\n",
            "Batch 7700, Loss: 0.2879803478717804\n",
            "Batch 7800, Loss: 0.43187713623046875\n",
            "Batch 7900, Loss: 0.5758370161056519\n",
            "Batch 8000, Loss: 0.17251455783843994\n",
            "Batch 8100, Loss: 0.791691243648529\n",
            "Batch 8200, Loss: 0.28802379965782166\n",
            "Batch 8300, Loss: 0.38460078835487366\n",
            "Batch 8400, Loss: 0.4320087432861328\n",
            "Batch 8500, Loss: 0.21603766083717346\n",
            "Batch 8600, Loss: 0.14407673478126526\n",
            "Batch 8700, Loss: 0.2881968915462494\n",
            "Batch 8800, Loss: 0.257780522108078\n",
            "Batch 8900, Loss: 0.4331011474132538\n",
            "Batch 9000, Loss: 0.12208395451307297\n",
            "Batch 9100, Loss: 0.33745718002319336\n",
            "Batch 9200, Loss: 0.18045884370803833\n",
            "Batch 9300, Loss: 0.14805036783218384\n",
            "Batch 9400, Loss: 0.07415300607681274\n",
            "Batch 9500, Loss: 0.07703274488449097\n",
            "Batch 9600, Loss: 0.0862019881606102\n",
            "Batch 9700, Loss: 0.17375461757183075\n",
            "Batch 9800, Loss: 0.14417408406734467\n",
            "Batch 9900, Loss: 0.07342251390218735\n",
            "Batch 10000, Loss: 0.18833892047405243\n",
            "Batch 10100, Loss: 0.07310584932565689\n",
            "Batch 10200, Loss: 0.21948015689849854\n",
            "Batch 10300, Loss: 0.2161036878824234\n",
            "Batch 10400, Loss: 0.07310094684362411\n",
            "Batch 10500, Loss: 0.14406287670135498\n",
            "Batch 10600, Loss: 0.07222415506839752\n",
            "Batch 10700, Loss: 0.09980572760105133\n",
            "Batch 10800, Loss: 0.07229723036289215\n",
            "Batch 10900, Loss: 0.07231095433235168\n",
            "Batch 11000, Loss: 0.07218048721551895\n",
            "Batch 11100, Loss: 0.0003686650888994336\n",
            "Batch 11200, Loss: 0.07221396267414093\n",
            "Batch 11300, Loss: 0.14418350160121918\n",
            "Batch 11400, Loss: 0.14418186247348785\n",
            "Batch 11500, Loss: 0.000337133533321321\n",
            "Batch 11600, Loss: 0.07205476611852646\n",
            "Batch 11700, Loss: 0.07209790498018265\n",
            "Batch 11800, Loss: 0.07209134101867676\n",
            "Batch 11900, Loss: 0.1331205815076828\n",
            "Batch 12000, Loss: 0.07211446762084961\n",
            "Batch 12100, Loss: 0.00015655554307159036\n",
            "Batch 12200, Loss: 0.07214482128620148\n",
            "Batch 12300, Loss: 0.0721760168671608\n",
            "Batch 12400, Loss: 0.07219871133565903\n",
            "Batch 12500, Loss: 0.07208897918462753\n",
            "Batch 12600, Loss: 0.07220235466957092\n",
            "Batch 12700, Loss: 0.072088822722435\n",
            "Batch 12800, Loss: 0.07228460907936096\n",
            "Batch 12900, Loss: 0.07232201099395752\n",
            "Batch 13000, Loss: 0.14418891072273254\n",
            "Batch 13100, Loss: 0.10651367157697678\n",
            "Batch 13200, Loss: 0.07244639843702316\n",
            "Batch 13300, Loss: 0.14413520693778992\n",
            "Batch 13400, Loss: 0.008302919566631317\n",
            "Batch 13500, Loss: 0.00010946279508061707\n",
            "Batch 13600, Loss: 0.0002180399460485205\n",
            "Batch 13700, Loss: 0.07208932191133499\n",
            "Batch 13800, Loss: 0.07209049165248871\n",
            "Batch 13900, Loss: 0.07211124897003174\n",
            "Batch 14000, Loss: 0.07233819365501404\n",
            "Batch 14100, Loss: 0.07209677249193192\n",
            "Batch 14200, Loss: 0.07219412177801132\n",
            "Batch 14300, Loss: 0.07219954580068588\n",
            "Batch 14400, Loss: 0.14403685927391052\n",
            "Batch 14500, Loss: 0.00014705999637953937\n",
            "Batch 14600, Loss: 0.07209338247776031\n",
            "Batch 14700, Loss: 0.00017827789997681975\n",
            "Batch 14800, Loss: 0.21602432429790497\n",
            "Batch 14900, Loss: 0.14405225217342377\n",
            "Batch 15000, Loss: 0.07207999378442764\n",
            "Batch 15100, Loss: 0.00017932665650732815\n",
            "Batch 15200, Loss: 7.685744640184566e-05\n",
            "Batch 15300, Loss: 0.0720510333776474\n",
            "Batch 15400, Loss: 5.806742046843283e-05\n",
            "Batch 15500, Loss: 0.07200268656015396\n",
            "Batch 15600, Loss: 0.0001901591895148158\n",
            "Batch 15700, Loss: 0.0721067413687706\n",
            "Batch 15800, Loss: 0.14401239156723022\n",
            "Batch 15900, Loss: 0.14409856498241425\n",
            "Batch 16000, Loss: 0.00011165678733959794\n",
            "Batch 16100, Loss: 7.95957530499436e-05\n",
            "Batch 16200, Loss: 0.00012898851127829403\n",
            "Batch 16300, Loss: 5.6413220590911806e-05\n",
            "Batch 16400, Loss: 0.07221601903438568\n",
            "Batch 16500, Loss: 0.14403654634952545\n",
            "Batch 16600, Loss: 0.00011383682431187481\n",
            "Batch 16700, Loss: 4.80698945466429e-05\n",
            "Batch 16800, Loss: 3.5768793168244883e-05\n",
            "Batch 16900, Loss: 7.521610677940771e-05\n",
            "Batch 17000, Loss: 0.07201507687568665\n",
            "Batch 17100, Loss: 0.00022720277775079012\n",
            "Batch 17200, Loss: 3.840768476948142e-05\n",
            "Batch 17300, Loss: 0.07226207107305527\n",
            "Batch 17400, Loss: 0.00012312673788983375\n",
            "Batch 17500, Loss: 0.07204321026802063\n",
            "Batch 17600, Loss: 0.07205793261528015\n",
            "Batch 17700, Loss: 4.497021291172132e-05\n",
            "Batch 17800, Loss: 0.0001274222886422649\n",
            "Batch 17900, Loss: 0.00010327222844352946\n",
            "Batch 18000, Loss: 3.335433575557545e-05\n",
            "Batch 18100, Loss: 0.14405159652233124\n",
            "Batch 18200, Loss: 0.07211682945489883\n",
            "Batch 18300, Loss: 0.07201370596885681\n",
            "Batch 18400, Loss: 6.332137127174065e-05\n",
            "Batch 18500, Loss: 0.07201919704675674\n",
            "Batch 18600, Loss: 0.00012977633741684258\n",
            "Batch 18700, Loss: 6.659207429038361e-05\n",
            "Batch 18800, Loss: 0.14428453147411346\n",
            "Batch 18900, Loss: 8.38321284390986e-05\n",
            "Batch 19000, Loss: 0.07198619842529297\n",
            "Batch 19100, Loss: 4.991248351871036e-05\n",
            "Batch 19200, Loss: 0.07205064594745636\n",
            "Batch 19300, Loss: 0.07228289544582367\n",
            "Batch 19400, Loss: 0.07202182710170746\n",
            "Batch 19500, Loss: 9.086815407499671e-05\n",
            "Batch 19600, Loss: 0.00011211596574867144\n",
            "Batch 19700, Loss: 0.00011303620703984052\n",
            "Batch 19800, Loss: 0.0720018818974495\n",
            "Batch 19900, Loss: 9.810686606215313e-05\n",
            "Batch 20000, Loss: 6.517197471112013e-05\n",
            "Batch 20100, Loss: 0.07212482392787933\n",
            "Batch 20200, Loss: 0.0003929048543795943\n",
            "Batch 20300, Loss: 0.000117207266157493\n",
            "Batch 20400, Loss: 0.0002162245218642056\n",
            "Batch 20500, Loss: 0.07207165658473969\n",
            "Batch 20600, Loss: 6.773212953703478e-05\n",
            "Batch 20700, Loss: 0.00010583388939267024\n",
            "Batch 20800, Loss: 0.07205848395824432\n",
            "Batch 20900, Loss: 5.020175740355626e-05\n",
            "Batch 21000, Loss: 0.0001287510385736823\n",
            "Batch 21100, Loss: 0.07203850150108337\n",
            "Batch 21200, Loss: 0.17135632038116455\n",
            "Batch 21300, Loss: 0.00011191946396138519\n",
            "Batch 21400, Loss: 7.23763951100409e-05\n",
            "Batch 21500, Loss: 9.71793633652851e-05\n",
            "Batch 21600, Loss: 0.07209055870771408\n",
            "Batch 21700, Loss: 9.845375461736694e-05\n",
            "Batch 21800, Loss: 0.00016623144620098174\n",
            "Batch 21900, Loss: 9.599332406651229e-05\n",
            "Batch 22000, Loss: 0.07203303277492523\n",
            "Batch 22100, Loss: 0.0001535179908387363\n",
            "Batch 22200, Loss: 6.809777551097795e-05\n",
            "Batch 22300, Loss: 0.07209326326847076\n",
            "Batch 22400, Loss: 0.00014729153190273792\n",
            "Batch 22500, Loss: 4.174366040388122e-05\n",
            "Batch 22600, Loss: 0.00011156464461237192\n",
            "Batch 22700, Loss: 0.00011942773562623188\n",
            "Batch 22800, Loss: 4.131547029828653e-05\n",
            "Batch 22900, Loss: 0.07206142693758011\n",
            "Batch 23000, Loss: 0.028959421440958977\n",
            "Batch 23100, Loss: 0.0001594203495187685\n",
            "Batch 23200, Loss: 0.21592557430267334\n",
            "Batch 23300, Loss: 0.14397992193698883\n",
            "Batch 23400, Loss: 8.657405123813078e-05\n",
            "Batch 23500, Loss: 0.143964946269989\n",
            "Batch 23600, Loss: 8.889602759154513e-05\n",
            "Batch 23700, Loss: 0.00010950192518066615\n",
            "Batch 23800, Loss: 0.07209555804729462\n",
            "Batch 23900, Loss: 0.07201473414897919\n",
            "Batch 24000, Loss: 3.948083394789137e-05\n",
            "Batch 24100, Loss: 0.0001417637540725991\n",
            "Batch 24200, Loss: 0.0720105916261673\n",
            "Batch 24300, Loss: 0.00010012234270107001\n",
            "Batch 24400, Loss: 0.07219510525465012\n",
            "Batch 24500, Loss: 9.016779949888587e-05\n",
            "Batch 24600, Loss: 0.07204151153564453\n",
            "Batch 24700, Loss: 3.606461905292235e-05\n",
            "Batch 24800, Loss: 0.00015355793584603816\n",
            "Batch 24900, Loss: 5.509202674147673e-05\n",
            "Batch 25000, Loss: 5.658408554154448e-05\n",
            "Batch 25100, Loss: 0.07203450053930283\n",
            "Batch 25200, Loss: 0.07204515486955643\n",
            "Batch 25300, Loss: 0.07203037291765213\n",
            "Batch 25400, Loss: 0.07198251783847809\n",
            "Batch 25500, Loss: 6.874922110000625e-05\n",
            "Batch 25600, Loss: 0.00010934469901258126\n",
            "Batch 25700, Loss: 0.07200289517641068\n",
            "Batch 25800, Loss: 0.07202541828155518\n",
            "Batch 25900, Loss: 0.03132688254117966\n",
            "Batch 26000, Loss: 5.859269367647357e-05\n",
            "Batch 26100, Loss: 0.07199358195066452\n",
            "Batch 26200, Loss: 0.07197683304548264\n",
            "Batch 26300, Loss: 0.00016388032236136496\n",
            "Batch 26400, Loss: 0.00014025821292307228\n",
            "Batch 26500, Loss: 7.984618423506618e-05\n",
            "Batch 26600, Loss: 0.00026911834720522165\n",
            "Batch 26700, Loss: 4.30077088822145e-05\n",
            "Batch 26800, Loss: 0.00014622978051193058\n",
            "Batch 26900, Loss: 0.0002301269705640152\n",
            "Batch 27000, Loss: 5.297092138789594e-05\n",
            "Batch 27100, Loss: 0.14401642978191376\n",
            "Batch 27200, Loss: 0.14397640526294708\n",
            "Batch 27300, Loss: 0.07200656831264496\n",
            "Batch 27400, Loss: 7.2756054578349e-05\n",
            "Batch 27500, Loss: 0.07207044959068298\n",
            "Batch 27600, Loss: 6.753749039489776e-05\n",
            "Batch 27700, Loss: 0.00015697719936724752\n",
            "Batch 27800, Loss: 0.00018045626347884536\n",
            "Batch 27900, Loss: 9.212879376718774e-05\n",
            "Batch 28000, Loss: 4.288030322641134e-05\n",
            "Batch 28100, Loss: 0.00011721452756319195\n",
            "Batch 28200, Loss: 0.00010618942906148732\n",
            "Batch 28300, Loss: 5.119219349580817e-05\n",
            "Batch 28400, Loss: 0.0721086859703064\n",
            "Batch 28500, Loss: 3.166769602103159e-05\n",
            "Batch 28600, Loss: 0.07207579165697098\n",
            "Batch 28700, Loss: 7.422579801641405e-05\n",
            "Batch 28800, Loss: 8.366921974811703e-05\n",
            "Batch 28900, Loss: 0.029457688331604004\n",
            "Batch 29000, Loss: 0.00010354848200222477\n",
            "Batch 29100, Loss: 0.00011643343896139413\n",
            "Batch 29200, Loss: 0.07200830429792404\n",
            "Batch 29300, Loss: 0.14406265318393707\n",
            "Batch 29400, Loss: 0.0720147117972374\n",
            "Batch 29500, Loss: 7.147074211388826e-05\n",
            "Batch 29600, Loss: 9.124861389864236e-05\n",
            "Batch 29700, Loss: 5.101373608340509e-05\n",
            "Batch 29800, Loss: 0.14397799968719482\n",
            "Batch 29900, Loss: 4.464877929422073e-05\n",
            "Batch 30000, Loss: 2.0913435946567915e-05\n",
            "Batch 30100, Loss: 0.35987037420272827\n",
            "Batch 30200, Loss: 0.00021523164468817413\n",
            "Batch 30300, Loss: 0.07202395796775818\n",
            "Batch 30400, Loss: 0.14396587014198303\n",
            "Batch 30500, Loss: 7.346373604377732e-05\n",
            "Batch 30600, Loss: 0.07202354073524475\n",
            "Batch 30700, Loss: 0.00012962706387043\n",
            "Batch 30800, Loss: 0.07207220047712326\n",
            "Batch 30900, Loss: 0.14402711391448975\n",
            "Batch 31000, Loss: 0.07205523550510406\n",
            "Batch 31100, Loss: 9.516910358797759e-05\n",
            "Batch 31200, Loss: 0.07212045788764954\n",
            "Batch 31300, Loss: 0.07203293591737747\n",
            "Batch 31400, Loss: 0.2159554660320282\n",
            "Batch 31500, Loss: 0.07199180126190186\n",
            "Batch 31600, Loss: 0.00017219454457517713\n",
            "Batch 31700, Loss: 0.0720045417547226\n",
            "Batch 31800, Loss: 0.00011780506611103192\n",
            "Batch 31900, Loss: 0.1439950168132782\n",
            "Batch 32000, Loss: 3.255192859796807e-05\n",
            "Batch 32100, Loss: 4.817232183995657e-05\n",
            "Batch 32200, Loss: 0.07198380678892136\n",
            "Batch 32300, Loss: 3.2562918931944296e-05\n",
            "Batch 32400, Loss: 0.14401400089263916\n",
            "Batch 32500, Loss: 0.07201598584651947\n",
            "Batch 32600, Loss: 9.015142131829634e-05\n",
            "Batch 32700, Loss: 0.17083318531513214\n",
            "Batch 32800, Loss: 6.129015673650429e-05\n",
            "Batch 32900, Loss: 0.1440107524394989\n",
            "Batch 33000, Loss: 3.8742833567084745e-05\n",
            "Batch 33100, Loss: 0.0002524688607081771\n",
            "Batch 33200, Loss: 5.8066099882125854e-05\n",
            "Batch 33300, Loss: 0.0720200389623642\n",
            "Batch 33400, Loss: 0.14395591616630554\n",
            "Batch 33500, Loss: 0.00022861997422296554\n",
            "Batch 33600, Loss: 0.00021705987455789\n",
            "Batch 33700, Loss: 5.6034772569546476e-05\n",
            "Batch 33800, Loss: 0.14401528239250183\n",
            "Batch 33900, Loss: 0.14397785067558289\n",
            "Batch 34000, Loss: 0.1440201699733734\n",
            "Batch 34100, Loss: 7.510522118536755e-05\n",
            "Batch 34200, Loss: 5.471874101203866e-05\n",
            "Batch 34300, Loss: 0.00012422229337971658\n",
            "Batch 34400, Loss: 0.07199929654598236\n",
            "Batch 34500, Loss: 4.3039013689849526e-05\n",
            "Batch 34600, Loss: 3.539777026162483e-05\n",
            "Batch 34700, Loss: 0.072121262550354\n",
            "Batch 34800, Loss: 0.07199154049158096\n",
            "Batch 34900, Loss: 0.0001510482543380931\n",
            "Batch 35000, Loss: 8.762321522226557e-05\n",
            "Batch 35100, Loss: 6.222917727427557e-05\n",
            "Batch 35200, Loss: 9.46557120187208e-05\n",
            "Batch 35300, Loss: 0.00010860294423764572\n",
            "Batch 35400, Loss: 0.07212519645690918\n",
            "Batch 35500, Loss: 8.618848369223997e-05\n",
            "Batch 35600, Loss: 0.00012566377699840814\n",
            "Batch 35700, Loss: 0.07209230959415436\n",
            "Batch 35800, Loss: 0.21593961119651794\n",
            "Batch 35900, Loss: 0.00026519212406128645\n",
            "Batch 36000, Loss: 0.00014311015547718853\n",
            "Batch 36100, Loss: 0.0721416100859642\n",
            "Batch 36200, Loss: 0.01562410593032837\n",
            "Batch 36300, Loss: 0.007475360296666622\n",
            "Batch 36400, Loss: 5.4371077567338943e-05\n",
            "Batch 36500, Loss: 0.0720863938331604\n",
            "Batch 36600, Loss: 0.0001599971146788448\n",
            "Batch 36700, Loss: 8.266839722637087e-05\n",
            "Batch 36800, Loss: 0.0001187909219879657\n",
            "Batch 36900, Loss: 0.0005576129187829792\n",
            "Batch 37000, Loss: 0.0720408484339714\n",
            "Batch 37100, Loss: 7.215167715912685e-05\n",
            "Batch 37200, Loss: 0.0005648359074257314\n",
            "Batch 37300, Loss: 4.6781173296039924e-05\n",
            "Batch 37400, Loss: 0.07213857769966125\n",
            "Batch 37500, Loss: 4.907436596113257e-05\n",
            "Batch 37600, Loss: 5.4858690418768674e-05\n",
            "Batch 37700, Loss: 5.294714355841279e-05\n",
            "Batch 37800, Loss: 0.0720212534070015\n",
            "Batch 37900, Loss: 4.5043594582239166e-05\n",
            "Batch 38000, Loss: 6.9701716711279e-05\n",
            "Batch 38100, Loss: 0.00012613458966370672\n",
            "Batch 38200, Loss: 0.0006645785761065781\n",
            "Batch 38300, Loss: 0.00016735617828089744\n",
            "Batch 38400, Loss: 0.005461932625621557\n",
            "Batch 38500, Loss: 0.0002165847399737686\n",
            "Batch 38600, Loss: 0.00014277712034527212\n",
            "Batch 38700, Loss: 0.00017439296061638743\n",
            "Batch 38800, Loss: 0.0006916880956850946\n",
            "Batch 38900, Loss: 0.00012671660806518048\n",
            "Batch 39000, Loss: 0.00011999687558272853\n",
            "Batch 39100, Loss: 0.00012278012582100928\n",
            "Batch 39200, Loss: 7.86080927355215e-05\n",
            "Batch 39300, Loss: 6.354647484840825e-05\n",
            "Batch 39400, Loss: 4.2543670133454725e-05\n",
            "Batch 39500, Loss: 0.0001344216288998723\n",
            "Batch 39600, Loss: 9.351725748274475e-05\n",
            "Batch 39700, Loss: 4.7660218115197495e-05\n",
            "Batch 39800, Loss: 0.072199247777462\n",
            "Batch 39900, Loss: 0.028630150482058525\n",
            "Batch 40000, Loss: 8.317638275912032e-05\n",
            "Batch 40100, Loss: 4.4072796299587935e-05\n",
            "Batch 40200, Loss: 0.00013143918476998806\n",
            "Batch 40300, Loss: 5.7021621614694595e-05\n",
            "Batch 40400, Loss: 8.790354331722483e-05\n",
            "Batch 40500, Loss: 8.565462485421449e-05\n",
            "Batch 40600, Loss: 0.0001229759509442374\n",
            "Batch 40700, Loss: 9.027766645886004e-05\n",
            "Batch 40800, Loss: 8.074788638623431e-05\n",
            "Batch 40900, Loss: 0.0003338146489113569\n",
            "Batch 41000, Loss: 4.433514186530374e-05\n",
            "Batch 41100, Loss: 6.0978934925515205e-05\n",
            "Batch 41200, Loss: 4.7379766328958794e-05\n",
            "Batch 41300, Loss: 0.00030775758204981685\n",
            "Batch 41400, Loss: 9.121168841375038e-05\n",
            "Batch 41500, Loss: 0.00010454896982992068\n",
            "Batch 41600, Loss: 0.02812620997428894\n",
            "Batch 41700, Loss: 0.00015183397044893354\n",
            "Batch 41800, Loss: 0.00010103659587912261\n",
            "Batch 41900, Loss: 0.00016725064779166132\n",
            "Batch 42000, Loss: 0.00021397860837168992\n",
            "Batch 42100, Loss: 0.07202056050300598\n",
            "Batch 42200, Loss: 9.047794446814805e-05\n",
            "Batch 42300, Loss: 0.00011776777682825923\n",
            "Batch 42400, Loss: 5.5463660828536376e-05\n",
            "Batch 42500, Loss: 7.818694575689733e-05\n",
            "Batch 42600, Loss: 0.07210192829370499\n",
            "Batch 42700, Loss: 0.00013534801837522537\n",
            "Batch 42800, Loss: 0.00012403631990309805\n",
            "Batch 42900, Loss: 0.00010400914470665157\n",
            "Batch 43000, Loss: 0.0002447637962177396\n",
            "Batch 43100, Loss: 5.888289160793647e-05\n",
            "Batch 43200, Loss: 0.00023563040303997695\n",
            "Batch 43300, Loss: 6.214663881110027e-05\n",
            "Batch 43400, Loss: 6.605546514037997e-05\n",
            "Batch 43500, Loss: 6.853853119537234e-05\n",
            "Batch 43600, Loss: 4.4345892092678696e-05\n",
            "Batch 43700, Loss: 6.031910379533656e-05\n",
            "Batch 43800, Loss: 0.00010741758887888864\n",
            "Batch 43900, Loss: 5.148500349605456e-05\n",
            "Batch 44000, Loss: 0.072059266269207\n",
            "Batch 44100, Loss: 0.00012349238386377692\n",
            "Batch 44200, Loss: 4.587426155922003e-05\n",
            "Batch 44300, Loss: 7.421500777127221e-05\n",
            "Batch 44400, Loss: 0.00015986920334398746\n",
            "Batch 44500, Loss: 0.00013635972572956234\n",
            "Batch 44600, Loss: 7.478451152564958e-05\n",
            "Batch 44700, Loss: 0.02948419749736786\n",
            "Batch 44800, Loss: 9.768277232069522e-05\n",
            "Batch 44900, Loss: 0.00012822094140574336\n",
            "Batch 45000, Loss: 6.312123878160492e-05\n",
            "Batch 45100, Loss: 8.529226761311293e-05\n",
            "Batch 45200, Loss: 0.00017245663912035525\n",
            "Batch 45300, Loss: 0.00010592117178020999\n",
            "Batch 45400, Loss: 9.935206617228687e-05\n",
            "Batch 45500, Loss: 0.000149096071254462\n",
            "Batch 45600, Loss: 0.00010448082321090624\n",
            "Batch 45700, Loss: 0.0001034072702168487\n",
            "Batch 45800, Loss: 8.301332127302885e-05\n",
            "Batch 45900, Loss: 6.67841886752285e-05\n",
            "Batch 46000, Loss: 0.00018499615543987602\n",
            "Batch 46100, Loss: 6.237353227334097e-05\n",
            "Batch 46200, Loss: 5.916418740525842e-05\n",
            "Batch 46300, Loss: 8.465836435789242e-05\n",
            "Batch 46400, Loss: 9.372671047458425e-05\n",
            "Batch 46500, Loss: 5.4250253015197814e-05\n",
            "Batch 46600, Loss: 0.0001232949289260432\n",
            "Batch 46700, Loss: 4.183456985629164e-05\n",
            "Batch 46800, Loss: 0.07203567028045654\n",
            "Batch 46900, Loss: 8.75183250172995e-05\n",
            "Batch 47000, Loss: 3.886301419697702e-05\n",
            "Batch 47100, Loss: 0.03197073936462402\n",
            "Batch 47200, Loss: 4.177568189334124e-05\n",
            "Batch 47300, Loss: 7.210743933683261e-05\n",
            "Batch 47400, Loss: 2.5020846806000918e-05\n",
            "Batch 47500, Loss: 0.03050961159169674\n",
            "Batch 47600, Loss: 7.068669947329909e-05\n",
            "Batch 47700, Loss: 6.329299503704533e-05\n",
            "Batch 47800, Loss: 9.010837675305083e-05\n",
            "Batch 47900, Loss: 0.0001057296758517623\n",
            "Batch 48000, Loss: 0.07199878245592117\n",
            "Batch 48100, Loss: 8.951265772338957e-05\n",
            "Batch 48200, Loss: 9.862238948699087e-05\n",
            "Batch 48300, Loss: 0.00010661600390449166\n",
            "Batch 48400, Loss: 0.00019297907419968396\n",
            "Batch 48500, Loss: 7.141876267269254e-05\n",
            "Batch 48600, Loss: 0.00010023709910456091\n",
            "Batch 48700, Loss: 8.866712596500292e-05\n",
            "Batch 48800, Loss: 0.00011591460497584194\n",
            "Batch 48900, Loss: 0.00018189463298767805\n",
            "Batch 49000, Loss: 7.664405711693689e-05\n",
            "Batch 49100, Loss: 0.00011513444042066112\n",
            "Batch 49200, Loss: 0.030735179781913757\n",
            "Batch 49300, Loss: 0.00012062153109582141\n",
            "Batch 49400, Loss: 6.230740837054327e-05\n",
            "Batch 49500, Loss: 0.00010620226385071874\n",
            "Batch 49600, Loss: 5.804336615256034e-05\n",
            "Batch 49700, Loss: 0.00034860108280554414\n",
            "Batch 49800, Loss: 8.528221223969012e-05\n",
            "Batch 49900, Loss: 0.00017969617329072207\n",
            "Batch 50000, Loss: 9.485949703957886e-05\n",
            "Batch 50100, Loss: 0.00015994916611816734\n",
            "Batch 50200, Loss: 7.84347575972788e-05\n",
            "Batch 50300, Loss: 5.52755082026124e-05\n",
            "Batch 50400, Loss: 5.967570177745074e-05\n",
            "Batch 50500, Loss: 6.30016511422582e-05\n",
            "Batch 50600, Loss: 0.0001672174403211102\n",
            "Batch 50700, Loss: 6.565367220900953e-05\n",
            "Batch 50800, Loss: 0.00014968737377785146\n",
            "Batch 50900, Loss: 6.56154879834503e-05\n",
            "Batch 51000, Loss: 0.00025300716515630484\n",
            "Batch 51100, Loss: 3.6845092836301774e-05\n",
            "Batch 51200, Loss: 2.532018334022723e-05\n",
            "Batch 51300, Loss: 0.07206884026527405\n",
            "Batch 51400, Loss: 9.05446577235125e-05\n",
            "Batch 51500, Loss: 4.428275133250281e-05\n",
            "Batch 51600, Loss: 0.02624514140188694\n",
            "Batch 51700, Loss: 0.07206342369318008\n",
            "Batch 51800, Loss: 5.56411687284708e-05\n",
            "Batch 51900, Loss: 0.07198032736778259\n",
            "Batch 52000, Loss: 2.7220876290812157e-05\n",
            "Batch 52100, Loss: 1.6484356820001267e-05\n",
            "Batch 52200, Loss: 6.598600157303736e-05\n",
            "Batch 52300, Loss: 7.229222683236003e-05\n",
            "Batch 52400, Loss: 0.00012177167081972584\n",
            "Batch 52500, Loss: 3.3569518564036116e-05\n",
            "Batch 52600, Loss: 8.630470983916894e-05\n",
            "Batch 52700, Loss: 0.00010805860802065581\n",
            "Batch 52800, Loss: 5.249704190646298e-05\n",
            "Batch 52900, Loss: 8.050339965848252e-05\n",
            "Batch 53000, Loss: 6.25057946308516e-05\n",
            "Batch 53100, Loss: 0.00025169565924443305\n",
            "Batch 53200, Loss: 0.07204464077949524\n",
            "Batch 53300, Loss: 0.07205137610435486\n",
            "Batch 53400, Loss: 5.010360837331973e-05\n",
            "Batch 53500, Loss: 0.0721297413110733\n",
            "Batch 53600, Loss: 8.033052290556952e-05\n",
            "Batch 53700, Loss: 0.00012831893400289118\n",
            "Batch 53800, Loss: 6.120409670984372e-05\n",
            "Batch 53900, Loss: 7.287770131370053e-05\n",
            "Batch 54000, Loss: 4.330500814830884e-05\n",
            "Batch 54100, Loss: 0.0001501478982390836\n",
            "Batch 54200, Loss: 3.404190647415817e-05\n",
            "Batch 54300, Loss: 3.3533757232362404e-05\n",
            "Batch 54400, Loss: 4.595585778588429e-05\n",
            "Batch 54500, Loss: 0.0720229297876358\n",
            "Batch 54600, Loss: 8.717464515939355e-05\n",
            "Batch 54700, Loss: 0.00017284789646510035\n",
            "Batch 54800, Loss: 0.00013524274982046336\n",
            "Batch 54900, Loss: 5.307225728756748e-05\n",
            "Batch 55000, Loss: 0.0002357030170969665\n",
            "Batch 55100, Loss: 0.000124133046483621\n",
            "Batch 55200, Loss: 5.368379788706079e-05\n",
            "Batch 55300, Loss: 0.030552474781870842\n",
            "Batch 55400, Loss: 0.00018870856729336083\n",
            "Batch 55500, Loss: 0.0001494496682425961\n",
            "Batch 55600, Loss: 0.0002758761984296143\n",
            "Batch 55700, Loss: 6.630826101172715e-05\n",
            "Batch 55800, Loss: 7.358295988524333e-05\n",
            "Batch 55900, Loss: 0.00014094657672103494\n",
            "Batch 56000, Loss: 4.3664327677106485e-05\n",
            "Batch 56100, Loss: 6.332783232210204e-05\n",
            "Batch 56200, Loss: 7.824066415196285e-05\n",
            "Batch 56300, Loss: 4.020320557174273e-05\n",
            "Batch 56400, Loss: 0.00010912267316598445\n",
            "Batch 56500, Loss: 6.76293348078616e-05\n",
            "Batch 56600, Loss: 0.00012163065548520535\n",
            "Batch 56700, Loss: 0.00025941216154024005\n",
            "Batch 56800, Loss: 3.733927587745711e-05\n",
            "Batch 56900, Loss: 5.2593906730180606e-05\n",
            "Batch 57000, Loss: 0.00023806336685083807\n",
            "Batch 57100, Loss: 5.868230073247105e-05\n",
            "Batch 57200, Loss: 3.614322849898599e-05\n",
            "Batch 57300, Loss: 3.565408042049967e-05\n",
            "Batch 57400, Loss: 0.00014726708468515426\n",
            "Batch 57500, Loss: 0.00014893569459673017\n",
            "Batch 57600, Loss: 0.0001919106871355325\n",
            "Batch 57700, Loss: 0.0001273450325243175\n",
            "Batch 57800, Loss: 9.002362639876083e-05\n",
            "Batch 57900, Loss: 0.00021051052317488939\n",
            "Batch 58000, Loss: 5.8314592024544254e-05\n",
            "Batch 58100, Loss: 2.5638331862865016e-05\n",
            "Batch 58200, Loss: 8.025024726521224e-05\n",
            "Batch 58300, Loss: 3.0053668524487875e-05\n",
            "Batch 58400, Loss: 5.999200220685452e-05\n",
            "Batch 58500, Loss: 5.771776704932563e-05\n",
            "Batch 58600, Loss: 8.228050865000114e-05\n",
            "Batch 58700, Loss: 8.227548096328974e-05\n",
            "Batch 58800, Loss: 5.2344115829328075e-05\n",
            "Batch 58900, Loss: 3.721130997291766e-05\n",
            "Batch 59000, Loss: 0.03388364985585213\n",
            "Batch 59100, Loss: 4.542703027254902e-05\n",
            "Batch 59200, Loss: 3.7799367419211194e-05\n",
            "Batch 59300, Loss: 5.0798225856851786e-05\n",
            "Batch 59400, Loss: 8.501305273966864e-05\n",
            "Batch 59500, Loss: 5.711181438528001e-05\n",
            "Batch 59600, Loss: 0.00015286050620488822\n",
            "Batch 59700, Loss: 0.0720209926366806\n",
            "Batch 59800, Loss: 0.0001501169754192233\n",
            "Batch 59900, Loss: 6.90349843353033e-05\n",
            "Batch 60000, Loss: 4.841596819460392e-05\n",
            "Batch 60100, Loss: 0.00018249437562189996\n",
            "Batch 60200, Loss: 0.0001871354616014287\n",
            "Batch 60300, Loss: 0.21593257784843445\n",
            "Batch 60400, Loss: 4.87650468130596e-05\n",
            "Batch 60500, Loss: 4.6974961151136085e-05\n",
            "Batch 60600, Loss: 9.907806088449433e-05\n",
            "Batch 60700, Loss: 0.00017264501366298646\n",
            "Batch 60800, Loss: 7.904352969489992e-05\n",
            "Batch 60900, Loss: 0.14394769072532654\n",
            "Batch 61000, Loss: 5.448496449389495e-05\n",
            "Batch 61100, Loss: 5.1145252655260265e-05\n",
            "Batch 61200, Loss: 0.07218094915151596\n",
            "Batch 61300, Loss: 0.00010861374175874516\n",
            "Batch 61400, Loss: 6.032506644260138e-05\n",
            "Batch 61500, Loss: 0.07205627858638763\n",
            "Batch 61600, Loss: 0.14395937323570251\n",
            "Batch 61700, Loss: 7.677949906792492e-05\n",
            "Batch 61800, Loss: 0.0001248230691999197\n",
            "Batch 61900, Loss: 5.0782764446921647e-05\n",
            "Batch 62000, Loss: 8.762954530538991e-05\n",
            "Batch 62100, Loss: 0.00010420029138913378\n",
            "Batch 62200, Loss: 0.0001156443395302631\n",
            "Batch 62300, Loss: 7.319643191294745e-05\n",
            "Batch 62400, Loss: 0.00025438060401938856\n",
            "Batch 62500, Loss: 5.6752116506686434e-05\n",
            "Batch 62600, Loss: 4.673056901083328e-05\n",
            "Batch 62700, Loss: 8.655489364173263e-05\n",
            "Batch 62800, Loss: 6.139540346339345e-05\n",
            "Batch 62900, Loss: 6.342264532577246e-05\n",
            "Batch 63000, Loss: 7.17732691555284e-05\n",
            "Batch 63100, Loss: 0.00017675473645795137\n",
            "Batch 63200, Loss: 7.010291301412508e-05\n",
            "Batch 63300, Loss: 5.233331103227101e-05\n",
            "Batch 63400, Loss: 0.0001749664661474526\n",
            "Batch 63500, Loss: 0.00014258985174819827\n",
            "Batch 63600, Loss: 0.00017818270134739578\n",
            "Batch 63700, Loss: 0.00012113383127143607\n",
            "Batch 63800, Loss: 6.56872070976533e-05\n",
            "Batch 63900, Loss: 5.11400394316297e-05\n",
            "Batch 64000, Loss: 3.468416616669856e-05\n",
            "Batch 64100, Loss: 3.361180642968975e-05\n",
            "Batch 64200, Loss: 3.0510589567711577e-05\n",
            "Batch 64300, Loss: 3.062924224650487e-05\n",
            "Batch 64400, Loss: 7.832505070837215e-05\n",
            "Batch 64500, Loss: 0.07240228354930878\n",
            "Batch 64600, Loss: 4.817120498046279e-05\n",
            "Batch 64700, Loss: 4.065416942466982e-05\n",
            "Batch 64800, Loss: 0.00010098317579831928\n",
            "Batch 64900, Loss: 7.225236913654953e-05\n",
            "Batch 65000, Loss: 4.6021988964639604e-05\n",
            "Batch 65100, Loss: 8.4772749687545e-05\n",
            "Batch 65200, Loss: 2.9800154152326286e-05\n",
            "Batch 65300, Loss: 9.931482782121748e-05\n",
            "Batch 65400, Loss: 9.859298006631434e-05\n",
            "Batch 65500, Loss: 9.693711035652086e-05\n",
            "Batch 65600, Loss: 7.832821574993432e-05\n",
            "Batch 65700, Loss: 8.022696420084685e-05\n",
            "Batch 65800, Loss: 0.07198403030633926\n",
            "Batch 65900, Loss: 9.88371975836344e-05\n",
            "Batch 66000, Loss: 6.997941090958193e-05\n",
            "Batch 66100, Loss: 6.795475928811356e-05\n",
            "Batch 66200, Loss: 0.00028967540129087865\n",
            "Batch 66300, Loss: 8.488786988891661e-05\n",
            "Batch 66400, Loss: 0.00010443557403050363\n",
            "Batch 66500, Loss: 8.500522380927578e-05\n",
            "Batch 66600, Loss: 0.07202062755823135\n",
            "Batch 66700, Loss: 0.00013090090942569077\n",
            "Batch 66800, Loss: 9.477288404013962e-05\n",
            "Batch 66900, Loss: 5.006412175134756e-05\n",
            "Batch 67000, Loss: 8.142064325511456e-05\n",
            "Batch 67100, Loss: 0.0719965472817421\n",
            "Batch 67200, Loss: 3.7787445762660354e-05\n",
            "Batch 67300, Loss: 5.102603608975187e-05\n",
            "Batch 67400, Loss: 0.00031919038156047463\n",
            "Batch 67500, Loss: 0.14398011565208435\n",
            "Batch 67600, Loss: 4.637180609279312e-05\n",
            "Batch 67700, Loss: 9.286740532843396e-05\n",
            "Batch 67800, Loss: 0.02661191113293171\n",
            "Batch 67900, Loss: 9.680075163487345e-05\n",
            "Batch 68000, Loss: 0.0001529583241790533\n",
            "Batch 68100, Loss: 0.07206462323665619\n",
            "Batch 68200, Loss: 3.313402339699678e-05\n",
            "Batch 68300, Loss: 1.953449464053847e-05\n",
            "Batch 68400, Loss: 6.376967940013856e-05\n",
            "Batch 68500, Loss: 6.484859477495775e-05\n",
            "Batch 68600, Loss: 7.498358172597364e-05\n",
            "Batch 68700, Loss: 0.030015302821993828\n",
            "Batch 68800, Loss: 0.00036402017576619983\n",
            "Batch 68900, Loss: 7.152420585043728e-05\n",
            "Batch 69000, Loss: 0.0001121822206187062\n",
            "Batch 69100, Loss: 0.07209621369838715\n",
            "Batch 69200, Loss: 0.07199272513389587\n",
            "Batch 69300, Loss: 0.07219989597797394\n",
            "Batch 69400, Loss: 8.88098293216899e-05\n",
            "Batch 69500, Loss: 0.00014151123468764126\n",
            "Batch 69600, Loss: 8.356025500688702e-05\n",
            "Batch 69700, Loss: 0.00015869186609052122\n",
            "Batch 69800, Loss: 0.00020620152645278722\n",
            "Batch 69900, Loss: 9.071901877177879e-05\n",
            "Batch 70000, Loss: 0.07206247746944427\n",
            "Batch 70100, Loss: 0.00025234255008399487\n",
            "Batch 70200, Loss: 0.0001233927469002083\n",
            "Batch 70300, Loss: 0.00010419359023217112\n",
            "Batch 70400, Loss: 7.8921890235506e-05\n",
            "Batch 70500, Loss: 8.916972001316026e-05\n",
            "Batch 70600, Loss: 5.626295751426369e-05\n",
            "Batch 70700, Loss: 0.07203947007656097\n",
            "Batch 70800, Loss: 9.810547635424882e-05\n",
            "Batch 70900, Loss: 5.137418338563293e-05\n",
            "Batch 71000, Loss: 6.232883606571704e-05\n",
            "Batch 71100, Loss: 0.00044255133252590895\n",
            "Batch 71200, Loss: 0.00010049343836726621\n",
            "Batch 71300, Loss: 0.0001393606944475323\n",
            "Batch 71400, Loss: 6.615383608732373e-05\n",
            "Batch 71500, Loss: 0.00013113713066559285\n",
            "Batch 71600, Loss: 0.00011170253856107593\n",
            "Batch 71700, Loss: 8.511401392752305e-05\n",
            "Batch 71800, Loss: 0.02863321825861931\n",
            "Batch 71900, Loss: 8.04737865109928e-05\n",
            "Batch 72000, Loss: 0.00015784200513735414\n",
            "Batch 72100, Loss: 0.0001182631531264633\n",
            "Batch 72200, Loss: 0.027365710586309433\n",
            "Batch 72300, Loss: 0.026637915521860123\n",
            "Batch 72400, Loss: 0.07211875170469284\n",
            "Batch 72500, Loss: 0.00015115928545128554\n",
            "Batch 72600, Loss: 0.0001713185920380056\n",
            "Batch 72700, Loss: 8.952830830821767e-05\n",
            "Batch 72800, Loss: 7.76009910623543e-05\n",
            "Batch 72900, Loss: 6.019392822054215e-05\n",
            "Batch 73000, Loss: 0.00010324168397346511\n",
            "Batch 73100, Loss: 0.00012910379155073315\n",
            "Batch 73200, Loss: 0.00011492248449940234\n",
            "Batch 73300, Loss: 0.00015724473632872105\n",
            "Batch 73400, Loss: 9.155691805062816e-05\n",
            "Batch 73500, Loss: 3.5153385397279635e-05\n",
            "Batch 73600, Loss: 5.078164758742787e-05\n",
            "Batch 73700, Loss: 3.9917093090480193e-05\n",
            "Batch 73800, Loss: 4.337653808761388e-05\n",
            "Batch 73900, Loss: 7.068186096148565e-05\n",
            "Batch 74000, Loss: 0.0002696271985769272\n",
            "Batch 74100, Loss: 0.00015235826140269637\n",
            "Batch 74200, Loss: 6.579748878721148e-05\n",
            "Batch 74300, Loss: 7.771424134261906e-05\n",
            "Batch 74400, Loss: 0.07201883941888809\n",
            "Batch 74500, Loss: 2.6920797608909197e-05\n",
            "Batch 74600, Loss: 5.911837433814071e-05\n",
            "Batch 74700, Loss: 9.059048898052424e-05\n",
            "Batch 74800, Loss: 0.00013315872638486326\n",
            "Batch 74900, Loss: 6.352677883114666e-05\n",
            "Batch 75000, Loss: 5.16051659360528e-05\n",
            "Batch 75100, Loss: 5.577882984653115e-05\n",
            "Batch 75200, Loss: 9.118994057644159e-05\n",
            "Batch 75300, Loss: 6.68635475449264e-05\n",
            "Batch 75400, Loss: 6.985013169469312e-05\n",
            "Batch 75500, Loss: 0.00015449505008291453\n",
            "Batch 75600, Loss: 0.00015247284318320453\n",
            "Batch 75700, Loss: 8.021336543606594e-05\n",
            "Batch 75800, Loss: 0.00013757304986938834\n",
            "Batch 75900, Loss: 7.23546399967745e-05\n",
            "Batch 76000, Loss: 6.114691495895386e-05\n",
            "Batch 76100, Loss: 6.269077130127698e-05\n",
            "Batch 76200, Loss: 5.5415039241779596e-05\n",
            "Batch 76300, Loss: 0.07200761884450912\n",
            "Batch 76400, Loss: 0.00012516397691797465\n",
            "Batch 76500, Loss: 8.833182801026851e-05\n",
            "Batch 76600, Loss: 7.640395779162645e-05\n",
            "Batch 76700, Loss: 8.20038840174675e-05\n",
            "Batch 76800, Loss: 6.078200021875091e-05\n",
            "Batch 76900, Loss: 0.0001425730879418552\n",
            "Batch 77000, Loss: 0.00014102445857133716\n",
            "Batch 77100, Loss: 0.02744111977517605\n",
            "Batch 77200, Loss: 4.933187665301375e-05\n",
            "Batch 77300, Loss: 0.00010096268670167774\n",
            "Batch 77400, Loss: 6.709565059281886e-05\n",
            "Batch 77500, Loss: 0.00010632579505909234\n",
            "Batch 77600, Loss: 8.224604971474037e-05\n",
            "Batch 77700, Loss: 0.00012207141844555736\n",
            "Batch 77800, Loss: 0.0001691705983830616\n",
            "Batch 77900, Loss: 6.186147220432758e-05\n",
            "Batch 78000, Loss: 0.00011503724090289325\n",
            "Batch 78100, Loss: 0.07200547307729721\n",
            "Batch 78200, Loss: 0.00014340749476104975\n",
            "Batch 78300, Loss: 0.0001852070854511112\n",
            "Batch 78400, Loss: 9.965255594579503e-05\n",
            "Batch 78500, Loss: 0.00013566469715442508\n",
            "Batch 78600, Loss: 0.00011074540088884532\n",
            "Batch 78700, Loss: 0.00012350322504062206\n",
            "Batch 78800, Loss: 8.081151463557035e-05\n",
            "Batch 78900, Loss: 0.0001002514545689337\n",
            "Batch 79000, Loss: 3.407617987249978e-05\n",
            "Batch 79100, Loss: 0.00010323982132831588\n",
            "Batch 79200, Loss: 7.998591172508895e-05\n",
            "Batch 79300, Loss: 6.829435005784035e-05\n",
            "Batch 79400, Loss: 2.894927456509322e-05\n",
            "Batch 79500, Loss: 2.72761990345316e-05\n",
            "Batch 79600, Loss: 9.20285820029676e-05\n",
            "Batch 79700, Loss: 0.00012373962090350688\n",
            "Batch 79800, Loss: 5.089117621537298e-05\n",
            "Batch 79900, Loss: 0.0001864020014181733\n",
            "Batch 80000, Loss: 3.658394780359231e-05\n",
            "Batch 80100, Loss: 3.228797868359834e-05\n",
            "Batch 80200, Loss: 4.540374720818363e-05\n",
            "Batch 80300, Loss: 2.2510876078740694e-05\n",
            "Batch 80400, Loss: 6.950012175366282e-05\n",
            "Batch 80500, Loss: 2.6444506147527136e-05\n",
            "Batch 80600, Loss: 4.731565422844142e-05\n",
            "Batch 80700, Loss: 9.738940570969135e-05\n",
            "Batch 80800, Loss: 3.1107585527934134e-05\n",
            "Batch 80900, Loss: 6.31709917797707e-05\n",
            "Batch 81000, Loss: 3.515040589263663e-05\n",
            "Batch 81100, Loss: 0.0001297034468734637\n",
            "Batch 81200, Loss: 0.00010979069338645786\n",
            "Batch 81300, Loss: 0.07200774550437927\n",
            "Batch 81400, Loss: 0.00012076609709765762\n",
            "Batch 81500, Loss: 6.40094222035259e-05\n",
            "Batch 81600, Loss: 6.269560981309041e-05\n",
            "Batch 81700, Loss: 0.07198318839073181\n",
            "Batch 81800, Loss: 0.00010287805343978107\n",
            "Batch 81900, Loss: 6.127265078248456e-05\n",
            "Batch 82000, Loss: 3.933219704777002e-05\n",
            "Batch 82100, Loss: 4.183904457022436e-05\n",
            "Batch 82200, Loss: 0.1439950168132782\n",
            "Batch 82300, Loss: 0.00015307642752304673\n",
            "Batch 82400, Loss: 4.707945845439099e-05\n",
            "Batch 82500, Loss: 0.0001270808861590922\n",
            "Batch 82600, Loss: 0.00010883821232710034\n",
            "Batch 82700, Loss: 0.00016023345233406872\n",
            "Batch 82800, Loss: 8.773908484727144e-05\n",
            "Batch 82900, Loss: 9.358402894577011e-05\n",
            "Batch 83000, Loss: 6.0916303482372314e-05\n",
            "Batch 83100, Loss: 4.3623724195640534e-05\n",
            "Batch 83200, Loss: 0.14403925836086273\n",
            "Batch 83300, Loss: 7.450577686540782e-05\n",
            "Batch 83400, Loss: 4.147860818193294e-05\n",
            "Batch 83500, Loss: 0.00011324572551529855\n",
            "Batch 83600, Loss: 0.00015295310004148632\n",
            "Batch 83700, Loss: 0.0001809084351407364\n",
            "Batch 83800, Loss: 6.591708370251581e-05\n",
            "Batch 83900, Loss: 6.759301322745159e-05\n",
            "Batch 84000, Loss: 0.00012469750072341412\n",
            "Batch 84100, Loss: 0.07206784933805466\n",
            "Batch 84200, Loss: 0.07201585918664932\n",
            "Batch 84300, Loss: 5.137362677487545e-05\n",
            "Batch 84400, Loss: 8.940480620367453e-05\n",
            "Batch 84500, Loss: 7.963160896906629e-05\n",
            "Batch 84600, Loss: 4.8990437790052965e-05\n",
            "Batch 84700, Loss: 5.4475651268148795e-05\n",
            "Batch 84800, Loss: 0.00020369314006529748\n",
            "Batch 84900, Loss: 8.11814607004635e-05\n",
            "Batch 85000, Loss: 3.287901927251369e-05\n",
            "Batch 85100, Loss: 6.663666863460094e-05\n",
            "Batch 85200, Loss: 2.7282532755634747e-05\n",
            "Batch 85300, Loss: 4.470038038562052e-05\n",
            "Batch 85400, Loss: 6.650888099102303e-05\n",
            "Batch 85500, Loss: 0.07203540951013565\n",
            "Batch 85600, Loss: 0.00016547187988180667\n",
            "Batch 85700, Loss: 5.0533901230664924e-05\n",
            "Batch 85800, Loss: 2.406473140581511e-05\n",
            "Batch 85900, Loss: 0.0002241964975837618\n",
            "Batch 86000, Loss: 9.488595969742164e-05\n",
            "Batch 86100, Loss: 8.356416947208345e-05\n",
            "Batch 86200, Loss: 3.8493602914968506e-05\n",
            "Batch 86300, Loss: 0.00011730880942195654\n",
            "Batch 86400, Loss: 6.532080442411825e-05\n",
            "Batch 86500, Loss: 0.07208918780088425\n",
            "Batch 86600, Loss: 0.02999948337674141\n",
            "Batch 86700, Loss: 0.00017543071589898318\n",
            "Batch 86800, Loss: 7.0807414886076e-05\n",
            "Batch 86900, Loss: 0.0001034756496665068\n",
            "Batch 87000, Loss: 0.00015175878070294857\n",
            "Batch 87100, Loss: 4.6379256673390046e-05\n",
            "Batch 87200, Loss: 7.712784281466156e-05\n",
            "Batch 87300, Loss: 0.00011599623394431546\n",
            "Batch 87400, Loss: 0.0002126347681041807\n",
            "Batch 87500, Loss: 8.369101851712912e-05\n",
            "Batch 87600, Loss: 0.00014663574984297156\n",
            "Batch 87700, Loss: 9.35830976231955e-05\n",
            "Batch 87800, Loss: 9.120185859501362e-05\n",
            "Batch 87900, Loss: 6.985460640862584e-05\n",
            "Batch 88000, Loss: 0.07204042375087738\n",
            "Batch 88100, Loss: 3.9934227970661595e-05\n",
            "Batch 88200, Loss: 6.758519157301635e-05\n",
            "Batch 88300, Loss: 5.876705836271867e-05\n",
            "Batch 88400, Loss: 6.925200432306156e-05\n",
            "Batch 88500, Loss: 0.0002763075171969831\n",
            "Batch 88600, Loss: 8.463211270282045e-05\n",
            "Batch 88700, Loss: 0.07209419459104538\n",
            "Batch 88800, Loss: 0.00017841035150922835\n",
            "Batch 88900, Loss: 0.07206951826810837\n",
            "Batch 89000, Loss: 0.0001344702031929046\n",
            "Batch 89100, Loss: 0.0001244590530404821\n",
            "Batch 89200, Loss: 7.057139737298712e-05\n",
            "Batch 89300, Loss: 6.114933785283938e-05\n",
            "Batch 89400, Loss: 6.592155114049092e-05\n",
            "Batch 89500, Loss: 8.105143206194043e-05\n",
            "Batch 89600, Loss: 0.00010060837666969746\n",
            "Batch 89700, Loss: 0.00018008424376603216\n",
            "Batch 89800, Loss: 0.00011527120659593493\n",
            "Batch 89900, Loss: 5.864281047252007e-05\n",
            "Batch 90000, Loss: 9.836310346145183e-05\n",
            "Batch 90100, Loss: 8.416268246946856e-05\n",
            "Batch 90200, Loss: 0.0001261276484001428\n",
            "Batch 90300, Loss: 5.9123962273588404e-05\n",
            "Batch 90400, Loss: 0.00011122787691419944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Average Loss: 0.07869524008215541\n",
            "Batch 0, Loss: 0.00010753553215181455\n",
            "Batch 100, Loss: 0.07200941443443298\n",
            "Batch 200, Loss: 6.22224688413553e-05\n",
            "Batch 300, Loss: 0.07203683257102966\n",
            "Batch 400, Loss: 7.831201219232753e-05\n",
            "Batch 500, Loss: 6.675271288258955e-05\n",
            "Batch 600, Loss: 6.734507769579068e-05\n",
            "Batch 700, Loss: 0.00013721594586968422\n",
            "Batch 800, Loss: 5.838873403263278e-05\n",
            "Batch 900, Loss: 3.621475843829103e-05\n",
            "Batch 1000, Loss: 0.00010049287811852992\n",
            "Batch 1100, Loss: 6.149655382614583e-05\n",
            "Batch 1200, Loss: 4.18338313465938e-05\n",
            "Batch 1300, Loss: 7.830735557945445e-05\n",
            "Batch 1400, Loss: 7.592857582494617e-05\n",
            "Batch 1500, Loss: 6.269300502026454e-05\n",
            "Batch 1600, Loss: 5.9355501434765756e-05\n",
            "Batch 1700, Loss: 2.6960844479617663e-05\n",
            "Batch 1800, Loss: 8.334808080689982e-05\n",
            "Batch 1900, Loss: 3.409648343222216e-05\n",
            "Batch 2000, Loss: 3.0289858841570094e-05\n",
            "Batch 2100, Loss: 0.00019309295748826116\n",
            "Batch 2200, Loss: 7.474421727238223e-05\n",
            "Batch 2300, Loss: 5.698942914023064e-05\n",
            "Batch 2400, Loss: 6.056945858290419e-05\n",
            "Batch 2500, Loss: 6.223625678103417e-05\n",
            "Batch 2600, Loss: 0.00011386530968593433\n",
            "Batch 2700, Loss: 0.00010897252650465816\n",
            "Batch 2800, Loss: 3.07518093904946e-05\n",
            "Batch 2900, Loss: 4.863391222897917e-05\n",
            "Batch 3000, Loss: 8.309250551974401e-05\n",
            "Batch 3100, Loss: 4.673708826885559e-05\n",
            "Batch 3200, Loss: 8.095475641312078e-05\n",
            "Batch 3300, Loss: 9.87244930001907e-05\n",
            "Batch 3400, Loss: 0.00012768556189257652\n",
            "Batch 3500, Loss: 7.868363900342956e-05\n",
            "Batch 3600, Loss: 0.0001306734629906714\n",
            "Batch 3700, Loss: 0.0001580877142259851\n",
            "Batch 3800, Loss: 0.00010397116420790553\n",
            "Batch 3900, Loss: 0.07201360911130905\n",
            "Batch 4000, Loss: 0.00013375989510677755\n",
            "Batch 4100, Loss: 5.782040534541011e-05\n",
            "Batch 4200, Loss: 2.6462388632353395e-05\n",
            "Batch 4300, Loss: 6.735681381542236e-05\n",
            "Batch 4400, Loss: 3.6352972529130057e-05\n",
            "Batch 4500, Loss: 4.481885116547346e-05\n",
            "Batch 4600, Loss: 7.355073466897011e-05\n",
            "Batch 4700, Loss: 0.00015308480942621827\n",
            "Batch 4800, Loss: 8.85713889147155e-05\n",
            "Batch 4900, Loss: 5.197696737013757e-05\n",
            "Batch 5000, Loss: 3.90924651583191e-05\n",
            "Batch 5100, Loss: 0.00012361982953734696\n",
            "Batch 5200, Loss: 0.0002608158392831683\n",
            "Batch 5300, Loss: 6.603797373827547e-05\n",
            "Batch 5400, Loss: 0.00011707464727805927\n",
            "Batch 5500, Loss: 5.9965554100926965e-05\n",
            "Batch 5600, Loss: 2.6933092158287764e-05\n",
            "Batch 5700, Loss: 5.54271464352496e-05\n",
            "Batch 5800, Loss: 0.0001508131535956636\n",
            "Batch 5900, Loss: 0.00014198871213011444\n",
            "Batch 6000, Loss: 5.697061715181917e-05\n",
            "Batch 6100, Loss: 5.2205527026671916e-05\n",
            "Batch 6200, Loss: 5.5655887990724295e-05\n",
            "Batch 6300, Loss: 0.0001038288464769721\n",
            "Batch 6400, Loss: 0.029177557677030563\n",
            "Batch 6500, Loss: 7.330931111937389e-05\n",
            "Batch 6600, Loss: 0.09983032196760178\n",
            "Batch 6700, Loss: 0.0001454449666198343\n",
            "Batch 6800, Loss: 0.00010634051432134584\n",
            "Batch 6900, Loss: 0.00010537797788856551\n",
            "Batch 7000, Loss: 0.00012386498565319926\n",
            "Batch 7100, Loss: 7.760061271255836e-05\n",
            "Batch 7200, Loss: 0.07216782122850418\n",
            "Batch 7300, Loss: 6.483965262304991e-05\n",
            "Batch 7400, Loss: 0.07205281406641006\n",
            "Batch 7500, Loss: 4.993466063751839e-05\n",
            "Batch 7600, Loss: 6.626895628869534e-05\n",
            "Batch 7700, Loss: 0.00012803429854102433\n",
            "Batch 7800, Loss: 8.044621790759265e-05\n",
            "Batch 7900, Loss: 7.341847231145948e-05\n",
            "Batch 8000, Loss: 4.838169479626231e-05\n",
            "Batch 8100, Loss: 3.8841928471811116e-05\n",
            "Batch 8200, Loss: 5.445181159302592e-05\n",
            "Batch 8300, Loss: 0.07219738513231277\n",
            "Batch 8400, Loss: 0.00010525820835027844\n",
            "Batch 8500, Loss: 0.00034588351263664663\n",
            "Batch 8600, Loss: 0.00011657893628580496\n",
            "Batch 8700, Loss: 0.0001562793622724712\n",
            "Batch 8800, Loss: 3.871861918014474e-05\n",
            "Batch 8900, Loss: 6.757960363756865e-05\n",
            "Batch 9000, Loss: 0.0001016798778437078\n",
            "Batch 9100, Loss: 0.00011121986608486623\n",
            "Batch 9200, Loss: 6.411672075046226e-05\n",
            "Batch 9300, Loss: 0.00010799956362461671\n",
            "Batch 9400, Loss: 0.00011597612319746986\n",
            "Batch 9500, Loss: 0.07207819819450378\n",
            "Batch 9600, Loss: 8.867980068316683e-05\n",
            "Batch 9700, Loss: 0.00011037581862183288\n",
            "Batch 9800, Loss: 8.855536725604907e-05\n",
            "Batch 9900, Loss: 0.0001010796768241562\n",
            "Batch 10000, Loss: 0.00015007953334134072\n",
            "Batch 10100, Loss: 8.772474393481389e-05\n",
            "Batch 10200, Loss: 0.07200832664966583\n",
            "Batch 10300, Loss: 0.031727880239486694\n",
            "Batch 10400, Loss: 4.873840953223407e-05\n",
            "Batch 10500, Loss: 8.140518184518442e-05\n",
            "Batch 10600, Loss: 8.152291411533952e-05\n",
            "Batch 10700, Loss: 0.07211744040250778\n",
            "Batch 10800, Loss: 5.5287811846937984e-05\n",
            "Batch 10900, Loss: 3.574349466362037e-05\n",
            "Batch 11000, Loss: 4.6706729335710406e-05\n",
            "Batch 11100, Loss: 0.00041832280112430453\n",
            "Batch 11200, Loss: 7.498358172597364e-05\n",
            "Batch 11300, Loss: 7.820639439160004e-05\n",
            "Batch 11400, Loss: 6.865609611850232e-05\n",
            "Batch 11500, Loss: 0.00010394694982096553\n",
            "Batch 11600, Loss: 7.198879029601812e-05\n",
            "Batch 11700, Loss: 4.410002293298021e-05\n",
            "Batch 11800, Loss: 2.871140713978093e-05\n",
            "Batch 11900, Loss: 0.00012660492211580276\n",
            "Batch 12000, Loss: 5.792024967377074e-05\n",
            "Batch 12100, Loss: 7.353601540671661e-05\n",
            "Batch 12200, Loss: 9.750956087373197e-05\n",
            "Batch 12300, Loss: 0.027912957593798637\n",
            "Batch 12400, Loss: 0.00012933832476846874\n",
            "Batch 12500, Loss: 0.0002712902205530554\n",
            "Batch 12600, Loss: 0.00018055055988952518\n",
            "Batch 12700, Loss: 0.0002206149511039257\n",
            "Batch 12800, Loss: 6.257471977733076e-05\n",
            "Batch 12900, Loss: 0.00017577908874955028\n",
            "Batch 13000, Loss: 0.00013100840442348272\n",
            "Batch 13100, Loss: 0.00013041021884419024\n",
            "Batch 13200, Loss: 6.280626257648692e-05\n",
            "Batch 13300, Loss: 4.384799467516132e-05\n",
            "Batch 13400, Loss: 0.0001053649393725209\n",
            "Batch 13500, Loss: 0.07199259102344513\n",
            "Batch 13600, Loss: 5.1001450628973544e-05\n",
            "Batch 13700, Loss: 8.117047400446609e-05\n",
            "Batch 13800, Loss: 7.889693370088935e-05\n",
            "Batch 13900, Loss: 0.00012480573786888272\n",
            "Batch 14000, Loss: 0.00013541767839342356\n",
            "Batch 14100, Loss: 9.523486369289458e-05\n",
            "Batch 14200, Loss: 0.029217686504125595\n",
            "Batch 14300, Loss: 0.00039446732262149453\n",
            "Batch 14400, Loss: 7.878236647229642e-05\n",
            "Batch 14500, Loss: 7.425001967931166e-05\n",
            "Batch 14600, Loss: 0.07202062010765076\n",
            "Batch 14700, Loss: 8.604412141721696e-05\n",
            "Batch 14800, Loss: 6.20861173956655e-05\n",
            "Batch 14900, Loss: 0.07198412716388702\n",
            "Batch 15000, Loss: 6.75747578497976e-05\n",
            "Batch 15100, Loss: 0.000124442478409037\n",
            "Batch 15200, Loss: 9.881280129775405e-05\n",
            "Batch 15300, Loss: 0.00012909168435726315\n",
            "Batch 15400, Loss: 5.171488010091707e-05\n",
            "Batch 15500, Loss: 4.75384367746301e-05\n",
            "Batch 15600, Loss: 0.0002773626474663615\n",
            "Batch 15700, Loss: 0.00027425953885540366\n",
            "Batch 15800, Loss: 7.937138434499502e-05\n",
            "Batch 15900, Loss: 0.00010571441816864535\n",
            "Batch 16000, Loss: 0.000121815457532648\n",
            "Batch 16100, Loss: 0.00015078912838362157\n",
            "Batch 16200, Loss: 4.825577707379125e-05\n",
            "Batch 16300, Loss: 5.218764636083506e-05\n",
            "Batch 16400, Loss: 7.161773100961e-05\n",
            "Batch 16500, Loss: 0.00012408182374201715\n",
            "Batch 16600, Loss: 0.07203300297260284\n",
            "Batch 16700, Loss: 0.07203134149312973\n",
            "Batch 16800, Loss: 0.00011609199282247573\n",
            "Batch 16900, Loss: 0.07207509130239487\n",
            "Batch 17000, Loss: 0.00011418628128012642\n",
            "Batch 17100, Loss: 7.352912507485598e-05\n",
            "Batch 17200, Loss: 5.1109676860505715e-05\n",
            "Batch 17300, Loss: 0.00011203338362975046\n",
            "Batch 17400, Loss: 9.39120800467208e-05\n",
            "Batch 17500, Loss: 0.0001423208595952019\n",
            "Batch 17600, Loss: 0.14397351443767548\n",
            "Batch 17700, Loss: 4.4436244934331626e-05\n",
            "Batch 17800, Loss: 3.9547900087200105e-05\n",
            "Batch 17900, Loss: 0.00013957660121377558\n",
            "Batch 18000, Loss: 0.072111576795578\n",
            "Batch 18100, Loss: 0.0722377821803093\n",
            "Batch 18200, Loss: 0.00019007378432434052\n",
            "Batch 18300, Loss: 0.00025470275431871414\n",
            "Batch 18400, Loss: 6.529602978844196e-05\n",
            "Batch 18500, Loss: 0.00014125322923064232\n",
            "Batch 18600, Loss: 0.00010595900675980374\n",
            "Batch 18700, Loss: 0.00014172714145388454\n",
            "Batch 18800, Loss: 7.686369644943625e-05\n",
            "Batch 18900, Loss: 7.364257180597633e-05\n",
            "Batch 19000, Loss: 7.853200804674998e-05\n",
            "Batch 19100, Loss: 7.948613347252831e-05\n",
            "Batch 19200, Loss: 0.07205673307180405\n",
            "Batch 19300, Loss: 6.779978139093146e-05\n",
            "Batch 19400, Loss: 0.0001201425984618254\n",
            "Batch 19500, Loss: 0.00011990620259894058\n",
            "Batch 19600, Loss: 9.630021668272093e-05\n",
            "Batch 19700, Loss: 0.07203990966081619\n",
            "Batch 19800, Loss: 8.472990884911269e-05\n",
            "Batch 19900, Loss: 6.339135143207386e-05\n",
            "Batch 20000, Loss: 5.146825424162671e-05\n",
            "Batch 20100, Loss: 0.0001433987490599975\n",
            "Batch 20200, Loss: 0.00010512203152757138\n",
            "Batch 20300, Loss: 4.37183516623918e-05\n",
            "Batch 20400, Loss: 7.042555080261081e-05\n",
            "Batch 20500, Loss: 0.00013039755867794156\n",
            "Batch 20600, Loss: 4.204171273158863e-05\n",
            "Batch 20700, Loss: 5.468465678859502e-05\n",
            "Batch 20800, Loss: 0.00027032734942622483\n",
            "Batch 20900, Loss: 0.00010261595161864534\n",
            "Batch 21000, Loss: 0.0001547210122225806\n",
            "Batch 21100, Loss: 0.07215647399425507\n",
            "Batch 21200, Loss: 0.00010393167758593336\n",
            "Batch 21300, Loss: 0.0001065499018295668\n",
            "Batch 21400, Loss: 5.6122134992619976e-05\n",
            "Batch 21500, Loss: 0.07205387204885483\n",
            "Batch 21600, Loss: 6.304097041720524e-05\n",
            "Batch 21700, Loss: 6.709025183226913e-05\n",
            "Batch 21800, Loss: 0.00012491471716202796\n",
            "Batch 21900, Loss: 0.00030233844881877303\n",
            "Batch 22000, Loss: 0.00010441005724715069\n",
            "Batch 22100, Loss: 0.00023252292885445058\n",
            "Batch 22200, Loss: 0.00023908508592285216\n",
            "Batch 22300, Loss: 0.00010178569209529087\n",
            "Batch 22400, Loss: 4.730037835543044e-05\n",
            "Batch 22500, Loss: 3.6803561670240015e-05\n",
            "Batch 22600, Loss: 7.948985876282677e-05\n",
            "Batch 22700, Loss: 0.00012193654401926324\n",
            "Batch 22800, Loss: 0.00012635045277420431\n",
            "Batch 22900, Loss: 7.996542262844741e-05\n",
            "Batch 23000, Loss: 6.601599307032302e-05\n",
            "Batch 23100, Loss: 7.67472738516517e-05\n",
            "Batch 23200, Loss: 0.0002362192899454385\n",
            "Batch 23300, Loss: 8.99839578778483e-05\n",
            "Batch 23400, Loss: 7.209235627669841e-05\n",
            "Batch 23500, Loss: 0.00011418311623856425\n",
            "Batch 23600, Loss: 6.566019874298945e-05\n",
            "Batch 23700, Loss: 0.00014590268256142735\n",
            "Batch 23800, Loss: 8.390431321458891e-05\n",
            "Batch 23900, Loss: 5.934078581049107e-05\n",
            "Batch 24000, Loss: 0.07202191650867462\n",
            "Batch 24100, Loss: 0.14407499134540558\n",
            "Batch 24200, Loss: 8.46172115416266e-05\n",
            "Batch 24300, Loss: 0.0001831637491704896\n",
            "Batch 24400, Loss: 0.00024397608649451286\n",
            "Batch 24500, Loss: 0.00014411764277610928\n",
            "Batch 24600, Loss: 0.00015150710532907397\n",
            "Batch 24700, Loss: 0.00014733117131982\n",
            "Batch 24800, Loss: 0.00010298330016667023\n",
            "Batch 24900, Loss: 0.07200724631547928\n",
            "Batch 25000, Loss: 0.0001584215642651543\n",
            "Batch 25100, Loss: 6.219900387804955e-05\n",
            "Batch 25200, Loss: 5.552642687689513e-05\n",
            "Batch 25300, Loss: 0.00013898198085371405\n",
            "Batch 25400, Loss: 9.272509487345815e-05\n",
            "Batch 25500, Loss: 0.00020081049297004938\n",
            "Batch 25600, Loss: 9.213271550834179e-05\n",
            "Batch 25700, Loss: 0.000143635697895661\n",
            "Batch 25800, Loss: 0.00010476679017301649\n",
            "Batch 25900, Loss: 6.578165630344301e-05\n",
            "Batch 26000, Loss: 7.925496174721047e-05\n",
            "Batch 26100, Loss: 9.892493835650384e-05\n",
            "Batch 26200, Loss: 6.696861237287521e-05\n",
            "Batch 26300, Loss: 8.235055429395288e-05\n",
            "Batch 26400, Loss: 5.611971209873445e-05\n",
            "Batch 26500, Loss: 9.570187830831856e-05\n",
            "Batch 26600, Loss: 9.963821503333747e-05\n",
            "Batch 26700, Loss: 4.9199814384337515e-05\n",
            "Batch 26800, Loss: 0.0001306375052081421\n",
            "Batch 26900, Loss: 5.6476430472685024e-05\n",
            "Batch 27000, Loss: 8.353679004358128e-05\n",
            "Batch 27100, Loss: 0.03090060129761696\n",
            "Batch 27200, Loss: 0.0002064114814857021\n",
            "Batch 27300, Loss: 5.9576610510703176e-05\n",
            "Batch 27400, Loss: 5.9218778915237635e-05\n",
            "Batch 27500, Loss: 5.9579775552265346e-05\n",
            "Batch 27600, Loss: 7.209943578345701e-05\n",
            "Batch 27700, Loss: 4.215440640109591e-05\n",
            "Batch 27800, Loss: 9.664354001870379e-05\n",
            "Batch 27900, Loss: 7.494558667531237e-05\n",
            "Batch 28000, Loss: 7.220170664368197e-05\n",
            "Batch 28100, Loss: 0.030150456354022026\n",
            "Batch 28200, Loss: 8.245654316851869e-05\n",
            "Batch 28300, Loss: 0.00019090021669398993\n",
            "Batch 28400, Loss: 5.848950968356803e-05\n",
            "Batch 28500, Loss: 6.433577800635248e-05\n",
            "Batch 28600, Loss: 6.373875658027828e-05\n",
            "Batch 28700, Loss: 0.00010010653204517439\n",
            "Batch 28800, Loss: 9.5095339929685e-05\n",
            "Batch 28900, Loss: 0.00029666966293007135\n",
            "Batch 29000, Loss: 0.07199782133102417\n",
            "Batch 29100, Loss: 8.818522474030033e-05\n",
            "Batch 29200, Loss: 0.00012955759302712977\n",
            "Batch 29300, Loss: 3.906024358002469e-05\n",
            "Batch 29400, Loss: 8.174607501132414e-05\n",
            "Batch 29500, Loss: 0.00017093222413677722\n",
            "Batch 29600, Loss: 0.00018899343558587134\n",
            "Batch 29700, Loss: 8.806321420706809e-05\n",
            "Batch 29800, Loss: 0.03033291921019554\n",
            "Batch 29900, Loss: 0.00010094964818563312\n",
            "Batch 30000, Loss: 0.00014291401021182537\n",
            "Batch 30100, Loss: 0.0002180899609811604\n",
            "Batch 30200, Loss: 0.00017432896129321307\n",
            "Batch 30300, Loss: 8.413325122091919e-05\n",
            "Batch 30400, Loss: 6.839643174316734e-05\n",
            "Batch 30500, Loss: 7.6621538028121e-05\n",
            "Batch 30600, Loss: 9.975408465834334e-05\n",
            "Batch 30700, Loss: 0.00011644946789601818\n",
            "Batch 30800, Loss: 0.07213226705789566\n",
            "Batch 30900, Loss: 0.14402836561203003\n",
            "Batch 31000, Loss: 0.03139277920126915\n",
            "Batch 31100, Loss: 7.328546780627221e-05\n",
            "Batch 31200, Loss: 6.112102710176259e-05\n",
            "Batch 31300, Loss: 9.116833098232746e-05\n",
            "Batch 31400, Loss: 6.302793190116063e-05\n",
            "Batch 31500, Loss: 7.089757855283096e-05\n",
            "Batch 31600, Loss: 5.885777500225231e-05\n",
            "Batch 31700, Loss: 9.224169480148703e-05\n",
            "Batch 31800, Loss: 3.381465648999438e-05\n",
            "Batch 31900, Loss: 5.086677265353501e-05\n",
            "Batch 32000, Loss: 0.0719950720667839\n",
            "Batch 32100, Loss: 0.00010428841051179916\n",
            "Batch 32200, Loss: 0.07201726734638214\n",
            "Batch 32300, Loss: 5.8263929531676695e-05\n",
            "Batch 32400, Loss: 6.267214484978467e-05\n",
            "Batch 32500, Loss: 7.316011033253744e-05\n",
            "Batch 32600, Loss: 0.00013301697617862374\n",
            "Batch 32700, Loss: 0.07203347980976105\n",
            "Batch 32800, Loss: 0.0004947076668031514\n",
            "Batch 32900, Loss: 7.030018605291843e-05\n",
            "Batch 33000, Loss: 0.07198577374219894\n",
            "Batch 33100, Loss: 6.470349035225809e-05\n",
            "Batch 33200, Loss: 6.839381967438385e-05\n",
            "Batch 33300, Loss: 4.216371962684207e-05\n",
            "Batch 33400, Loss: 5.5875883845146745e-05\n",
            "Batch 33500, Loss: 8.663984044687822e-05\n",
            "Batch 33600, Loss: 0.00011239384912187234\n",
            "Batch 33700, Loss: 0.0001869732077466324\n",
            "Batch 33800, Loss: 0.00011442397953942418\n",
            "Batch 33900, Loss: 7.793404802214354e-05\n",
            "Batch 34000, Loss: 6.756414222763851e-05\n",
            "Batch 34100, Loss: 0.00011799564526882023\n",
            "Batch 34200, Loss: 7.555229240097106e-05\n",
            "Batch 34300, Loss: 6.255385960685089e-05\n",
            "Batch 34400, Loss: 0.00010083042434416711\n",
            "Batch 34500, Loss: 9.355627844342962e-05\n",
            "Batch 34600, Loss: 5.111116843181662e-05\n",
            "Batch 34700, Loss: 7.793647091602907e-05\n",
            "Batch 34800, Loss: 6.315440987236798e-05\n",
            "Batch 34900, Loss: 8.830854494590312e-05\n",
            "Batch 35000, Loss: 8.008371514733881e-05\n",
            "Batch 35100, Loss: 0.0720505341887474\n",
            "Batch 35200, Loss: 6.21947183390148e-05\n",
            "Batch 35300, Loss: 5.718912143493071e-05\n",
            "Batch 35400, Loss: 0.00014232737885322422\n",
            "Batch 35500, Loss: 6.446021143347025e-05\n",
            "Batch 35600, Loss: 5.9212074120296165e-05\n",
            "Batch 35700, Loss: 7.447951065842062e-05\n",
            "Batch 35800, Loss: 0.026896335184574127\n",
            "Batch 35900, Loss: 0.00010154519259231165\n",
            "Batch 36000, Loss: 7.006790110608563e-05\n",
            "Batch 36100, Loss: 0.00010333370300941169\n",
            "Batch 36200, Loss: 7.853219722164795e-05\n",
            "Batch 36300, Loss: 8.401626837439835e-05\n",
            "Batch 36400, Loss: 5.0635237130336463e-05\n",
            "Batch 36500, Loss: 0.07200105488300323\n",
            "Batch 36600, Loss: 0.07234761118888855\n",
            "Batch 36700, Loss: 0.00010357382416259497\n",
            "Batch 36800, Loss: 0.07200749218463898\n",
            "Batch 36900, Loss: 5.254491770756431e-05\n",
            "Batch 37000, Loss: 9.558377496432513e-05\n",
            "Batch 37100, Loss: 0.00011823725799331442\n",
            "Batch 37200, Loss: 0.00011263210035394877\n",
            "Batch 37300, Loss: 4.884197915089317e-05\n",
            "Batch 37400, Loss: 6.005049726809375e-05\n",
            "Batch 37500, Loss: 3.4533662983449176e-05\n",
            "Batch 37600, Loss: 5.0630394980544224e-05\n",
            "Batch 37700, Loss: 8.85471745277755e-05\n",
            "Batch 37800, Loss: 0.00017731772095430642\n",
            "Batch 37900, Loss: 9.52251793933101e-05\n",
            "Batch 38000, Loss: 0.0002370552538195625\n",
            "Batch 38100, Loss: 0.07205148786306381\n",
            "Batch 38200, Loss: 9.630077693145722e-05\n",
            "Batch 38300, Loss: 0.07201964408159256\n",
            "Batch 38400, Loss: 9.785437578102574e-05\n",
            "Batch 38500, Loss: 5.52872552361805e-05\n",
            "Batch 38600, Loss: 0.00013206391304265708\n",
            "Batch 38700, Loss: 6.541897164424881e-05\n",
            "Batch 38800, Loss: 8.819137292448431e-05\n",
            "Batch 38900, Loss: 6.195647438289598e-05\n",
            "Batch 39000, Loss: 0.07203813642263412\n",
            "Batch 39100, Loss: 8.652247925056145e-05\n",
            "Batch 39200, Loss: 6.624716479564086e-05\n",
            "Batch 39300, Loss: 4.275904575479217e-05\n",
            "Batch 39400, Loss: 6.375086377374828e-05\n",
            "Batch 39500, Loss: 0.00012789420725312084\n",
            "Batch 39600, Loss: 6.518035661429167e-05\n",
            "Batch 39700, Loss: 0.07200474292039871\n",
            "Batch 39800, Loss: 0.00011704465578077361\n",
            "Batch 39900, Loss: 5.83876135351602e-05\n",
            "Batch 40000, Loss: 7.471478602383286e-05\n",
            "Batch 40100, Loss: 0.07199735194444656\n",
            "Batch 40200, Loss: 0.07201141119003296\n",
            "Batch 40300, Loss: 3.7873131077503785e-05\n",
            "Batch 40400, Loss: 3.1082439818419516e-05\n",
            "Batch 40500, Loss: 0.00014577618276234716\n",
            "Batch 40600, Loss: 8.067943417700008e-05\n",
            "Batch 40700, Loss: 0.0002985857427120209\n",
            "Batch 40800, Loss: 6.076505087548867e-05\n",
            "Batch 40900, Loss: 6.589473196072504e-05\n",
            "Batch 41000, Loss: 0.07215241342782974\n",
            "Batch 41100, Loss: 0.0001385060022585094\n",
            "Batch 41200, Loss: 7.471888238796964e-05\n",
            "Batch 41300, Loss: 0.00016951729776337743\n",
            "Batch 41400, Loss: 0.030571425333619118\n",
            "Batch 41500, Loss: 0.00011145142343593761\n",
            "Batch 41600, Loss: 0.07206079363822937\n",
            "Batch 41700, Loss: 8.223264012485743e-05\n",
            "Batch 41800, Loss: 3.455079786363058e-05\n",
            "Batch 41900, Loss: 7.150819146772847e-05\n",
            "Batch 42000, Loss: 0.0001225376909133047\n",
            "Batch 42100, Loss: 0.0002066549932351336\n",
            "Batch 42200, Loss: 7.937231566756964e-05\n",
            "Batch 42300, Loss: 0.07211636006832123\n",
            "Batch 42400, Loss: 0.00011681571049848571\n",
            "Batch 42500, Loss: 0.00012122399493819103\n",
            "Batch 42600, Loss: 0.00011264122440479696\n",
            "Batch 42700, Loss: 0.07201632112264633\n",
            "Batch 42800, Loss: 0.07203682512044907\n",
            "Batch 42900, Loss: 5.147216506884433e-05\n",
            "Batch 43000, Loss: 6.721208046656102e-05\n",
            "Batch 43100, Loss: 6.650124123552814e-05\n",
            "Batch 43200, Loss: 0.00027748598949983716\n",
            "Batch 43300, Loss: 9.499083535047248e-05\n",
            "Batch 43400, Loss: 8.938264363678172e-05\n",
            "Batch 43500, Loss: 9.868910274235532e-05\n",
            "Batch 43600, Loss: 8.998582052299753e-05\n",
            "Batch 43700, Loss: 0.00013386383943725377\n",
            "Batch 43800, Loss: 4.1814459109446034e-05\n",
            "Batch 43900, Loss: 9.165397204924375e-05\n",
            "Batch 44000, Loss: 0.00012873587547801435\n",
            "Batch 44100, Loss: 6.804715667385608e-05\n",
            "Batch 44200, Loss: 5.147179399500601e-05\n",
            "Batch 44300, Loss: 4.5630255044670776e-05\n",
            "Batch 44400, Loss: 0.000207491684705019\n",
            "Batch 44500, Loss: 0.00016450929979328066\n",
            "Batch 44600, Loss: 0.00016331383085343987\n",
            "Batch 44700, Loss: 0.0002561453729867935\n",
            "Batch 44800, Loss: 0.00019044172950088978\n",
            "Batch 44900, Loss: 0.00017756532179191709\n",
            "Batch 45000, Loss: 8.044472633628175e-05\n",
            "Batch 45100, Loss: 0.00010095020843436942\n",
            "Batch 45200, Loss: 0.0001697505358606577\n",
            "Batch 45300, Loss: 0.00022347176854964346\n",
            "Batch 45400, Loss: 0.07202623039484024\n",
            "Batch 45500, Loss: 5.4237967560766265e-05\n",
            "Batch 45600, Loss: 3.7663205148419365e-05\n",
            "Batch 45700, Loss: 6.53165188850835e-05\n",
            "Batch 45800, Loss: 6.746429426129907e-05\n",
            "Batch 45900, Loss: 4.278791675460525e-05\n",
            "Batch 46000, Loss: 4.743747558677569e-05\n",
            "Batch 46100, Loss: 7.318692951230332e-05\n",
            "Batch 46200, Loss: 0.07206426560878754\n",
            "Batch 46300, Loss: 7.748288044240326e-05\n",
            "Batch 46400, Loss: 7.008391548879445e-05\n",
            "Batch 46500, Loss: 8.069955219980329e-05\n",
            "Batch 46600, Loss: 8.212086686398834e-05\n",
            "Batch 46700, Loss: 9.548373782308772e-05\n",
            "Batch 46800, Loss: 8.9875356934499e-05\n",
            "Batch 46900, Loss: 0.07203278690576553\n",
            "Batch 47000, Loss: 0.00012015899119433016\n",
            "Batch 47100, Loss: 0.07200070470571518\n",
            "Batch 47200, Loss: 9.142950148088858e-05\n",
            "Batch 47300, Loss: 9.155170118901879e-05\n",
            "Batch 47400, Loss: 0.00011515291407704353\n",
            "Batch 47500, Loss: 8.642188913654536e-05\n",
            "Batch 47600, Loss: 0.07203123718500137\n",
            "Batch 47700, Loss: 0.00012695961049757898\n",
            "Batch 47800, Loss: 5.804281681776047e-05\n",
            "Batch 47900, Loss: 5.8398789406055585e-05\n",
            "Batch 48000, Loss: 0.0002139374118996784\n",
            "Batch 48100, Loss: 5.1962066208943725e-05\n",
            "Batch 48200, Loss: 3.7657988286809996e-05\n",
            "Batch 48300, Loss: 0.00020368680998217314\n",
            "Batch 48400, Loss: 8.213055116357282e-05\n",
            "Batch 48500, Loss: 0.00015951287059579045\n",
            "Batch 48600, Loss: 0.00018031544459518045\n",
            "Batch 48700, Loss: 0.00013483106158673763\n",
            "Batch 48800, Loss: 0.07215137034654617\n",
            "Batch 48900, Loss: 0.0001537878706585616\n",
            "Batch 49000, Loss: 9.846276952885091e-05\n",
            "Batch 49100, Loss: 0.03161803260445595\n",
            "Batch 49200, Loss: 8.439553494099528e-05\n",
            "Batch 49300, Loss: 0.0002614008844830096\n",
            "Batch 49400, Loss: 7.830605318304151e-05\n",
            "Batch 49500, Loss: 6.37680059298873e-05\n",
            "Batch 49600, Loss: 0.07200166583061218\n",
            "Batch 49700, Loss: 0.00013136942288838327\n",
            "Batch 49800, Loss: 8.761222125031054e-05\n",
            "Batch 49900, Loss: 4.683544102590531e-05\n",
            "Batch 50000, Loss: 0.00015855849778745323\n",
            "Batch 50100, Loss: 5.828124994877726e-05\n",
            "Batch 50200, Loss: 0.0001455535675631836\n",
            "Batch 50300, Loss: 0.00016165805573109537\n",
            "Batch 50400, Loss: 0.00010108209971804172\n",
            "Batch 50500, Loss: 8.439404336968437e-05\n",
            "Batch 50600, Loss: 9.416187822353095e-05\n",
            "Batch 50700, Loss: 0.00011825440014945343\n",
            "Batch 50800, Loss: 8.666014764457941e-05\n",
            "Batch 50900, Loss: 5.0060021749231964e-05\n",
            "Batch 51000, Loss: 5.137381231179461e-05\n",
            "Batch 51100, Loss: 7.450093107763678e-05\n",
            "Batch 51200, Loss: 4.350506787886843e-05\n",
            "Batch 51300, Loss: 5.793049422209151e-05\n",
            "Batch 51400, Loss: 0.0719902291893959\n",
            "Batch 51500, Loss: 8.093612996162847e-05\n",
            "Batch 51600, Loss: 4.206164157949388e-05\n",
            "Batch 51700, Loss: 4.98169356433209e-05\n",
            "Batch 51800, Loss: 5.852433969266713e-05\n",
            "Batch 51900, Loss: 4.492725929594599e-05\n",
            "Batch 52000, Loss: 5.411055462900549e-05\n",
            "Batch 52100, Loss: 0.00011634514521574602\n",
            "Batch 52200, Loss: 0.00016773983952589333\n",
            "Batch 52300, Loss: 0.07205532491207123\n",
            "Batch 52400, Loss: 0.00018722936511039734\n",
            "Batch 52500, Loss: 0.00011456332140369341\n",
            "Batch 52600, Loss: 5.6490400311304256e-05\n",
            "Batch 52700, Loss: 0.03196023404598236\n",
            "Batch 52800, Loss: 3.036623093066737e-05\n",
            "Batch 52900, Loss: 0.00011801017535617575\n",
            "Batch 53000, Loss: 7.364964403677732e-05\n",
            "Batch 53100, Loss: 5.278707612887956e-05\n",
            "Batch 53200, Loss: 5.231226168689318e-05\n",
            "Batch 53300, Loss: 0.00011705322685884312\n",
            "Batch 53400, Loss: 0.07213394343852997\n",
            "Batch 53500, Loss: 0.0003196427715010941\n",
            "Batch 53600, Loss: 9.18911027838476e-05\n",
            "Batch 53700, Loss: 0.00014388066483661532\n",
            "Batch 53800, Loss: 7.222405838547274e-05\n",
            "Batch 53900, Loss: 3.4092758141923696e-05\n",
            "Batch 54000, Loss: 0.00010122180538019165\n",
            "Batch 54100, Loss: 0.07202491909265518\n",
            "Batch 54200, Loss: 4.136647476116195e-05\n",
            "Batch 54300, Loss: 0.00013460750051308423\n",
            "Batch 54400, Loss: 0.00010026114614447579\n",
            "Batch 54500, Loss: 0.00011552828073035926\n",
            "Batch 54600, Loss: 0.00017854449106380343\n",
            "Batch 54700, Loss: 8.011631143745035e-05\n",
            "Batch 54800, Loss: 7.583208207506686e-05\n",
            "Batch 54900, Loss: 3.468100112513639e-05\n",
            "Batch 55000, Loss: 0.07199869304895401\n",
            "Batch 55100, Loss: 0.07208573073148727\n",
            "Batch 55200, Loss: 0.00010205188300460577\n",
            "Batch 55300, Loss: 0.00011731272388715297\n",
            "Batch 55400, Loss: 3.992416895925999e-05\n",
            "Batch 55500, Loss: 7.808382360963151e-05\n",
            "Batch 55600, Loss: 3.157735773129389e-05\n",
            "Batch 55700, Loss: 0.07205401360988617\n",
            "Batch 55800, Loss: 5.209618029766716e-05\n",
            "Batch 55900, Loss: 0.0001775822602212429\n",
            "Batch 56000, Loss: 0.07204161584377289\n",
            "Batch 56100, Loss: 0.00017084744467865676\n",
            "Batch 56200, Loss: 5.1013743359362707e-05\n",
            "Batch 56300, Loss: 9.048896026797593e-05\n",
            "Batch 56400, Loss: 0.07217365503311157\n",
            "Batch 56500, Loss: 6.270026642596349e-05\n",
            "Batch 56600, Loss: 0.00017698388546705246\n",
            "Batch 56700, Loss: 0.0605328306555748\n",
            "Batch 56800, Loss: 0.000167389604030177\n",
            "Batch 56900, Loss: 0.00014294903667178005\n",
            "Batch 57000, Loss: 6.890254007885233e-05\n",
            "Batch 57100, Loss: 4.1113329643849283e-05\n",
            "Batch 57200, Loss: 0.07203743606805801\n",
            "Batch 57300, Loss: 0.00013995738117955625\n",
            "Batch 57400, Loss: 8.106391760520637e-05\n",
            "Batch 57500, Loss: 0.0001045458484441042\n",
            "Batch 57600, Loss: 5.555399548029527e-05\n",
            "Batch 57700, Loss: 0.07204114645719528\n",
            "Batch 57800, Loss: 0.0001406856026733294\n",
            "Batch 57900, Loss: 0.028177613392472267\n",
            "Batch 58000, Loss: 0.00010812158143380657\n",
            "Batch 58100, Loss: 0.00013793111429549754\n",
            "Batch 58200, Loss: 0.00015366771549452096\n",
            "Batch 58300, Loss: 6.674898759229109e-05\n",
            "Batch 58400, Loss: 3.1090636184671894e-05\n",
            "Batch 58500, Loss: 0.0721273273229599\n",
            "Batch 58600, Loss: 8.653869008412585e-05\n",
            "Batch 58700, Loss: 4.4568128942046314e-05\n",
            "Batch 58800, Loss: 3.896654743584804e-05\n",
            "Batch 58900, Loss: 8.605566836195067e-05\n",
            "Batch 59000, Loss: 7.843253843020648e-05\n",
            "Batch 59100, Loss: 0.0001249281340278685\n",
            "Batch 59200, Loss: 0.00024129843222908676\n",
            "Batch 59300, Loss: 0.0001856819144450128\n",
            "Batch 59400, Loss: 0.0001164060304290615\n",
            "Batch 59500, Loss: 9.015900286613032e-05\n",
            "Batch 59600, Loss: 4.921113213640638e-05\n",
            "Batch 59700, Loss: 0.00012962118489667773\n",
            "Batch 59800, Loss: 4.6858691348461434e-05\n",
            "Batch 59900, Loss: 8.833920583128929e-05\n",
            "Batch 60000, Loss: 9.775352373253554e-05\n",
            "Batch 60100, Loss: 7.314758113352582e-05\n",
            "Batch 60200, Loss: 0.0001045237950165756\n",
            "Batch 60300, Loss: 0.00013920542551204562\n",
            "Batch 60400, Loss: 6.677000055788085e-05\n",
            "Batch 60500, Loss: 0.029250821098685265\n",
            "Batch 60600, Loss: 0.00015024097228888422\n",
            "Batch 60700, Loss: 8.918289677239954e-05\n",
            "Batch 60800, Loss: 3.612235013861209e-05\n",
            "Batch 60900, Loss: 0.029856208711862564\n",
            "Batch 61000, Loss: 0.00017182950978167355\n",
            "Batch 61100, Loss: 0.00010379117156844586\n",
            "Batch 61200, Loss: 0.00016796593263279647\n",
            "Batch 61300, Loss: 0.0002000363019760698\n",
            "Batch 61400, Loss: 5.1212849939474836e-05\n",
            "Batch 61500, Loss: 0.00010734882380347699\n",
            "Batch 61600, Loss: 0.00011162182636326179\n",
            "Batch 61700, Loss: 8.132784569170326e-05\n",
            "Batch 61800, Loss: 0.00011715562868630514\n",
            "Batch 61900, Loss: 0.0001517428900115192\n",
            "Batch 62000, Loss: 5.8996156440116465e-05\n",
            "Batch 62100, Loss: 9.653824963606894e-05\n",
            "Batch 62200, Loss: 6.67560743750073e-05\n",
            "Batch 62300, Loss: 0.07205339521169662\n",
            "Batch 62400, Loss: 0.0001007927639875561\n",
            "Batch 62500, Loss: 0.00025860851746983826\n",
            "Batch 62600, Loss: 8.78393038874492e-05\n",
            "Batch 62700, Loss: 3.270372690167278e-05\n",
            "Batch 62800, Loss: 0.00012965609494131058\n",
            "Batch 62900, Loss: 7.466912211384624e-05\n",
            "Batch 63000, Loss: 0.00023430395231116563\n",
            "Batch 63100, Loss: 7.551632006652653e-05\n",
            "Batch 63200, Loss: 0.00018645112868398428\n",
            "Batch 63300, Loss: 0.028002304956316948\n",
            "Batch 63400, Loss: 0.00010419468162581325\n",
            "Batch 63500, Loss: 0.00011421922681620345\n",
            "Batch 63600, Loss: 0.00012618256732821465\n",
            "Batch 63700, Loss: 0.00012316023639868945\n",
            "Batch 63800, Loss: 0.00018786459986586124\n",
            "Batch 63900, Loss: 8.357736805919558e-05\n",
            "Batch 64000, Loss: 7.494258898077533e-05\n",
            "Batch 64100, Loss: 0.028263991698622704\n",
            "Batch 64200, Loss: 0.00010454582661623135\n",
            "Batch 64300, Loss: 0.0001409981632605195\n",
            "Batch 64400, Loss: 6.313018093351275e-05\n",
            "Batch 64500, Loss: 0.00014493729395326227\n",
            "Batch 64600, Loss: 5.25287032360211e-05\n",
            "Batch 64700, Loss: 8.137219992931932e-05\n",
            "Batch 64800, Loss: 0.0001705819449853152\n",
            "Batch 64900, Loss: 0.0002740264171734452\n",
            "Batch 65000, Loss: 0.00011035213537979871\n",
            "Batch 65100, Loss: 0.07207159698009491\n",
            "Batch 65200, Loss: 0.00011010176240233704\n",
            "Batch 65300, Loss: 0.0720382034778595\n",
            "Batch 65400, Loss: 0.027382947504520416\n",
            "Batch 65500, Loss: 7.276127143995836e-05\n",
            "Batch 65600, Loss: 6.500096060335636e-05\n",
            "Batch 65700, Loss: 0.0001295050315093249\n",
            "Batch 65800, Loss: 5.5921791499713436e-05\n",
            "Batch 65900, Loss: 3.6617100704461336e-05\n",
            "Batch 66000, Loss: 2.5627339709899388e-05\n",
            "Batch 66100, Loss: 6.71518937451765e-05\n",
            "Batch 66200, Loss: 0.00016373427934013307\n",
            "Batch 66300, Loss: 0.0001631375780561939\n",
            "Batch 66400, Loss: 0.028155211359262466\n",
            "Batch 66500, Loss: 0.0003284210106357932\n",
            "Batch 66600, Loss: 0.0001421241177013144\n",
            "Batch 66700, Loss: 9.777313243830577e-05\n",
            "Batch 66800, Loss: 7.344062760239467e-05\n",
            "Batch 66900, Loss: 4.589885429595597e-05\n",
            "Batch 67000, Loss: 4.386401269584894e-05\n",
            "Batch 67100, Loss: 4.828650344279595e-05\n",
            "Batch 67200, Loss: 0.0001013447399600409\n",
            "Batch 67300, Loss: 0.00011373656889190897\n",
            "Batch 67400, Loss: 8.748274558456615e-05\n",
            "Batch 67500, Loss: 5.390224032453261e-05\n",
            "Batch 67600, Loss: 0.00015392235945910215\n",
            "Batch 67700, Loss: 6.077621947042644e-05\n",
            "Batch 67800, Loss: 9.212432632921264e-05\n",
            "Batch 67900, Loss: 7.734037353657186e-05\n",
            "Batch 68000, Loss: 4.836083098780364e-05\n",
            "Batch 68100, Loss: 5.05037241964601e-05\n",
            "Batch 68200, Loss: 7.103764801286161e-05\n",
            "Batch 68300, Loss: 0.00017214074614457786\n",
            "Batch 68400, Loss: 0.00015818382962606847\n",
            "Batch 68500, Loss: 7.982832175912336e-05\n",
            "Batch 68600, Loss: 0.00013576752098742872\n",
            "Batch 68700, Loss: 7.06486971466802e-05\n",
            "Batch 68800, Loss: 0.0002092745853587985\n",
            "Batch 68900, Loss: 0.0001010593623504974\n",
            "Batch 69000, Loss: 0.00010309282515663654\n",
            "Batch 69100, Loss: 6.886490882607177e-05\n",
            "Batch 69200, Loss: 3.9402231777785346e-05\n",
            "Batch 69300, Loss: 0.00010330259101465344\n",
            "Batch 69400, Loss: 8.912761404644698e-05\n",
            "Batch 69500, Loss: 7.6484982855618e-05\n",
            "Batch 69600, Loss: 0.07207603752613068\n",
            "Batch 69700, Loss: 7.099536742316559e-05\n",
            "Batch 69800, Loss: 0.00013717047113459557\n",
            "Batch 69900, Loss: 0.00015983087359927595\n",
            "Batch 70000, Loss: 0.00014802435180172324\n",
            "Batch 70100, Loss: 5.786548354080878e-05\n",
            "Batch 70200, Loss: 0.07207421213388443\n",
            "Batch 70300, Loss: 0.07201901823282242\n",
            "Batch 70400, Loss: 7.13483605068177e-05\n",
            "Batch 70500, Loss: 5.1664024795172736e-05\n",
            "Batch 70600, Loss: 8.613091631559655e-05\n",
            "Batch 70700, Loss: 8.541056740796193e-05\n",
            "Batch 70800, Loss: 7.93164290371351e-05\n",
            "Batch 70900, Loss: 0.0002059039834421128\n",
            "Batch 71000, Loss: 0.07209926843643188\n",
            "Batch 71100, Loss: 0.00017775587912183255\n",
            "Batch 71200, Loss: 5.3561041568173096e-05\n",
            "Batch 71300, Loss: 4.4984815758652985e-05\n",
            "Batch 71400, Loss: 8.420570520684123e-05\n",
            "Batch 71500, Loss: 9.327349835075438e-05\n",
            "Batch 71600, Loss: 7.371707761194557e-05\n",
            "Batch 71700, Loss: 6.776680675102398e-05\n",
            "Batch 71800, Loss: 0.00014489558816421777\n",
            "Batch 71900, Loss: 0.000219956724322401\n",
            "Batch 72000, Loss: 0.0002608612703625113\n",
            "Batch 72100, Loss: 0.0001575292117195204\n",
            "Batch 72200, Loss: 0.00011746472591767088\n",
            "Batch 72300, Loss: 8.035268547246233e-05\n",
            "Batch 72400, Loss: 5.0819831812987104e-05\n",
            "Batch 72500, Loss: 9.099713497562334e-05\n",
            "Batch 72600, Loss: 7.072209700709209e-05\n",
            "Batch 72700, Loss: 0.00013213767670094967\n",
            "Batch 72800, Loss: 0.00013594898337032646\n",
            "Batch 72900, Loss: 0.00010685726010706276\n",
            "Batch 73000, Loss: 7.596843352075666e-05\n",
            "Batch 73100, Loss: 0.07208016514778137\n",
            "Batch 73200, Loss: 7.666194142075256e-05\n",
            "Batch 73300, Loss: 9.468867938267067e-05\n",
            "Batch 73400, Loss: 0.00015120716125238687\n",
            "Batch 73500, Loss: 6.678848149022087e-05\n",
            "Batch 73600, Loss: 0.00012269454600755125\n",
            "Batch 73700, Loss: 8.311709098052233e-05\n",
            "Batch 73800, Loss: 6.36865952401422e-05\n",
            "Batch 73900, Loss: 4.567551877698861e-05\n",
            "Batch 74000, Loss: 4.019128391519189e-05\n",
            "Batch 74100, Loss: 0.00011792149598477408\n",
            "Batch 74200, Loss: 9.94252841337584e-05\n",
            "Batch 74300, Loss: 0.07207120954990387\n",
            "Batch 74400, Loss: 6.390883208950981e-05\n",
            "Batch 74500, Loss: 8.275458822026849e-05\n",
            "Batch 74600, Loss: 6.42720697214827e-05\n",
            "Batch 74700, Loss: 4.256644024280831e-05\n",
            "Batch 74800, Loss: 5.2583101933123544e-05\n",
            "Batch 74900, Loss: 0.10437077283859253\n",
            "Batch 75000, Loss: 4.281064320821315e-05\n",
            "Batch 75100, Loss: 3.803947402047925e-05\n",
            "Batch 75200, Loss: 0.00015059593715704978\n",
            "Batch 75300, Loss: 0.00020992013742215931\n",
            "Batch 75400, Loss: 6.571011908818036e-05\n",
            "Batch 75500, Loss: 0.00015416828682646155\n",
            "Batch 75600, Loss: 9.896964184008539e-05\n",
            "Batch 75700, Loss: 7.130179437808692e-05\n",
            "Batch 75800, Loss: 0.00011855579941766337\n",
            "Batch 75900, Loss: 0.00010468686377862468\n",
            "Batch 76000, Loss: 0.00018332155013922602\n",
            "Batch 76100, Loss: 9.145576041191816e-05\n",
            "Batch 76200, Loss: 0.00012829378829337656\n",
            "Batch 76300, Loss: 7.09478699718602e-05\n",
            "Batch 76400, Loss: 7.486939284717664e-05\n",
            "Batch 76500, Loss: 0.000105284656456206\n",
            "Batch 76600, Loss: 0.0001477212499594316\n",
            "Batch 76700, Loss: 0.07207047939300537\n",
            "Batch 76800, Loss: 7.058033952489495e-05\n",
            "Batch 76900, Loss: 4.518301284406334e-05\n",
            "Batch 77000, Loss: 8.202157914638519e-05\n",
            "Batch 77100, Loss: 5.268760287435725e-05\n",
            "Batch 77200, Loss: 6.807546742493287e-05\n",
            "Batch 77300, Loss: 7.809164526406676e-05\n",
            "Batch 77400, Loss: 6.091593240853399e-05\n",
            "Batch 77500, Loss: 8.50020587677136e-05\n",
            "Batch 77600, Loss: 0.00038168724859133363\n",
            "Batch 77700, Loss: 6.496837158920243e-05\n",
            "Batch 77800, Loss: 0.0001865340891527012\n",
            "Batch 77900, Loss: 0.0001063442396116443\n",
            "Batch 78000, Loss: 0.0001708502386463806\n",
            "Batch 78100, Loss: 6.401091377483681e-05\n",
            "Batch 78200, Loss: 0.028962353244423866\n",
            "Batch 78300, Loss: 0.00023232134117279202\n",
            "Batch 78400, Loss: 0.00011015431664418429\n",
            "Batch 78500, Loss: 9.894803224597126e-05\n",
            "Batch 78600, Loss: 0.00010634181671775877\n",
            "Batch 78700, Loss: 8.01084897830151e-05\n",
            "Batch 78800, Loss: 7.33158303773962e-05\n",
            "Batch 78900, Loss: 9.036769915837795e-05\n",
            "Batch 79000, Loss: 7.378227746812627e-05\n",
            "Batch 79100, Loss: 0.0001013302244246006\n",
            "Batch 79200, Loss: 3.717852450790815e-05\n",
            "Batch 79300, Loss: 5.446745490189642e-05\n",
            "Batch 79400, Loss: 0.00010121584637090564\n",
            "Batch 79500, Loss: 0.00011062301200581715\n",
            "Batch 79600, Loss: 5.9235168009763584e-05\n",
            "Batch 79700, Loss: 0.0001349560625385493\n",
            "Batch 79800, Loss: 0.027355117723345757\n",
            "Batch 79900, Loss: 0.0001276907860301435\n",
            "Batch 80000, Loss: 0.00011635185364866629\n",
            "Batch 80100, Loss: 0.0001797274744603783\n",
            "Batch 80200, Loss: 8.869637531461194e-05\n",
            "Batch 80300, Loss: 0.02878965623676777\n",
            "Batch 80400, Loss: 0.0002199157461291179\n",
            "Batch 80500, Loss: 0.00011027130676666275\n",
            "Batch 80600, Loss: 0.00011384705430828035\n",
            "Batch 80700, Loss: 0.00021012617798987776\n",
            "Batch 80800, Loss: 0.00012218765914440155\n",
            "Batch 80900, Loss: 5.1008340960834175e-05\n",
            "Batch 81000, Loss: 8.403805986745283e-05\n",
            "Batch 81100, Loss: 0.00020607687474694103\n",
            "Batch 81200, Loss: 5.816110206069425e-05\n",
            "Batch 81300, Loss: 8.618177525931969e-05\n",
            "Batch 81400, Loss: 7.521643419750035e-05\n",
            "Batch 81500, Loss: 0.07202514261007309\n",
            "Batch 81600, Loss: 6.23325613560155e-05\n",
            "Batch 81700, Loss: 6.256913184188306e-05\n",
            "Batch 81800, Loss: 0.03055240958929062\n",
            "Batch 81900, Loss: 9.285883425036445e-05\n",
            "Batch 82000, Loss: 0.00011300486221443862\n",
            "Batch 82100, Loss: 4.373418414616026e-05\n",
            "Batch 82200, Loss: 0.00011086145968874916\n",
            "Batch 82300, Loss: 0.00011515068035805598\n",
            "Batch 82400, Loss: 6.1020062275929376e-05\n",
            "Batch 82500, Loss: 6.030569420545362e-05\n",
            "Batch 82600, Loss: 0.00016046296514105052\n",
            "Batch 82700, Loss: 6.722213583998382e-05\n",
            "Batch 82800, Loss: 0.00019152338791172951\n",
            "Batch 82900, Loss: 5.576839976129122e-05\n",
            "Batch 83000, Loss: 6.889117503305897e-05\n",
            "Batch 83100, Loss: 4.134188930038363e-05\n",
            "Batch 83200, Loss: 3.657351771835238e-05\n",
            "Batch 83300, Loss: 8.522429561708122e-05\n",
            "Batch 83400, Loss: 6.363928696373478e-05\n",
            "Batch 83500, Loss: 6.22068255324848e-05\n",
            "Batch 83600, Loss: 0.00013804121408611536\n",
            "Batch 83700, Loss: 0.00012338082888163626\n",
            "Batch 83800, Loss: 0.000157120666699484\n",
            "Batch 83900, Loss: 0.029615100473165512\n",
            "Batch 84000, Loss: 0.00013399127055890858\n",
            "Batch 84100, Loss: 0.00015282604726962745\n",
            "Batch 84200, Loss: 0.07206115126609802\n",
            "Batch 84300, Loss: 7.592093606945127e-05\n",
            "Batch 84400, Loss: 7.05583588569425e-05\n",
            "Batch 84500, Loss: 0.00016271602362394333\n",
            "Batch 84600, Loss: 0.00010000109614338726\n",
            "Batch 84700, Loss: 0.00010513394954614341\n",
            "Batch 84800, Loss: 8.832251478452235e-05\n",
            "Batch 84900, Loss: 7.102759991539642e-05\n",
            "Batch 85000, Loss: 6.363556167343631e-05\n",
            "Batch 85100, Loss: 0.00013135396875441074\n",
            "Batch 85200, Loss: 9.237264021066949e-05\n",
            "Batch 85300, Loss: 6.470851803896949e-05\n",
            "Batch 85400, Loss: 6.411057256627828e-05\n",
            "Batch 85500, Loss: 6.267922435654327e-05\n",
            "Batch 85600, Loss: 3.179697159794159e-05\n",
            "Batch 85700, Loss: 6.829192716395482e-05\n",
            "Batch 85800, Loss: 0.00012754231283906847\n",
            "Batch 85900, Loss: 0.00014411391748581082\n",
            "Batch 86000, Loss: 8.436684584012255e-05\n",
            "Batch 86100, Loss: 9.557092562317848e-05\n",
            "Batch 86200, Loss: 7.852604903746396e-05\n",
            "Batch 86300, Loss: 9.18739679036662e-05\n",
            "Batch 86400, Loss: 0.00011298604658804834\n",
            "Batch 86500, Loss: 6.15911849308759e-05\n",
            "Batch 86600, Loss: 0.00012848008191213012\n",
            "Batch 86700, Loss: 8.734249422559515e-05\n",
            "Batch 86800, Loss: 5.015036731492728e-05\n",
            "Batch 86900, Loss: 6.003987800795585e-05\n",
            "Batch 87000, Loss: 0.00010057894542114809\n",
            "Batch 87100, Loss: 0.00024873577058315277\n",
            "Batch 87200, Loss: 6.385723827406764e-05\n",
            "Batch 87300, Loss: 0.00010975735494866967\n",
            "Batch 87400, Loss: 7.590343011543155e-05\n",
            "Batch 87500, Loss: 5.98098267801106e-05\n",
            "Batch 87600, Loss: 0.00011810499563580379\n",
            "Batch 87700, Loss: 0.00015018368139863014\n",
            "Batch 87800, Loss: 0.00011715419532265514\n",
            "Batch 87900, Loss: 0.00016150994633790106\n",
            "Batch 88000, Loss: 8.293770952150226e-05\n",
            "Batch 88100, Loss: 0.00010476716124685481\n",
            "Batch 88200, Loss: 0.00018435066158417612\n",
            "Batch 88300, Loss: 6.528504309244454e-05\n",
            "Batch 88400, Loss: 5.872961992281489e-05\n",
            "Batch 88500, Loss: 7.589672168251127e-05\n",
            "Batch 88600, Loss: 4.358591104391962e-05\n",
            "Batch 88700, Loss: 0.00011930636537726969\n",
            "Batch 88800, Loss: 9.521642641630024e-05\n",
            "Batch 88900, Loss: 4.716551848105155e-05\n",
            "Batch 89000, Loss: 2.569887146819383e-05\n",
            "Batch 89100, Loss: 3.524316707625985e-05\n",
            "Batch 89200, Loss: 3.691029269248247e-05\n",
            "Batch 89300, Loss: 4.072700176038779e-05\n",
            "Batch 89400, Loss: 0.00015698002243880183\n",
            "Batch 89500, Loss: 9.688681893749163e-05\n",
            "Batch 89600, Loss: 5.30091165273916e-05\n",
            "Batch 89700, Loss: 9.34275594772771e-05\n",
            "Batch 89800, Loss: 8.746879029786214e-05\n",
            "Batch 89900, Loss: 0.02763310819864273\n",
            "Batch 90000, Loss: 6.039827349013649e-05\n",
            "Batch 90100, Loss: 5.88547954976093e-05\n",
            "Batch 90200, Loss: 6.898487481521443e-05\n",
            "Batch 90300, Loss: 0.0001270499633392319\n",
            "Batch 90400, Loss: 0.029994193464517593\n",
            "Epoch 2: Average Loss: 0.0062864392157044174\n",
            "Batch 0, Loss: 7.983671093825251e-05\n",
            "Batch 100, Loss: 0.00011179474677192047\n",
            "Batch 200, Loss: 0.00010893098806263879\n",
            "Batch 300, Loss: 6.7916203988716e-05\n",
            "Batch 400, Loss: 2.8915934308315627e-05\n",
            "Batch 500, Loss: 5.169234282220714e-05\n",
            "Batch 600, Loss: 0.0001744461478665471\n",
            "Batch 700, Loss: 8.436573261860758e-05\n",
            "Batch 800, Loss: 0.0001470787392463535\n",
            "Batch 900, Loss: 0.00011274406278971583\n",
            "Batch 1000, Loss: 0.00010117859346792102\n",
            "Batch 1100, Loss: 0.029666369780898094\n",
            "Batch 1200, Loss: 9.283127292292193e-05\n",
            "Batch 1300, Loss: 7.35129215172492e-05\n",
            "Batch 1400, Loss: 0.00013874165597371757\n",
            "Batch 1500, Loss: 0.00010845074575627223\n",
            "Batch 1600, Loss: 0.000132774977828376\n",
            "Batch 1700, Loss: 0.00011203021131223068\n",
            "Batch 1800, Loss: 5.229196176514961e-05\n",
            "Batch 1900, Loss: 0.07199817150831223\n",
            "Batch 2000, Loss: 0.07201390713453293\n",
            "Batch 2100, Loss: 0.072017140686512\n",
            "Batch 2200, Loss: 0.00013492458674591035\n",
            "Batch 2300, Loss: 7.029310654615983e-05\n",
            "Batch 2400, Loss: 0.00012060906738042831\n",
            "Batch 2500, Loss: 3.857537740259431e-05\n",
            "Batch 2600, Loss: 0.00012144735956098884\n",
            "Batch 2700, Loss: 0.00011596401600399986\n",
            "Batch 2800, Loss: 0.00023740105098113418\n",
            "Batch 2900, Loss: 7.387373625533655e-05\n",
            "Batch 3000, Loss: 0.00010069835843751207\n",
            "Batch 3100, Loss: 0.00016962458903435618\n",
            "Batch 3200, Loss: 6.6238411818631e-05\n",
            "Batch 3300, Loss: 0.00010868733079405501\n",
            "Batch 3400, Loss: 0.00013718836999032646\n",
            "Batch 3500, Loss: 6.206805119290948e-05\n",
            "Batch 3600, Loss: 4.632580021279864e-05\n",
            "Batch 3700, Loss: 0.03046511858701706\n",
            "Batch 3800, Loss: 7.101213850546628e-05\n",
            "Batch 3900, Loss: 9.045077604241669e-05\n",
            "Batch 4000, Loss: 5.6581866374472156e-05\n",
            "Batch 4100, Loss: 6.683747051283717e-05\n",
            "Batch 4200, Loss: 6.731229950673878e-05\n",
            "Batch 4300, Loss: 8.675086428411305e-05\n",
            "Batch 4400, Loss: 0.00027330542798154056\n",
            "Batch 4500, Loss: 0.00011858841025969014\n",
            "Batch 4600, Loss: 0.00017778943583834916\n",
            "Batch 4700, Loss: 0.00014900295354891568\n",
            "Batch 4800, Loss: 0.00011846918641822413\n",
            "Batch 4900, Loss: 0.00013504343223758042\n",
            "Batch 5000, Loss: 6.898376159369946e-05\n",
            "Batch 5100, Loss: 0.00015817659732419997\n",
            "Batch 5200, Loss: 8.341756620211527e-05\n",
            "Batch 5300, Loss: 4.799611269845627e-05\n",
            "Batch 5400, Loss: 9.474457328906283e-05\n",
            "Batch 5500, Loss: 9.74872091319412e-05\n",
            "Batch 5600, Loss: 5.0149435992352664e-05\n",
            "Batch 5700, Loss: 7.960441871546209e-05\n",
            "Batch 5800, Loss: 7.126379932742566e-05\n",
            "Batch 5900, Loss: 5.265333311399445e-05\n",
            "Batch 6000, Loss: 0.00013253523502498865\n",
            "Batch 6100, Loss: 0.00030198594322428107\n",
            "Batch 6200, Loss: 0.00013266339374240488\n",
            "Batch 6300, Loss: 8.711410919204354e-05\n",
            "Batch 6400, Loss: 7.006324449321255e-05\n",
            "Batch 6500, Loss: 9.188160765916109e-05\n",
            "Batch 6600, Loss: 4.871829514740966e-05\n",
            "Batch 6700, Loss: 0.00013886349915992469\n",
            "Batch 6800, Loss: 6.457290874095634e-05\n",
            "Batch 6900, Loss: 0.00013326137559488416\n",
            "Batch 7000, Loss: 0.0001345717319054529\n",
            "Batch 7100, Loss: 0.00018638206529431045\n",
            "Batch 7200, Loss: 0.00010845409997273237\n",
            "Batch 7300, Loss: 7.04149279044941e-05\n",
            "Batch 7400, Loss: 8.496890222886577e-05\n",
            "Batch 7500, Loss: 0.0001212115166708827\n",
            "Batch 7600, Loss: 0.0002821272937580943\n",
            "Batch 7700, Loss: 8.03135844762437e-05\n",
            "Batch 7800, Loss: 0.00010094182653119788\n",
            "Batch 7900, Loss: 0.0001395749277435243\n",
            "Batch 8000, Loss: 8.079437247943133e-05\n",
            "Batch 8100, Loss: 0.07205827534198761\n",
            "Batch 8200, Loss: 0.00014148534683045\n",
            "Batch 8300, Loss: 7.364405610132962e-05\n",
            "Batch 8400, Loss: 8.531929779564962e-05\n",
            "Batch 8500, Loss: 3.6200413887854666e-05\n",
            "Batch 8600, Loss: 2.4630244297441095e-05\n",
            "Batch 8700, Loss: 2.3311275072046556e-05\n",
            "Batch 8800, Loss: 7.148919394239783e-05\n",
            "Batch 8900, Loss: 0.00020486742141656578\n",
            "Batch 9000, Loss: 8.42554509290494e-05\n",
            "Batch 9100, Loss: 7.876857853261754e-05\n",
            "Batch 9200, Loss: 9.23620245885104e-05\n",
            "Batch 9300, Loss: 8.616221748525277e-05\n",
            "Batch 9400, Loss: 5.2652401791419834e-05\n",
            "Batch 9500, Loss: 5.5873646488180384e-05\n",
            "Batch 9600, Loss: 0.00012026312469970435\n",
            "Batch 9700, Loss: 8.592470840085298e-05\n",
            "Batch 9800, Loss: 8.223003533203155e-05\n",
            "Batch 9900, Loss: 0.00022083795920480043\n",
            "Batch 10000, Loss: 0.00010010690311901271\n",
            "Batch 10100, Loss: 0.00017731213301885873\n",
            "Batch 10200, Loss: 0.00012073908874299377\n",
            "Batch 10300, Loss: 0.00016354522085748613\n",
            "Batch 10400, Loss: 0.00016700061678420752\n",
            "Batch 10500, Loss: 3.429299977142364e-05\n",
            "Batch 10600, Loss: 2.509833939257078e-05\n",
            "Batch 10700, Loss: 0.0720175951719284\n",
            "Batch 10800, Loss: 5.335334935807623e-05\n",
            "Batch 10900, Loss: 8.209087536670268e-05\n",
            "Batch 11000, Loss: 5.1925188017776236e-05\n",
            "Batch 11100, Loss: 7.708182965870947e-05\n",
            "Batch 11200, Loss: 9.794620564207435e-05\n",
            "Batch 11300, Loss: 0.00019948161207139492\n",
            "Batch 11400, Loss: 0.0002117595140589401\n",
            "Batch 11500, Loss: 0.00011512795754242688\n",
            "Batch 11600, Loss: 8.066453301580623e-05\n",
            "Batch 11700, Loss: 5.311678251018748e-05\n",
            "Batch 11800, Loss: 7.94704828877002e-05\n",
            "Batch 11900, Loss: 7.27990991435945e-05\n",
            "Batch 12000, Loss: 6.277254578890279e-05\n",
            "Batch 12100, Loss: 5.8356694353278726e-05\n",
            "Batch 12200, Loss: 0.00014540790289174765\n",
            "Batch 12300, Loss: 0.00015232640726026148\n",
            "Batch 12400, Loss: 0.00017200043657794595\n",
            "Batch 12500, Loss: 0.0001500640792073682\n",
            "Batch 12600, Loss: 7.386907964246348e-05\n",
            "Batch 12700, Loss: 0.00011547315079951659\n",
            "Batch 12800, Loss: 9.50897519942373e-05\n",
            "Batch 12900, Loss: 8.411984163103625e-05\n",
            "Batch 13000, Loss: 8.792834705673158e-05\n",
            "Batch 13100, Loss: 0.00015744501433800906\n",
            "Batch 13200, Loss: 0.00014767468383070081\n",
            "Batch 13300, Loss: 0.00011392306623747572\n",
            "Batch 13400, Loss: 8.686710498295724e-05\n",
            "Batch 13500, Loss: 0.00010248518810840324\n",
            "Batch 13600, Loss: 0.0002422845718683675\n",
            "Batch 13700, Loss: 0.00019030479597859085\n",
            "Batch 13800, Loss: 7.648424798389897e-05\n",
            "Batch 13900, Loss: 0.028623266145586967\n",
            "Batch 14000, Loss: 0.00013408776430878788\n",
            "Batch 14100, Loss: 0.00013252517965156585\n",
            "Batch 14200, Loss: 0.028337521478533745\n",
            "Batch 14300, Loss: 9.688216232461855e-05\n",
            "Batch 14400, Loss: 8.303942013299093e-05\n",
            "Batch 14500, Loss: 0.00010772851965157315\n",
            "Batch 14600, Loss: 9.79504911811091e-05\n",
            "Batch 14700, Loss: 5.3711373766418546e-05\n",
            "Batch 14800, Loss: 5.693150160368532e-05\n",
            "Batch 14900, Loss: 0.030416356399655342\n",
            "Batch 15000, Loss: 0.00010772721725516021\n",
            "Batch 15100, Loss: 0.00015208461263682693\n",
            "Batch 15200, Loss: 5.43130372534506e-05\n",
            "Batch 15300, Loss: 4.41737865912728e-05\n",
            "Batch 15400, Loss: 4.9411977670388296e-05\n",
            "Batch 15500, Loss: 9.747473086463287e-05\n",
            "Batch 15600, Loss: 0.00012084006448276341\n",
            "Batch 15700, Loss: 5.9319365391274914e-05\n",
            "Batch 15800, Loss: 4.0479448216501623e-05\n",
            "Batch 15900, Loss: 5.049590254202485e-05\n",
            "Batch 16000, Loss: 0.0002779377973638475\n",
            "Batch 16100, Loss: 0.00010438993922434747\n",
            "Batch 16200, Loss: 0.0001790920359781012\n",
            "Batch 16300, Loss: 0.00010808768274728209\n",
            "Batch 16400, Loss: 0.00013109018618706614\n",
            "Batch 16500, Loss: 0.00010463564103702083\n",
            "Batch 16600, Loss: 5.336024332791567e-05\n",
            "Batch 16700, Loss: 4.8467012675246224e-05\n",
            "Batch 16800, Loss: 5.072502244729549e-05\n",
            "Batch 16900, Loss: 8.793616871116683e-05\n",
            "Batch 17000, Loss: 0.00017705914797261357\n",
            "Batch 17100, Loss: 4.704276580014266e-05\n",
            "Batch 17200, Loss: 0.00011548246402526274\n",
            "Batch 17300, Loss: 7.517787889810279e-05\n",
            "Batch 17400, Loss: 7.327485218411312e-05\n",
            "Batch 17500, Loss: 6.230182771105319e-05\n",
            "Batch 17600, Loss: 0.0001043873344315216\n",
            "Batch 17700, Loss: 0.00012108372175134718\n",
            "Batch 17800, Loss: 0.028494179248809814\n",
            "Batch 17900, Loss: 6.957556615816429e-05\n",
            "Batch 18000, Loss: 0.07210584729909897\n",
            "Batch 18100, Loss: 0.07203345745801926\n",
            "Batch 18200, Loss: 0.00015697350318077952\n",
            "Batch 18300, Loss: 3.9994396502152085e-05\n",
            "Batch 18400, Loss: 5.9432433772599325e-05\n",
            "Batch 18500, Loss: 6.13320735283196e-05\n",
            "Batch 18600, Loss: 0.00016828849038574845\n",
            "Batch 18700, Loss: 0.00010379606101196259\n",
            "Batch 18800, Loss: 6.909440708113834e-05\n",
            "Batch 18900, Loss: 0.00013909318658988923\n",
            "Batch 19000, Loss: 0.00015242981316987425\n",
            "Batch 19100, Loss: 9.21008613659069e-05\n",
            "Batch 19200, Loss: 5.764959496445954e-05\n",
            "Batch 19300, Loss: 0.00011237429134780541\n",
            "Batch 19400, Loss: 0.00012345665891189128\n",
            "Batch 19500, Loss: 0.00018039891438093036\n",
            "Batch 19600, Loss: 7.005206862231717e-05\n",
            "Batch 19700, Loss: 0.00019971914298366755\n",
            "Batch 19800, Loss: 0.00011631273810053244\n",
            "Batch 19900, Loss: 0.0001231032656505704\n",
            "Batch 20000, Loss: 0.00020615737594198436\n",
            "Batch 20100, Loss: 9.115156717598438e-05\n",
            "Batch 20200, Loss: 0.00017968539032153785\n",
            "Batch 20300, Loss: 0.00029082593391649425\n",
            "Batch 20400, Loss: 7.756075501674786e-05\n",
            "Batch 20500, Loss: 0.00015732634346932173\n",
            "Batch 20600, Loss: 0.00012907640484627336\n",
            "Batch 20700, Loss: 0.00017659302102401853\n",
            "Batch 20800, Loss: 0.00011058818199671805\n",
            "Batch 20900, Loss: 7.386963989119977e-05\n",
            "Batch 21000, Loss: 0.07202117890119553\n",
            "Batch 21100, Loss: 6.15906246821396e-05\n",
            "Batch 21200, Loss: 6.766771548427641e-05\n",
            "Batch 21300, Loss: 6.0035781643819064e-05\n",
            "Batch 21400, Loss: 0.07199684530496597\n",
            "Batch 21500, Loss: 0.0001104711918742396\n",
            "Batch 21600, Loss: 9.508565563010052e-05\n",
            "Batch 21700, Loss: 0.00020115180814173073\n",
            "Batch 21800, Loss: 0.00023227682686410844\n",
            "Batch 21900, Loss: 9.747417061589658e-05\n",
            "Batch 22000, Loss: 0.00011156133405165747\n",
            "Batch 22100, Loss: 9.712023165775463e-05\n",
            "Batch 22200, Loss: 0.0001581637334311381\n",
            "Batch 22300, Loss: 9.079540177481249e-05\n",
            "Batch 22400, Loss: 5.5387470638379455e-05\n",
            "Batch 22500, Loss: 3.3793792681535706e-05\n",
            "Batch 22600, Loss: 0.00010093810124089941\n",
            "Batch 22700, Loss: 5.693354978575371e-05\n",
            "Batch 22800, Loss: 5.454699930851348e-05\n",
            "Batch 22900, Loss: 7.565120904473588e-05\n",
            "Batch 23000, Loss: 9.533247794024646e-05\n",
            "Batch 23100, Loss: 0.00012204216909594834\n",
            "Batch 23200, Loss: 0.00012847338803112507\n",
            "Batch 23300, Loss: 0.00017587468028068542\n",
            "Batch 23400, Loss: 0.00022238095698412508\n",
            "Batch 23500, Loss: 0.00017552926146890968\n",
            "Batch 23600, Loss: 7.530082075390965e-05\n",
            "Batch 23700, Loss: 0.00012335157953202724\n",
            "Batch 23800, Loss: 0.00013038805627729744\n",
            "Batch 23900, Loss: 0.00010796808783197775\n",
            "Batch 24000, Loss: 6.397030665539205e-05\n",
            "Batch 24100, Loss: 0.00010046344686998054\n",
            "Batch 24200, Loss: 8.317204628838226e-05\n",
            "Batch 24300, Loss: 5.8129066019319e-05\n",
            "Batch 24400, Loss: 5.264643914415501e-05\n",
            "Batch 24500, Loss: 3.21296502079349e-05\n",
            "Batch 24600, Loss: 4.942669329466298e-05\n",
            "Batch 24700, Loss: 0.00010105210822075605\n",
            "Batch 24800, Loss: 0.0002236942236777395\n",
            "Batch 24900, Loss: 0.00012251533917151392\n",
            "Batch 25000, Loss: 9.235271136276424e-05\n",
            "Batch 25100, Loss: 8.508830796927214e-05\n",
            "Batch 25200, Loss: 0.028849627822637558\n",
            "Batch 25300, Loss: 7.685568562010303e-05\n",
            "Batch 25400, Loss: 0.029193514958024025\n",
            "Batch 25500, Loss: 6.15906246821396e-05\n",
            "Batch 25600, Loss: 6.54079849482514e-05\n",
            "Batch 25700, Loss: 0.0001006910897558555\n",
            "Batch 25800, Loss: 7.792100950609893e-05\n",
            "Batch 25900, Loss: 5.156940460437909e-05\n",
            "Batch 26000, Loss: 4.607787195709534e-05\n",
            "Batch 26100, Loss: 8.006602001842111e-05\n",
            "Batch 26200, Loss: 9.306542779086158e-05\n",
            "Batch 26300, Loss: 5.478263847180642e-05\n",
            "Batch 26400, Loss: 9.259655780624598e-05\n",
            "Batch 26500, Loss: 5.956021777819842e-05\n",
            "Batch 26600, Loss: 3.248990105930716e-05\n",
            "Batch 26700, Loss: 0.0720493346452713\n",
            "Batch 26800, Loss: 8.341551438206807e-05\n",
            "Batch 26900, Loss: 0.029431350529193878\n",
            "Batch 27000, Loss: 0.00012943930050823838\n",
            "Batch 27100, Loss: 9.688272257335484e-05\n",
            "Batch 27200, Loss: 8.19746419438161e-05\n",
            "Batch 27300, Loss: 9.425931057194248e-05\n",
            "Batch 27400, Loss: 0.00012489814253058285\n",
            "Batch 27500, Loss: 0.00012072829122189432\n",
            "Batch 27600, Loss: 7.303511665668339e-05\n",
            "Batch 27700, Loss: 7.410752004943788e-05\n",
            "Batch 27800, Loss: 0.00011584330059122294\n",
            "Batch 27900, Loss: 4.179434108664282e-05\n",
            "Batch 28000, Loss: 0.00010869646212086082\n",
            "Batch 28100, Loss: 0.00010964315879391506\n",
            "Batch 28200, Loss: 5.2284696721471846e-05\n",
            "Batch 28300, Loss: 0.00010702008148655295\n",
            "Batch 28400, Loss: 8.365004032384604e-05\n",
            "Batch 28500, Loss: 6.552701233886182e-05\n",
            "Batch 28600, Loss: 6.468840001616627e-05\n",
            "Batch 28700, Loss: 0.0001120225788326934\n",
            "Batch 28800, Loss: 5.9200152463745326e-05\n",
            "Batch 28900, Loss: 7.733349048066884e-05\n",
            "Batch 29000, Loss: 7.756038394290954e-05\n",
            "Batch 29100, Loss: 7.160748646128923e-05\n",
            "Batch 29200, Loss: 0.00012979714665561914\n",
            "Batch 29300, Loss: 8.030594472074881e-05\n",
            "Batch 29400, Loss: 0.00011023983097402379\n",
            "Batch 29500, Loss: 7.708797784289345e-05\n",
            "Batch 29600, Loss: 0.00011155444371979684\n",
            "Batch 29700, Loss: 4.990392699255608e-05\n",
            "Batch 29800, Loss: 3.858171112369746e-05\n",
            "Batch 29900, Loss: 8.317055471707135e-05\n",
            "Batch 30000, Loss: 0.00017647119238972664\n",
            "Batch 30100, Loss: 7.173023914219812e-05\n",
            "Batch 30200, Loss: 8.412877650698647e-05\n",
            "Batch 30300, Loss: 0.00012395776866469532\n",
            "Batch 30400, Loss: 7.280152203748003e-05\n",
            "Batch 30500, Loss: 5.491730917128734e-05\n",
            "Batch 30600, Loss: 0.030837377533316612\n",
            "Batch 30700, Loss: 4.91968312417157e-05\n",
            "Batch 30800, Loss: 0.00010630978067638353\n",
            "Batch 30900, Loss: 0.00026209879433736205\n",
            "Batch 31000, Loss: 8.572612568968907e-05\n",
            "Batch 31100, Loss: 6.072536780266091e-05\n",
            "Batch 31200, Loss: 9.423915616935119e-05\n",
            "Batch 31300, Loss: 0.00010569128062343225\n",
            "Batch 31400, Loss: 0.00019755237735807896\n",
            "Batch 31500, Loss: 0.00017365616804454476\n",
            "Batch 31600, Loss: 0.000186971461516805\n",
            "Batch 31700, Loss: 8.026568684726954e-05\n",
            "Batch 31800, Loss: 7.991585152922198e-05\n",
            "Batch 31900, Loss: 0.00023647199850529432\n",
            "Batch 32000, Loss: 9.218167542712763e-05\n",
            "Batch 32100, Loss: 0.00010471366840647534\n",
            "Batch 32200, Loss: 0.00010123277024831623\n",
            "Batch 32300, Loss: 7.350600935751572e-05\n",
            "Batch 32400, Loss: 5.919510658713989e-05\n",
            "Batch 32500, Loss: 0.00010382752225268632\n",
            "Batch 32600, Loss: 6.850389763712883e-05\n",
            "Batch 32700, Loss: 0.00011885980347869918\n",
            "Batch 32800, Loss: 0.00012939532462041825\n",
            "Batch 32900, Loss: 8.422469545621425e-05\n",
            "Batch 33000, Loss: 0.0001823335769586265\n",
            "Batch 33100, Loss: 5.586394763668068e-05\n",
            "Batch 33200, Loss: 8.697307930560783e-05\n",
            "Batch 33300, Loss: 0.0002036090736510232\n",
            "Batch 33400, Loss: 0.00010127879068022594\n",
            "Batch 33500, Loss: 0.00014470162568613887\n",
            "Batch 33600, Loss: 0.00011988084588665515\n",
            "Batch 33700, Loss: 9.703227988211438e-05\n",
            "Batch 33800, Loss: 0.0001266721374122426\n",
            "Batch 33900, Loss: 0.00018423791334498674\n",
            "Batch 34000, Loss: 0.00011393365275580436\n",
            "Batch 34100, Loss: 8.293787686852738e-05\n",
            "Batch 34200, Loss: 0.028988530859351158\n",
            "Batch 34300, Loss: 8.541801071260124e-05\n",
            "Batch 34400, Loss: 6.581964407814667e-05\n",
            "Batch 34500, Loss: 0.00010935551836155355\n",
            "Batch 34600, Loss: 7.428503158735111e-05\n",
            "Batch 34700, Loss: 4.029112096759491e-05\n",
            "Batch 34800, Loss: 4.35076690337155e-05\n",
            "Batch 34900, Loss: 0.00011804555106209591\n",
            "Batch 35000, Loss: 0.00010779016884043813\n",
            "Batch 35100, Loss: 8.643660112284124e-05\n",
            "Batch 35200, Loss: 0.0002000406529987231\n",
            "Batch 35300, Loss: 0.00012195645831525326\n",
            "Batch 35400, Loss: 0.000192389459698461\n",
            "Batch 35500, Loss: 0.00023663023603148758\n",
            "Batch 35600, Loss: 8.941988198785111e-05\n",
            "Batch 35700, Loss: 5.5295629863394424e-05\n",
            "Batch 35800, Loss: 5.575945397140458e-05\n",
            "Batch 35900, Loss: 3.7030808016425e-05\n",
            "Batch 36000, Loss: 0.02806949056684971\n",
            "Batch 36100, Loss: 0.0001150519383372739\n",
            "Batch 36200, Loss: 6.910352385602891e-05\n",
            "Batch 36300, Loss: 6.984789069974795e-05\n",
            "Batch 36400, Loss: 5.169587893760763e-05\n",
            "Batch 36500, Loss: 8.010121382540092e-05\n",
            "Batch 36600, Loss: 0.00024328073777724057\n",
            "Batch 36700, Loss: 8.759806223679334e-05\n",
            "Batch 36800, Loss: 7.861885387683287e-05\n",
            "Batch 36900, Loss: 5.301171404425986e-05\n",
            "Batch 37000, Loss: 3.7382676964625716e-05\n",
            "Batch 37100, Loss: 3.605251185945235e-05\n",
            "Batch 37200, Loss: 4.941588485962711e-05\n",
            "Batch 37300, Loss: 4.083410385646857e-05\n",
            "Batch 37400, Loss: 0.00014841703523416072\n",
            "Batch 37500, Loss: 8.496479858877137e-05\n",
            "Batch 37600, Loss: 0.00022934113803785294\n",
            "Batch 37700, Loss: 0.00015222934598568827\n",
            "Batch 37800, Loss: 0.0002390971640124917\n",
            "Batch 37900, Loss: 0.00016091509314719588\n",
            "Batch 38000, Loss: 0.0001300514122704044\n",
            "Batch 38100, Loss: 0.00012765965948347002\n",
            "Batch 38200, Loss: 0.0003208629786968231\n",
            "Batch 38300, Loss: 7.852045382605866e-05\n",
            "Batch 38400, Loss: 3.7368332414189354e-05\n",
            "Batch 38500, Loss: 0.00016424679779447615\n",
            "Batch 38600, Loss: 5.979417619528249e-05\n",
            "Batch 38700, Loss: 3.510644455673173e-05\n",
            "Batch 38800, Loss: 0.00010188049782300368\n",
            "Batch 38900, Loss: 0.00017909497546497732\n",
            "Batch 39000, Loss: 0.00023420955403707922\n",
            "Batch 39100, Loss: 0.00024266554100904614\n",
            "Batch 39200, Loss: 0.0001699712738627568\n",
            "Batch 39300, Loss: 6.824348383815959e-05\n",
            "Batch 39400, Loss: 0.00011451338650658727\n",
            "Batch 39500, Loss: 5.511047493200749e-05\n",
            "Batch 39600, Loss: 0.00010962026135530323\n",
            "Batch 39700, Loss: 0.00010040139022748917\n",
            "Batch 39800, Loss: 0.0001142777327913791\n",
            "Batch 39900, Loss: 6.705820123897865e-05\n",
            "Batch 40000, Loss: 7.192917837528512e-05\n",
            "Batch 40100, Loss: 7.253755757119507e-05\n",
            "Batch 40200, Loss: 0.00011415944754844531\n",
            "Batch 40300, Loss: 0.00012298588990233839\n",
            "Batch 40400, Loss: 6.060969099053182e-05\n",
            "Batch 40500, Loss: 0.00012225526734255254\n",
            "Batch 40600, Loss: 8.864291157806292e-05\n",
            "Batch 40700, Loss: 0.00013621666585095227\n",
            "Batch 40800, Loss: 8.195060945581645e-05\n",
            "Batch 40900, Loss: 0.00014360719069372863\n",
            "Batch 41000, Loss: 5.785188477602787e-05\n",
            "Batch 41100, Loss: 9.38826342462562e-05\n",
            "Batch 41200, Loss: 0.0001005757658276707\n",
            "Batch 41300, Loss: 9.101613250095397e-05\n",
            "Batch 41400, Loss: 0.0001655655651120469\n",
            "Batch 41500, Loss: 7.860912592150271e-05\n",
            "Batch 41600, Loss: 0.030106617137789726\n",
            "Batch 41700, Loss: 4.163582343608141e-05\n",
            "Batch 41800, Loss: 6.872501398902386e-05\n",
            "Batch 41900, Loss: 0.00017138583643827587\n",
            "Batch 42000, Loss: 6.795833178330213e-05\n",
            "Batch 42100, Loss: 4.616262231138535e-05\n",
            "Batch 42200, Loss: 7.919180643511936e-05\n",
            "Batch 42300, Loss: 0.00010031571582658216\n",
            "Batch 42400, Loss: 8.600740693509579e-05\n",
            "Batch 42500, Loss: 9.816657257033512e-05\n",
            "Batch 42600, Loss: 6.131456029834226e-05\n",
            "Batch 42700, Loss: 6.261048110900447e-05\n",
            "Batch 42800, Loss: 7.180195098044351e-05\n",
            "Batch 42900, Loss: 0.00011152220395160839\n",
            "Batch 43000, Loss: 0.00012881224392913282\n",
            "Batch 43100, Loss: 0.00015325078857131302\n",
            "Batch 43200, Loss: 8.468016312690452e-05\n",
            "Batch 43300, Loss: 0.00013738639245275408\n",
            "Batch 43400, Loss: 9.817644604481757e-05\n",
            "Batch 43500, Loss: 0.0001091163358069025\n",
            "Batch 43600, Loss: 8.349337440449744e-05\n",
            "Batch 43700, Loss: 7.967613055370748e-05\n",
            "Batch 43800, Loss: 6.607541581615806e-05\n",
            "Batch 43900, Loss: 6.630174175370485e-05\n",
            "Batch 44000, Loss: 0.00013797954306937754\n",
            "Batch 44100, Loss: 6.570937694050372e-05\n",
            "Batch 44200, Loss: 0.02952411025762558\n",
            "Batch 44300, Loss: 7.907072722446173e-05\n",
            "Batch 44400, Loss: 6.700790981994942e-05\n",
            "Batch 44500, Loss: 0.02875497005879879\n",
            "Batch 44600, Loss: 6.130654946900904e-05\n",
            "Batch 44700, Loss: 8.527607860742137e-05\n",
            "Batch 44800, Loss: 0.00012117536971345544\n",
            "Batch 44900, Loss: 0.00010614882194204256\n",
            "Batch 45000, Loss: 0.00010315822146367282\n",
            "Batch 45100, Loss: 4.019165862700902e-05\n",
            "Batch 45200, Loss: 8.120716665871441e-05\n",
            "Batch 45300, Loss: 0.00012891711958218366\n",
            "Batch 45400, Loss: 0.0001911157596623525\n",
            "Batch 45500, Loss: 8.742556383367628e-05\n",
            "Batch 45600, Loss: 0.00010219923569820821\n",
            "Batch 45700, Loss: 0.00013786775525659323\n",
            "Batch 45800, Loss: 0.00011389585415599868\n",
            "Batch 45900, Loss: 7.453334546880797e-05\n",
            "Batch 46000, Loss: 4.8416713980259374e-05\n",
            "Batch 46100, Loss: 0.00010208373714704067\n",
            "Batch 46200, Loss: 5.043443161412142e-05\n",
            "Batch 46300, Loss: 4.830364559893496e-05\n",
            "Batch 46400, Loss: 8.203983452403918e-05\n",
            "Batch 46500, Loss: 7.393278065137565e-05\n",
            "Batch 46600, Loss: 3.326236401335336e-05\n",
            "Batch 46700, Loss: 3.350265251356177e-05\n",
            "Batch 46800, Loss: 0.00011197786079719663\n",
            "Batch 46900, Loss: 0.00014357440522871912\n",
            "Batch 47000, Loss: 6.487523205578327e-05\n",
            "Batch 47100, Loss: 5.1029204769292846e-05\n",
            "Batch 47200, Loss: 0.00017172041407320648\n",
            "Batch 47300, Loss: 6.523660704260692e-05\n",
            "Batch 47400, Loss: 5.270790643407963e-05\n",
            "Batch 47500, Loss: 6.380413833539933e-05\n",
            "Batch 47600, Loss: 0.00010052807920146734\n",
            "Batch 47700, Loss: 9.325487189926207e-05\n",
            "Batch 47800, Loss: 0.00021565922361332923\n",
            "Batch 47900, Loss: 0.00012783645070157945\n",
            "Batch 48000, Loss: 6.31987422821112e-05\n",
            "Batch 48100, Loss: 0.00011722330236807466\n",
            "Batch 48200, Loss: 6.927640060894191e-05\n",
            "Batch 48300, Loss: 0.00013667158782482147\n",
            "Batch 48400, Loss: 0.0002113705122610554\n",
            "Batch 48500, Loss: 0.00013582341489382088\n",
            "Batch 48600, Loss: 0.00010112344898516312\n",
            "Batch 48700, Loss: 0.029497304931282997\n",
            "Batch 48800, Loss: 0.00010183262929785997\n",
            "Batch 48900, Loss: 0.00022126831754576415\n",
            "Batch 49000, Loss: 0.00011794124293373898\n",
            "Batch 49100, Loss: 0.00011794105375884101\n",
            "Batch 49200, Loss: 0.0001124515911214985\n",
            "Batch 49300, Loss: 7.96850654296577e-05\n",
            "Batch 49400, Loss: 7.46382211218588e-05\n",
            "Batch 49500, Loss: 3.73135699192062e-05\n",
            "Batch 49600, Loss: 2.3229500584420748e-05\n",
            "Batch 49700, Loss: 5.055196743342094e-05\n",
            "Batch 49800, Loss: 8.262773917522281e-05\n",
            "Batch 49900, Loss: 5.519243859453127e-05\n",
            "Batch 50000, Loss: 5.3299703722586855e-05\n",
            "Batch 50100, Loss: 0.028925545513629913\n",
            "Batch 50200, Loss: 5.3051211580168456e-05\n",
            "Batch 50300, Loss: 9.718635556055233e-05\n",
            "Batch 50400, Loss: 0.00011924730642931536\n",
            "Batch 50500, Loss: 0.00010350582306273282\n",
            "Batch 50600, Loss: 0.00010732166992966086\n",
            "Batch 50700, Loss: 3.874041067319922e-05\n",
            "Batch 50800, Loss: 8.024559065233916e-05\n",
            "Batch 50900, Loss: 7.416004518745467e-05\n",
            "Batch 51000, Loss: 0.00012211500143166631\n",
            "Batch 51100, Loss: 0.00013367531937547028\n",
            "Batch 51200, Loss: 7.332551467698067e-05\n",
            "Batch 51300, Loss: 6.295397906797007e-05\n",
            "Batch 51400, Loss: 4.613337659975514e-05\n",
            "Batch 51500, Loss: 3.539162571541965e-05\n",
            "Batch 51600, Loss: 3.396534884814173e-05\n",
            "Batch 51700, Loss: 9.526876965537667e-05\n",
            "Batch 51800, Loss: 9.991968545364216e-05\n",
            "Batch 51900, Loss: 8.036536746658385e-05\n",
            "Batch 52000, Loss: 9.479691652813926e-05\n",
            "Batch 52100, Loss: 0.00017003613174892962\n",
            "Batch 52200, Loss: 9.813174256123602e-05\n",
            "Batch 52300, Loss: 0.0002887529553845525\n",
            "Batch 52400, Loss: 8.977885590866208e-05\n",
            "Batch 52500, Loss: 0.0001290266664000228\n",
            "Batch 52600, Loss: 0.0001698039995972067\n",
            "Batch 52700, Loss: 0.00014284731878433377\n",
            "Batch 52800, Loss: 0.00010660857515176758\n",
            "Batch 52900, Loss: 0.00010529546125326306\n",
            "Batch 53000, Loss: 4.398230157676153e-05\n",
            "Batch 53100, Loss: 9.706974378786981e-05\n",
            "Batch 53200, Loss: 0.00010898071923293173\n",
            "Batch 53300, Loss: 4.230975901009515e-05\n",
            "Batch 53400, Loss: 0.00017773054423741996\n",
            "Batch 53500, Loss: 0.0001384452625643462\n",
            "Batch 53600, Loss: 0.00016575206245761365\n",
            "Batch 53700, Loss: 5.268927998258732e-05\n",
            "Batch 53800, Loss: 8.012637408683077e-05\n",
            "Batch 53900, Loss: 6.569484685314819e-05\n",
            "Batch 54000, Loss: 8.36977269500494e-05\n",
            "Batch 54100, Loss: 7.786270725773647e-05\n",
            "Batch 54200, Loss: 0.00013438562746159732\n",
            "Batch 54300, Loss: 0.0001530998997623101\n",
            "Batch 54400, Loss: 6.986466178204864e-05\n",
            "Batch 54500, Loss: 9.979823516914621e-05\n",
            "Batch 54600, Loss: 9.204795787809417e-05\n",
            "Batch 54700, Loss: 8.883441478246823e-05\n",
            "Batch 54800, Loss: 3.9105318137444556e-05\n",
            "Batch 54900, Loss: 0.00012066960334777832\n",
            "Batch 55000, Loss: 4.721357618109323e-05\n",
            "Batch 55100, Loss: 7.129862933652475e-05\n",
            "Batch 55200, Loss: 0.00012949238589499146\n",
            "Batch 55300, Loss: 0.00012162879284005612\n",
            "Batch 55400, Loss: 9.742256224853918e-05\n",
            "Batch 55500, Loss: 9.884707105811685e-05\n",
            "Batch 55600, Loss: 7.417028973577544e-05\n",
            "Batch 55700, Loss: 6.58105273032561e-05\n",
            "Batch 55800, Loss: 0.00013295604730956256\n",
            "Batch 55900, Loss: 5.425100607681088e-05\n",
            "Batch 56000, Loss: 8.69183277245611e-05\n",
            "Batch 56100, Loss: 0.00012006919860141352\n",
            "Batch 56200, Loss: 0.00018667809490580112\n",
            "Batch 56300, Loss: 0.00016442936612293124\n",
            "Batch 56400, Loss: 0.00011494446516735479\n",
            "Batch 56500, Loss: 0.00017438558279536664\n",
            "Batch 56600, Loss: 0.00014082438428886235\n",
            "Batch 56700, Loss: 6.866746116429567e-05\n",
            "Batch 56800, Loss: 8.416920172749087e-05\n",
            "Batch 56900, Loss: 0.00010886075324378908\n",
            "Batch 57000, Loss: 4.148568768869154e-05\n",
            "Batch 57100, Loss: 1.8873426597565413e-05\n",
            "Batch 57200, Loss: 2.8336817194940522e-05\n",
            "Batch 57300, Loss: 4.4066491682315245e-05\n",
            "Batch 57400, Loss: 8.282053022412583e-05\n",
            "Batch 57500, Loss: 9.545950888423249e-05\n",
            "Batch 57600, Loss: 8.941429405240342e-05\n",
            "Batch 57700, Loss: 0.00014674135309178382\n",
            "Batch 57800, Loss: 0.000152241627802141\n",
            "Batch 57900, Loss: 9.214854071615264e-05\n",
            "Batch 58000, Loss: 0.00012418651022017002\n",
            "Batch 58100, Loss: 0.00011524381261551753\n",
            "Batch 58200, Loss: 0.00012898677960038185\n",
            "Batch 58300, Loss: 9.167165990220383e-05\n",
            "Batch 58400, Loss: 0.00011871991591760889\n",
            "Batch 58500, Loss: 6.278278306126595e-05\n",
            "Batch 58600, Loss: 4.8090550990309566e-05\n",
            "Batch 58700, Loss: 7.437034946633503e-05\n",
            "Batch 58800, Loss: 5.4084845032775775e-05\n",
            "Batch 58900, Loss: 9.689947182778269e-05\n",
            "Batch 59000, Loss: 7.256941171362996e-05\n",
            "Batch 59100, Loss: 7.088806160027161e-05\n",
            "Batch 59200, Loss: 6.50482761557214e-05\n",
            "Batch 59300, Loss: 5.811862865812145e-05\n",
            "Batch 59400, Loss: 0.000200822192709893\n",
            "Batch 59500, Loss: 8.880590030457824e-05\n",
            "Batch 59600, Loss: 5.476921796798706e-05\n",
            "Batch 59700, Loss: 0.00012120069732191041\n",
            "Batch 59800, Loss: 0.00010191737965214998\n",
            "Batch 59900, Loss: 9.342195698991418e-05\n",
            "Batch 60000, Loss: 0.0001227522880071774\n",
            "Batch 60100, Loss: 0.00011618847929639742\n",
            "Batch 60200, Loss: 0.00011752954742405564\n",
            "Batch 60300, Loss: 6.25300090177916e-05\n",
            "Batch 60400, Loss: 3.210543218301609e-05\n",
            "Batch 60500, Loss: 8.578256529290229e-05\n",
            "Batch 60600, Loss: 8.948937465902418e-05\n",
            "Batch 60700, Loss: 0.00010036153980763629\n",
            "Batch 60800, Loss: 0.00022490126139018685\n",
            "Batch 60900, Loss: 8.936959056882188e-05\n",
            "Batch 61000, Loss: 5.6443641369696707e-05\n",
            "Batch 61100, Loss: 7.206646114354953e-05\n",
            "Batch 61200, Loss: 0.00012083986075595021\n",
            "Batch 61300, Loss: 0.00020057162328157574\n",
            "Batch 61400, Loss: 0.0002017617371166125\n",
            "Batch 61500, Loss: 6.300706445472315e-05\n",
            "Batch 61600, Loss: 6.2408740632236e-05\n",
            "Batch 61700, Loss: 8.614116086391732e-05\n",
            "Batch 61800, Loss: 0.00015733600594103336\n",
            "Batch 61900, Loss: 0.00011701167386490852\n",
            "Batch 62000, Loss: 8.588223136030138e-05\n",
            "Batch 62100, Loss: 0.00015328226436395198\n",
            "Batch 62200, Loss: 0.0001522194652352482\n",
            "Batch 62300, Loss: 0.0001083279712474905\n",
            "Batch 62400, Loss: 0.00010629896860336885\n",
            "Batch 62500, Loss: 9.316395880887285e-05\n",
            "Batch 62600, Loss: 0.00010759159340523183\n",
            "Batch 62700, Loss: 9.94889996945858e-05\n",
            "Batch 62800, Loss: 7.672062929486856e-05\n",
            "Batch 62900, Loss: 7.027633546385914e-05\n",
            "Batch 63000, Loss: 4.820510730496608e-05\n",
            "Batch 63100, Loss: 7.395774446194991e-05\n",
            "Batch 63200, Loss: 8.696359145687893e-05\n",
            "Batch 63300, Loss: 7.027447281870991e-05\n",
            "Batch 63400, Loss: 7.206478767329827e-05\n",
            "Batch 63500, Loss: 6.250449223443866e-05\n",
            "Batch 63600, Loss: 3.9246882806764916e-05\n",
            "Batch 63700, Loss: 7.061927317408845e-05\n",
            "Batch 63800, Loss: 0.00022726382303517312\n",
            "Batch 63900, Loss: 9.80585245997645e-05\n",
            "Batch 64000, Loss: 9.614596638130024e-05\n",
            "Batch 64100, Loss: 7.838353485567495e-05\n",
            "Batch 64200, Loss: 0.00010293617378920317\n",
            "Batch 64300, Loss: 0.00011868937144754454\n",
            "Batch 64400, Loss: 9.887873602565378e-05\n",
            "Batch 64500, Loss: 4.007113602710888e-05\n",
            "Batch 64600, Loss: 0.00010879462206503376\n",
            "Batch 64700, Loss: 4.3071049731224775e-05\n",
            "Batch 64800, Loss: 4.9149140977533534e-05\n",
            "Batch 64900, Loss: 3.124896466033533e-05\n",
            "Batch 65000, Loss: 3.147621464449912e-05\n",
            "Batch 65100, Loss: 3.220266808057204e-05\n",
            "Batch 65200, Loss: 9.780779510037974e-05\n",
            "Batch 65300, Loss: 0.00013369896623771638\n",
            "Batch 65400, Loss: 9.768987365532666e-05\n",
            "Batch 65500, Loss: 0.0001026949321385473\n",
            "Batch 65600, Loss: 4.163228368270211e-05\n",
            "Batch 65700, Loss: 7.133103645173833e-05\n",
            "Batch 65800, Loss: 6.370746268657967e-05\n",
            "Batch 65900, Loss: 6.883119203848764e-05\n",
            "Batch 66000, Loss: 4.1870524000842124e-05\n",
            "Batch 66100, Loss: 3.543204365996644e-05\n",
            "Batch 66200, Loss: 3.4350556234130636e-05\n",
            "Batch 66300, Loss: 4.4256117689656094e-05\n",
            "Batch 66400, Loss: 5.5707299907226115e-05\n",
            "Batch 66500, Loss: 0.00021627085516229272\n",
            "Batch 66600, Loss: 8.849184087011963e-05\n",
            "Batch 66700, Loss: 0.00013346255582291633\n",
            "Batch 66800, Loss: 0.00012500300363171846\n",
            "Batch 66900, Loss: 0.00011964316217927262\n",
            "Batch 67000, Loss: 0.00013658775424119085\n",
            "Batch 67100, Loss: 9.470786608289927e-05\n",
            "Batch 67200, Loss: 9.864792809821665e-05\n",
            "Batch 67300, Loss: 3.9755403122399e-05\n",
            "Batch 67400, Loss: 6.502126780105755e-05\n",
            "Batch 67500, Loss: 7.230694609461352e-05\n",
            "Batch 67600, Loss: 0.000124539335956797\n",
            "Batch 67700, Loss: 8.279482426587492e-05\n",
            "Batch 67800, Loss: 0.00010365746129537001\n",
            "Batch 67900, Loss: 0.00011011388414772227\n",
            "Batch 68000, Loss: 0.02851329930126667\n",
            "Batch 68100, Loss: 0.0001195345539599657\n",
            "Batch 68200, Loss: 7.801414176356047e-05\n",
            "Batch 68300, Loss: 4.188859384157695e-05\n",
            "Batch 68400, Loss: 4.450981941772625e-05\n",
            "Batch 68500, Loss: 4.617454032995738e-05\n",
            "Batch 68600, Loss: 8.911923214327544e-05\n",
            "Batch 68700, Loss: 7.899062620708719e-05\n",
            "Batch 68800, Loss: 9.113312262343243e-05\n",
            "Batch 68900, Loss: 0.00020045145356561989\n",
            "Batch 69000, Loss: 7.920670759631321e-05\n",
            "Batch 69100, Loss: 0.0001109409931814298\n",
            "Batch 69200, Loss: 5.477275772136636e-05\n",
            "Batch 69300, Loss: 6.168022082420066e-05\n",
            "Batch 69400, Loss: 8.063770656008273e-05\n",
            "Batch 69500, Loss: 0.00013990912702865899\n",
            "Batch 69600, Loss: 6.978679448366165e-05\n",
            "Batch 69700, Loss: 6.621493230341002e-05\n",
            "Batch 69800, Loss: 6.930695235496387e-05\n",
            "Batch 69900, Loss: 0.00012513526598922908\n",
            "Batch 70000, Loss: 0.00011403594544390216\n",
            "Batch 70100, Loss: 7.371744868578389e-05\n",
            "Batch 70200, Loss: 4.950269067194313e-05\n",
            "Batch 70300, Loss: 0.0001298752031289041\n",
            "Batch 70400, Loss: 6.228077108971775e-05\n",
            "Batch 70500, Loss: 0.00011964837176492438\n",
            "Batch 70600, Loss: 8.671416435390711e-05\n",
            "Batch 70700, Loss: 8.374243043363094e-05\n",
            "Batch 70800, Loss: 0.00018587011436466128\n",
            "Batch 70900, Loss: 0.00014087224553804845\n",
            "Batch 71000, Loss: 0.00013192810001783073\n",
            "Batch 71100, Loss: 0.0001094993349397555\n",
            "Batch 71200, Loss: 5.270716064842418e-05\n",
            "Batch 71300, Loss: 5.63022585993167e-05\n",
            "Batch 71400, Loss: 6.906366616021842e-05\n",
            "Batch 71500, Loss: 0.00010186150029767305\n",
            "Batch 71600, Loss: 5.726511517423205e-05\n",
            "Batch 71700, Loss: 7.943731907289475e-05\n",
            "Batch 71800, Loss: 7.944402750581503e-05\n",
            "Batch 71900, Loss: 0.0001626738958293572\n",
            "Batch 72000, Loss: 0.0001708016061456874\n",
            "Batch 72100, Loss: 4.817828448722139e-05\n",
            "Batch 72200, Loss: 3.637737245298922e-05\n",
            "Batch 72300, Loss: 9.88811589195393e-05\n",
            "Batch 72400, Loss: 8.623318717582151e-05\n",
            "Batch 72500, Loss: 7.77786917751655e-05\n",
            "Batch 72600, Loss: 0.00016827952640596777\n",
            "Batch 72700, Loss: 9.232085722032934e-05\n",
            "Batch 72800, Loss: 0.00011534608347574249\n",
            "Batch 72900, Loss: 5.785169923910871e-05\n",
            "Batch 73000, Loss: 4.3298678065184504e-05\n",
            "Batch 73100, Loss: 5.653343032463454e-05\n",
            "Batch 73200, Loss: 5.987781332805753e-05\n",
            "Batch 73300, Loss: 8.456430077785626e-05\n",
            "Batch 73400, Loss: 9.828970360103995e-05\n",
            "Batch 73500, Loss: 6.227034464245662e-05\n",
            "Batch 73600, Loss: 3.2217008993029594e-05\n",
            "Batch 73700, Loss: 0.00011725645163096488\n",
            "Batch 73800, Loss: 0.00014871940948069096\n",
            "Batch 73900, Loss: 0.00023644506291020662\n",
            "Batch 74000, Loss: 8.373385935556144e-05\n",
            "Batch 74100, Loss: 5.915692963753827e-05\n",
            "Batch 74200, Loss: 0.00010318113345419988\n",
            "Batch 74300, Loss: 0.00010244047007290646\n",
            "Batch 74400, Loss: 0.0001175969882751815\n",
            "Batch 74500, Loss: 0.00014372027362696826\n",
            "Batch 74600, Loss: 8.873735350789502e-05\n",
            "Batch 74700, Loss: 8.493108907714486e-05\n",
            "Batch 74800, Loss: 0.00011842391540994868\n",
            "Batch 74900, Loss: 8.03918155725114e-05\n",
            "Batch 75000, Loss: 0.00014228284999262542\n",
            "Batch 75100, Loss: 0.00019029472605325282\n",
            "Batch 75200, Loss: 0.030133981257677078\n",
            "Batch 75300, Loss: 0.00015754318155813962\n",
            "Batch 75400, Loss: 8.706641528988257e-05\n",
            "Batch 75500, Loss: 0.029026061296463013\n",
            "Batch 75600, Loss: 9.947148646460846e-05\n",
            "Batch 75700, Loss: 0.0001532498572487384\n",
            "Batch 75800, Loss: 0.00011532615462783724\n",
            "Batch 75900, Loss: 9.851418144535273e-05\n",
            "Batch 76000, Loss: 7.418481982313097e-05\n",
            "Batch 76100, Loss: 8.864291157806292e-05\n",
            "Batch 76200, Loss: 7.468087278539315e-05\n",
            "Batch 76300, Loss: 6.789440521970391e-05\n",
            "Batch 76400, Loss: 6.322817353066057e-05\n",
            "Batch 76500, Loss: 9.409648919245228e-05\n",
            "Batch 76600, Loss: 0.0001012614811770618\n",
            "Batch 76700, Loss: 0.0002688679378479719\n",
            "Batch 76800, Loss: 0.027882246300578117\n",
            "Batch 76900, Loss: 0.00010316064435755834\n",
            "Batch 77000, Loss: 8.719047764316201e-05\n",
            "Batch 77100, Loss: 0.0001636336965020746\n",
            "Batch 77200, Loss: 0.00016110902652144432\n",
            "Batch 77300, Loss: 0.0002563374291639775\n",
            "Batch 77400, Loss: 0.00012034005339955911\n",
            "Batch 77500, Loss: 4.7096036723814905e-05\n",
            "Batch 77600, Loss: 5.772316944785416e-05\n",
            "Batch 77700, Loss: 4.305037509766407e-05\n",
            "Batch 77800, Loss: 4.84155971207656e-05\n",
            "Batch 77900, Loss: 3.564793223631568e-05\n",
            "Batch 78000, Loss: 0.00010827861115103588\n",
            "Batch 78100, Loss: 0.00013452534039970487\n",
            "Batch 78200, Loss: 0.00010924413072643802\n",
            "Batch 78300, Loss: 0.00026385291130281985\n",
            "Batch 78400, Loss: 9.421868890058249e-05\n",
            "Batch 78500, Loss: 0.00010948685667244717\n",
            "Batch 78600, Loss: 0.02783665433526039\n",
            "Batch 78700, Loss: 0.00010174209455726668\n",
            "Batch 78800, Loss: 5.367653284338303e-05\n",
            "Batch 78900, Loss: 0.0001259385608136654\n",
            "Batch 79000, Loss: 7.94280058471486e-05\n",
            "Batch 79100, Loss: 0.00016874675930012017\n",
            "Batch 79200, Loss: 9.421943832421675e-05\n",
            "Batch 79300, Loss: 4.875964441453107e-05\n",
            "Batch 79400, Loss: 9.291360038332641e-05\n",
            "Batch 79500, Loss: 5.783716915175319e-05\n",
            "Batch 79600, Loss: 4.2098523408640176e-05\n",
            "Batch 79700, Loss: 3.517238292261027e-05\n",
            "Batch 79800, Loss: 0.00011555286619113758\n",
            "Batch 79900, Loss: 0.00011686413927236572\n",
            "Batch 80000, Loss: 0.00011140614515170455\n",
            "Batch 80100, Loss: 6.129798566689715e-05\n",
            "Batch 80200, Loss: 0.00015502225141972303\n",
            "Batch 80300, Loss: 0.00010065978858619928\n",
            "Batch 80400, Loss: 7.406410441035405e-05\n",
            "Batch 80500, Loss: 8.180810254998505e-05\n",
            "Batch 80600, Loss: 0.00010375079000368714\n",
            "Batch 80700, Loss: 6.631365977227688e-05\n",
            "Batch 80800, Loss: 3.3849672036012635e-05\n",
            "Batch 80900, Loss: 3.3728410926414654e-05\n",
            "Batch 81000, Loss: 6.605865200981498e-05\n",
            "Batch 81100, Loss: 6.189574196469039e-05\n",
            "Batch 81200, Loss: 0.00011769813863793388\n",
            "Batch 81300, Loss: 9.063389006769285e-05\n",
            "Batch 81400, Loss: 0.00011710761464200914\n",
            "Batch 81500, Loss: 0.00011270194954704493\n",
            "Batch 81600, Loss: 0.00011186012852704152\n",
            "Batch 81700, Loss: 9.373696957482025e-05\n",
            "Batch 81800, Loss: 9.897690324578434e-05\n",
            "Batch 81900, Loss: 0.0001413098507327959\n",
            "Batch 82000, Loss: 9.65978906606324e-05\n",
            "Batch 82100, Loss: 0.00010673785436665639\n",
            "Batch 82200, Loss: 0.00012592459097504616\n",
            "Batch 82300, Loss: 0.00013344337639864534\n",
            "Batch 82400, Loss: 0.00013499816122930497\n",
            "Batch 82500, Loss: 7.704735617153347e-05\n",
            "Batch 82600, Loss: 0.0001271261426154524\n",
            "Batch 82700, Loss: 4.674342198995873e-05\n",
            "Batch 82800, Loss: 5.629573934129439e-05\n",
            "Batch 82900, Loss: 0.00015705471741966903\n",
            "Batch 83000, Loss: 9.122905612457544e-05\n",
            "Batch 83100, Loss: 4.1028204577742144e-05\n",
            "Batch 83200, Loss: 0.00010637515515554696\n",
            "Batch 83300, Loss: 9.707309800432995e-05\n",
            "Batch 83400, Loss: 8.263723429990932e-05\n",
            "Batch 83500, Loss: 5.771460200776346e-05\n",
            "Batch 83600, Loss: 4.602794797392562e-05\n",
            "Batch 83700, Loss: 0.00012056639388902113\n",
            "Batch 83800, Loss: 0.00012509970110841095\n",
            "Batch 83900, Loss: 0.00012199000047985464\n",
            "Batch 84000, Loss: 9.885787585517392e-05\n",
            "Batch 84100, Loss: 4.279127097106539e-05\n",
            "Batch 84200, Loss: 9.301903628511354e-05\n",
            "Batch 84300, Loss: 0.00011043449194403365\n",
            "Batch 84400, Loss: 5.85552588745486e-05\n",
            "Batch 84500, Loss: 9.36270589591004e-05\n",
            "Batch 84600, Loss: 0.00013320586003828794\n",
            "Batch 84700, Loss: 7.846587686799467e-05\n",
            "Batch 84800, Loss: 4.6627559640910476e-05\n",
            "Batch 84900, Loss: 0.00016146131383720785\n",
            "Batch 85000, Loss: 8.717911259736866e-05\n",
            "Batch 85100, Loss: 6.344202120089903e-05\n",
            "Batch 85200, Loss: 0.00011603404709603637\n",
            "Batch 85300, Loss: 0.00014977903629187495\n",
            "Batch 85400, Loss: 0.00012343149865046144\n",
            "Batch 85500, Loss: 0.0001968230790225789\n",
            "Batch 85600, Loss: 0.00012414087541401386\n",
            "Batch 85700, Loss: 7.381412433460355e-05\n",
            "Batch 85800, Loss: 0.00016277898976113647\n",
            "Batch 85900, Loss: 6.087085057515651e-05\n",
            "Batch 86000, Loss: 0.00015097502910066396\n",
            "Batch 86100, Loss: 6.953700358280912e-05\n",
            "Batch 86200, Loss: 0.00012021729344269261\n",
            "Batch 86300, Loss: 5.690728357876651e-05\n",
            "Batch 86400, Loss: 7.907277176855132e-05\n",
            "Batch 86500, Loss: 5.510339542524889e-05\n",
            "Batch 86600, Loss: 7.000510959187523e-05\n",
            "Batch 86700, Loss: 0.00014596414985135198\n",
            "Batch 86800, Loss: 0.0001377354928990826\n",
            "Batch 86900, Loss: 0.00012068115029251203\n",
            "Batch 87000, Loss: 8.215681737056002e-05\n",
            "Batch 87100, Loss: 0.00018442032160237432\n",
            "Batch 87200, Loss: 8.097468526102602e-05\n",
            "Batch 87300, Loss: 7.536377961514518e-05\n",
            "Batch 87400, Loss: 6.237260822672397e-05\n",
            "Batch 87500, Loss: 4.723369420389645e-05\n",
            "Batch 87600, Loss: 5.556964242714457e-05\n",
            "Batch 87700, Loss: 9.003182640299201e-05\n",
            "Batch 87800, Loss: 0.0001236585812876001\n",
            "Batch 87900, Loss: 6.678047066088766e-05\n",
            "Batch 88000, Loss: 0.0001248573389602825\n",
            "Batch 88100, Loss: 6.510342063847929e-05\n",
            "Batch 88200, Loss: 0.00016243098070845008\n",
            "Batch 88300, Loss: 8.741048077354208e-05\n",
            "Batch 88400, Loss: 8.384246029891074e-05\n",
            "Batch 88500, Loss: 0.00013165667769499123\n",
            "Batch 88600, Loss: 7.643469143658876e-05\n",
            "Batch 88700, Loss: 5.448850424727425e-05\n",
            "Batch 88800, Loss: 0.0001163881752290763\n",
            "Batch 88900, Loss: 6.879952707095072e-05\n",
            "Batch 89000, Loss: 0.00013522226072382182\n",
            "Batch 89100, Loss: 0.0001024402808980085\n",
            "Batch 89200, Loss: 0.03045291267335415\n",
            "Batch 89300, Loss: 8.347735274583101e-05\n",
            "Batch 89400, Loss: 0.0001466718822484836\n",
            "Batch 89500, Loss: 0.00011435728811193258\n",
            "Batch 89600, Loss: 6.987639790168032e-05\n",
            "Batch 89700, Loss: 0.00028492987621575594\n",
            "Batch 89800, Loss: 8.036741201067343e-05\n",
            "Batch 89900, Loss: 5.448347656056285e-05\n",
            "Batch 90000, Loss: 0.00013272523938212544\n",
            "Batch 90100, Loss: 8.20508212200366e-05\n",
            "Batch 90200, Loss: 0.00011197115236427635\n",
            "Batch 90300, Loss: 0.00014250303502194583\n",
            "Batch 90400, Loss: 7.213650678750128e-05\n",
            "Epoch 3: Average Loss: 0.0018238929285908677\n",
            "Batch 0, Loss: 5.80653540964704e-05\n",
            "Batch 100, Loss: 7.967482088133693e-05\n",
            "Batch 200, Loss: 0.00014416738122235984\n",
            "Batch 300, Loss: 0.0001840564946178347\n",
            "Batch 400, Loss: 0.00011781606008298695\n",
            "Batch 500, Loss: 6.283829861786216e-05\n",
            "Batch 600, Loss: 4.8519723350182176e-05\n",
            "Batch 700, Loss: 6.868626951472834e-05\n",
            "Batch 800, Loss: 0.00010100441431859508\n",
            "Batch 900, Loss: 9.037570271175355e-05\n",
            "Batch 1000, Loss: 9.849741763900965e-05\n",
            "Batch 1100, Loss: 0.0001806002837838605\n",
            "Batch 1200, Loss: 0.00016026511730160564\n",
            "Batch 1300, Loss: 6.093139381846413e-05\n",
            "Batch 1400, Loss: 0.00010649102478055283\n",
            "Batch 1500, Loss: 7.262157305376604e-05\n",
            "Batch 1600, Loss: 8.180306758731604e-05\n",
            "Batch 1700, Loss: 0.02996291033923626\n",
            "Batch 1800, Loss: 0.00014130053750704974\n",
            "Batch 1900, Loss: 0.00011221128079341725\n",
            "Batch 2000, Loss: 0.00010589081648504362\n",
            "Batch 2100, Loss: 8.97883583093062e-05\n",
            "Batch 2200, Loss: 6.450547516578808e-05\n",
            "Batch 2300, Loss: 3.4085493098245934e-05\n",
            "Batch 2400, Loss: 4.3392745283199474e-05\n",
            "Batch 2500, Loss: 5.68765499338042e-05\n",
            "Batch 2600, Loss: 7.46367295505479e-05\n",
            "Batch 2700, Loss: 0.00020932935876771808\n",
            "Batch 2800, Loss: 0.00014845861005596817\n",
            "Batch 2900, Loss: 9.875243267742917e-05\n",
            "Batch 3000, Loss: 7.596433715661988e-05\n",
            "Batch 3100, Loss: 0.0001268806227017194\n",
            "Batch 3200, Loss: 0.00012354437785688788\n",
            "Batch 3300, Loss: 6.487187783932313e-05\n",
            "Batch 3400, Loss: 4.841913323616609e-05\n",
            "Batch 3500, Loss: 3.970604302594438e-05\n",
            "Batch 3600, Loss: 4.8178841097978875e-05\n",
            "Batch 3700, Loss: 0.00015418448310811073\n",
            "Batch 3800, Loss: 0.0001355927815893665\n",
            "Batch 3900, Loss: 0.027359390631318092\n",
            "Batch 4000, Loss: 0.00010601488611428067\n",
            "Batch 4100, Loss: 6.320489046629518e-05\n",
            "Batch 4200, Loss: 4.650312985177152e-05\n",
            "Batch 4300, Loss: 6.927808135515079e-05\n",
            "Batch 4400, Loss: 6.809111073380336e-05\n",
            "Batch 4500, Loss: 0.00010576992644928396\n",
            "Batch 4600, Loss: 0.00011912715126527473\n",
            "Batch 4700, Loss: 6.761070835636929e-05\n",
            "Batch 4800, Loss: 6.558196037076414e-05\n",
            "Batch 4900, Loss: 0.00016277247050311416\n",
            "Batch 5000, Loss: 0.0001299787691095844\n",
            "Batch 5100, Loss: 9.598930046195164e-05\n",
            "Batch 5200, Loss: 6.796984962420538e-05\n",
            "Batch 5300, Loss: 0.00010481801291462034\n",
            "Batch 5400, Loss: 0.00012962016626261175\n",
            "Batch 5500, Loss: 0.00013641879195347428\n",
            "Batch 5600, Loss: 0.00010386125359218568\n",
            "Batch 5700, Loss: 8.836479537421837e-05\n",
            "Batch 5800, Loss: 9.896796109387651e-05\n",
            "Batch 5900, Loss: 5.460474130813964e-05\n",
            "Batch 6000, Loss: 6.308548472588882e-05\n",
            "Batch 6100, Loss: 4.4111198803875595e-05\n",
            "Batch 6200, Loss: 0.027000660076737404\n",
            "Batch 6300, Loss: 0.00021637538156937808\n",
            "Batch 6400, Loss: 0.0001621740811970085\n",
            "Batch 6500, Loss: 0.00010244159057037905\n",
            "Batch 6600, Loss: 0.00010505738464416936\n",
            "Batch 6700, Loss: 8.096835517790169e-05\n",
            "Batch 6800, Loss: 7.321822340600193e-05\n",
            "Batch 6900, Loss: 8.132246875902638e-05\n",
            "Batch 7000, Loss: 4.029243063996546e-05\n",
            "Batch 7100, Loss: 0.00012496333511080593\n",
            "Batch 7200, Loss: 0.00010290897625964135\n",
            "Batch 7300, Loss: 0.00012103789049433544\n",
            "Batch 7400, Loss: 4.970833833795041e-05\n",
            "Batch 7500, Loss: 5.150308788870461e-05\n",
            "Batch 7600, Loss: 6.020789805916138e-05\n",
            "Batch 7700, Loss: 6.330659380182624e-05\n",
            "Batch 7800, Loss: 0.0001232966169482097\n",
            "Batch 7900, Loss: 0.00024510957882739604\n",
            "Batch 8000, Loss: 7.798154547344893e-05\n",
            "Batch 8100, Loss: 8.668361260788515e-05\n",
            "Batch 8200, Loss: 6.832434155512601e-05\n",
            "Batch 8300, Loss: 0.000138204573886469\n",
            "Batch 8400, Loss: 0.0001457193575333804\n",
            "Batch 8500, Loss: 7.297569391084835e-05\n",
            "Batch 8600, Loss: 3.672607272164896e-05\n",
            "Batch 8700, Loss: 6.415136158466339e-05\n",
            "Batch 8800, Loss: 0.00010624327114783227\n",
            "Batch 8900, Loss: 0.0001493054733145982\n",
            "Batch 9000, Loss: 7.845190702937543e-05\n",
            "Batch 9100, Loss: 3.6333975003799424e-05\n",
            "Batch 9200, Loss: 7.164734415709972e-05\n",
            "Batch 9300, Loss: 0.00018368240853305906\n",
            "Batch 9400, Loss: 0.00010253342770738527\n",
            "Batch 9500, Loss: 9.919820877257735e-05\n",
            "Batch 9600, Loss: 9.489657531958073e-05\n",
            "Batch 9700, Loss: 5.0417853344697505e-05\n",
            "Batch 9800, Loss: 7.498265040339902e-05\n",
            "Batch 9900, Loss: 0.00017063376435544342\n",
            "Batch 10000, Loss: 0.0001071895967470482\n",
            "Batch 10100, Loss: 0.00011017014912795275\n",
            "Batch 10200, Loss: 6.126985681476071e-05\n",
            "Batch 10300, Loss: 7.415111031150445e-05\n",
            "Batch 10400, Loss: 6.389299960574135e-05\n",
            "Batch 10500, Loss: 8.977457036962733e-05\n",
            "Batch 10600, Loss: 9.716847125673667e-05\n",
            "Batch 10700, Loss: 7.295911200344563e-05\n",
            "Batch 10800, Loss: 7.904483209131286e-05\n",
            "Batch 10900, Loss: 9.598334145266563e-05\n",
            "Batch 11000, Loss: 0.00010373514669481665\n",
            "Batch 11100, Loss: 9.502156899543479e-05\n",
            "Batch 11200, Loss: 0.00012328283628448844\n",
            "Batch 11300, Loss: 6.473254325101152e-05\n",
            "Batch 11400, Loss: 8.203387551475316e-05\n",
            "Batch 11500, Loss: 8.501808042638004e-05\n",
            "Batch 11600, Loss: 6.675979238934815e-05\n",
            "Batch 11700, Loss: 8.420421363553032e-05\n",
            "Batch 11800, Loss: 0.00010576452041277662\n",
            "Batch 11900, Loss: 9.670016152085736e-05\n",
            "Batch 12000, Loss: 0.029704291373491287\n",
            "Batch 12100, Loss: 0.0001875186717370525\n",
            "Batch 12200, Loss: 0.000147505896165967\n",
            "Batch 12300, Loss: 0.00014238177391234785\n",
            "Batch 12400, Loss: 0.0001852510467870161\n",
            "Batch 12500, Loss: 0.0001209102847496979\n",
            "Batch 12600, Loss: 0.00012782937847077847\n",
            "Batch 12700, Loss: 6.831446808064356e-05\n",
            "Batch 12800, Loss: 4.529273064690642e-05\n",
            "Batch 12900, Loss: 5.030590182286687e-05\n",
            "Batch 13000, Loss: 0.00011983205331489444\n",
            "Batch 13100, Loss: 7.42826159694232e-05\n",
            "Batch 13200, Loss: 0.00014082642155699432\n",
            "Batch 13300, Loss: 0.00010289574856869876\n",
            "Batch 13400, Loss: 8.143591549014673e-05\n",
            "Batch 13500, Loss: 0.00012866692850366235\n",
            "Batch 13600, Loss: 0.00010363305773353204\n",
            "Batch 13700, Loss: 0.00021625091903842986\n",
            "Batch 13800, Loss: 9.276979835703969e-05\n",
            "Batch 13900, Loss: 5.746573879150674e-05\n",
            "Batch 14000, Loss: 0.00013235601363703609\n",
            "Batch 14100, Loss: 0.00018251505389343947\n",
            "Batch 14200, Loss: 0.00011638463183771819\n",
            "Batch 14300, Loss: 0.00017149350605905056\n",
            "Batch 14400, Loss: 0.00010541988740442321\n",
            "Batch 14500, Loss: 7.155084313126281e-05\n",
            "Batch 14600, Loss: 0.00011375968460924923\n",
            "Batch 14700, Loss: 0.0001113847247324884\n",
            "Batch 14800, Loss: 0.00010529042629059404\n",
            "Batch 14900, Loss: 0.00010208168532699347\n",
            "Batch 15000, Loss: 4.389772948343307e-05\n",
            "Batch 15100, Loss: 7.0982139732223e-05\n",
            "Batch 15200, Loss: 0.00010460098565090448\n",
            "Batch 15300, Loss: 0.00016995228361338377\n",
            "Batch 15400, Loss: 0.00012128881644457579\n",
            "Batch 15500, Loss: 8.587328920839354e-05\n",
            "Batch 15600, Loss: 5.42690722795669e-05\n",
            "Batch 15700, Loss: 3.075851418543607e-05\n",
            "Batch 15800, Loss: 1.9531700672814623e-05\n",
            "Batch 15900, Loss: 0.03394061699509621\n",
            "Batch 16000, Loss: 4.8280176997650415e-05\n",
            "Batch 16100, Loss: 0.00012875784887000918\n",
            "Batch 16200, Loss: 7.320611621253192e-05\n",
            "Batch 16300, Loss: 5.698980385204777e-05\n",
            "Batch 16400, Loss: 7.619681855430827e-05\n",
            "Batch 16500, Loss: 0.00011268332309555262\n",
            "Batch 16600, Loss: 0.00012794022040907294\n",
            "Batch 16700, Loss: 0.0002010955213336274\n",
            "Batch 16800, Loss: 0.00010350321826990694\n",
            "Batch 16900, Loss: 0.00014023346011526883\n",
            "Batch 17000, Loss: 0.0001742697204463184\n",
            "Batch 17100, Loss: 7.869779074098915e-05\n",
            "Batch 17200, Loss: 0.00013808759103994817\n",
            "Batch 17300, Loss: 9.932190005201846e-05\n",
            "Batch 17400, Loss: 0.00012937111023347825\n",
            "Batch 17500, Loss: 9.109493839787319e-05\n",
            "Batch 17600, Loss: 7.7019416494295e-05\n",
            "Batch 17700, Loss: 8.31036813906394e-05\n",
            "Batch 17800, Loss: 0.00012639627675525844\n",
            "Batch 17900, Loss: 7.105982513166964e-05\n",
            "Batch 18000, Loss: 8.298725879285485e-05\n",
            "Batch 18100, Loss: 0.00010755918629001826\n",
            "Batch 18200, Loss: 0.0002613157266750932\n",
            "Batch 18300, Loss: 0.00018083315808326006\n",
            "Batch 18400, Loss: 6.830385245848447e-05\n",
            "Batch 18500, Loss: 5.983385563013144e-05\n",
            "Batch 18600, Loss: 0.00014784738596063107\n",
            "Batch 18700, Loss: 0.000117437906737905\n",
            "Batch 18800, Loss: 0.0001714640820864588\n",
            "Batch 18900, Loss: 6.4007930632215e-05\n",
            "Batch 19000, Loss: 0.00012757658259943128\n",
            "Batch 19100, Loss: 6.937010039109737e-05\n",
            "Batch 19200, Loss: 4.63593278254848e-05\n",
            "Batch 19300, Loss: 5.542192957364023e-05\n",
            "Batch 19400, Loss: 5.256075019133277e-05\n",
            "Batch 19500, Loss: 6.651111471001059e-05\n",
            "Batch 19600, Loss: 6.877903797430918e-05\n",
            "Batch 19700, Loss: 7.116488268366084e-05\n",
            "Batch 19800, Loss: 9.04865373740904e-05\n",
            "Batch 19900, Loss: 0.00014331378042697906\n",
            "Batch 20000, Loss: 0.00011768007243517786\n",
            "Batch 20100, Loss: 7.903868390712887e-05\n",
            "Batch 20200, Loss: 0.00012936309212818742\n",
            "Batch 20300, Loss: 0.00013306726759765297\n",
            "Batch 20400, Loss: 5.721985507989302e-05\n",
            "Batch 20500, Loss: 5.960380440228619e-05\n",
            "Batch 20600, Loss: 6.0436832427512854e-05\n",
            "Batch 20700, Loss: 7.831610855646431e-05\n",
            "Batch 20800, Loss: 0.00010980931983795017\n",
            "Batch 20900, Loss: 5.422306639957242e-05\n",
            "Batch 21000, Loss: 0.00010253417713101953\n",
            "Batch 21100, Loss: 0.00011755470768548548\n",
            "Batch 21200, Loss: 0.0001447573595214635\n",
            "Batch 21300, Loss: 6.0556791140697896e-05\n",
            "Batch 21400, Loss: 5.1153634558431804e-05\n",
            "Batch 21500, Loss: 9.098000009544194e-05\n",
            "Batch 21600, Loss: 5.3057730838190764e-05\n",
            "Batch 21700, Loss: 0.00017296394798904657\n",
            "Batch 21800, Loss: 0.0001977618521777913\n",
            "Batch 21900, Loss: 9.886066982289776e-05\n",
            "Batch 22000, Loss: 5.937785317655653e-05\n",
            "Batch 22100, Loss: 6.402451253961772e-05\n",
            "Batch 22200, Loss: 0.0001375995052512735\n",
            "Batch 22300, Loss: 0.00011601411824813113\n",
            "Batch 22400, Loss: 9.156586020253599e-05\n",
            "Batch 22500, Loss: 5.626761412713677e-05\n",
            "Batch 22600, Loss: 6.426201434805989e-05\n",
            "Batch 22700, Loss: 0.0001463037624489516\n",
            "Batch 22800, Loss: 0.0002118377451552078\n",
            "Batch 22900, Loss: 0.00013473659055307508\n",
            "Batch 23000, Loss: 8.036294457269832e-05\n",
            "Batch 23100, Loss: 8.094823715509847e-05\n",
            "Batch 23200, Loss: 7.617912342539057e-05\n",
            "Batch 23300, Loss: 8.917623927118257e-05\n",
            "Batch 23400, Loss: 0.00011340405762894079\n",
            "Batch 23500, Loss: 6.270753510762006e-05\n",
            "Batch 23600, Loss: 4.850724508287385e-05\n",
            "Batch 23700, Loss: 5.423051698016934e-05\n",
            "Batch 23800, Loss: 4.373604679130949e-05\n",
            "Batch 23900, Loss: 6.103310079197399e-05\n",
            "Batch 24000, Loss: 0.00011517843086039647\n",
            "Batch 24100, Loss: 0.00012842363503295928\n",
            "Batch 24200, Loss: 0.00013080106873530895\n",
            "Batch 24300, Loss: 7.284529419848695e-05\n",
            "Batch 24400, Loss: 4.8862097173696384e-05\n",
            "Batch 24500, Loss: 0.00018643142539076507\n",
            "Batch 24600, Loss: 0.00016812919056974351\n",
            "Batch 24700, Loss: 9.014322859002277e-05\n",
            "Batch 24800, Loss: 7.296600233530626e-05\n",
            "Batch 24900, Loss: 0.0001229318731930107\n",
            "Batch 25000, Loss: 5.972823782940395e-05\n",
            "Batch 25100, Loss: 6.509932427434251e-05\n",
            "Batch 25200, Loss: 6.545212818309665e-05\n",
            "Batch 25300, Loss: 3.3606032957322896e-05\n",
            "Batch 25400, Loss: 5.852303729625419e-05\n",
            "Batch 25500, Loss: 0.00021157953597139567\n",
            "Batch 25600, Loss: 0.00013378169387578964\n",
            "Batch 25700, Loss: 7.081672811182216e-05\n",
            "Batch 25800, Loss: 4.7323475882876664e-05\n",
            "Batch 25900, Loss: 5.126353426021524e-05\n",
            "Batch 26000, Loss: 0.00014367557014338672\n",
            "Batch 26100, Loss: 0.02974746748805046\n",
            "Batch 26200, Loss: 8.526135934516788e-05\n",
            "Batch 26300, Loss: 7.416321750497445e-05\n",
            "Batch 26400, Loss: 7.97629400040023e-05\n",
            "Batch 26500, Loss: 7.976237975526601e-05\n",
            "Batch 26600, Loss: 0.0001260365534108132\n",
            "Batch 26700, Loss: 0.0001012331631500274\n",
            "Batch 26800, Loss: 0.00012663193047046661\n",
            "Batch 26900, Loss: 0.02858724445104599\n",
            "Batch 27000, Loss: 0.00014511708286590874\n",
            "Batch 27100, Loss: 0.00018679435015656054\n",
            "Batch 27200, Loss: 0.00016528222477063537\n",
            "Batch 27300, Loss: 0.028331611305475235\n",
            "Batch 27400, Loss: 0.000137245180667378\n",
            "Batch 27500, Loss: 0.00010636584192980081\n",
            "Batch 27600, Loss: 9.347897139377892e-05\n",
            "Batch 27700, Loss: 0.00011364492820575833\n",
            "Batch 27800, Loss: 8.33557132864371e-05\n",
            "Batch 27900, Loss: 4.2568677599774674e-05\n",
            "Batch 28000, Loss: 5.198181315790862e-05\n",
            "Batch 28100, Loss: 0.00011613315291469917\n",
            "Batch 28200, Loss: 0.00010814784764079377\n",
            "Batch 28300, Loss: 0.00010350042430218309\n",
            "Batch 28400, Loss: 0.00013164363917894661\n",
            "Batch 28500, Loss: 8.525000157533213e-05\n",
            "Batch 28600, Loss: 0.00013533887977246195\n",
            "Batch 28700, Loss: 0.0001173438286059536\n",
            "Batch 28800, Loss: 8.274657739093527e-05\n",
            "Batch 28900, Loss: 0.030675044283270836\n",
            "Batch 29000, Loss: 8.87142596184276e-05\n",
            "Batch 29100, Loss: 7.976163760758936e-05\n",
            "Batch 29200, Loss: 0.00010504695092095062\n",
            "Batch 29300, Loss: 9.253060852643102e-05\n",
            "Batch 29400, Loss: 7.154339255066589e-05\n",
            "Batch 29500, Loss: 0.00011124911543447524\n",
            "Batch 29600, Loss: 6.18795384070836e-05\n",
            "Batch 29700, Loss: 7.71377090131864e-05\n",
            "Batch 29800, Loss: 7.797651778673753e-05\n",
            "Batch 29900, Loss: 9.34830677579157e-05\n",
            "Batch 30000, Loss: 0.00010206567094428465\n",
            "Batch 30100, Loss: 0.00018096169515047222\n",
            "Batch 30200, Loss: 8.621381130069494e-05\n",
            "Batch 30300, Loss: 7.153333717724308e-05\n",
            "Batch 30400, Loss: 0.00014213605027180165\n",
            "Batch 30500, Loss: 6.617414328502491e-05\n",
            "Batch 30600, Loss: 7.570653542643413e-05\n",
            "Batch 30700, Loss: 0.00010624811693560332\n",
            "Batch 30800, Loss: 0.02821752056479454\n",
            "Batch 30900, Loss: 9.349219180876389e-05\n",
            "Batch 31000, Loss: 0.00012449333735276014\n",
            "Batch 31100, Loss: 9.564040374243632e-05\n",
            "Batch 31200, Loss: 0.00011327590618748218\n",
            "Batch 31300, Loss: 3.7851154047530144e-05\n",
            "Batch 31400, Loss: 2.5075056328205392e-05\n",
            "Batch 31500, Loss: 4.30881955253426e-05\n",
            "Batch 31600, Loss: 0.00012083950423402712\n",
            "Batch 31700, Loss: 5.7284123613499105e-05\n",
            "Batch 31800, Loss: 9.901975863613188e-05\n",
            "Batch 31900, Loss: 0.00013193611812312156\n",
            "Batch 32000, Loss: 0.0001108314681914635\n",
            "Batch 32100, Loss: 9.22277249628678e-05\n",
            "Batch 32200, Loss: 9.198593033943325e-05\n",
            "Batch 32300, Loss: 4.965264452039264e-05\n",
            "Batch 32400, Loss: 4.238166002323851e-05\n",
            "Batch 32500, Loss: 0.00010057391773443669\n",
            "Batch 32600, Loss: 0.00013467810640577227\n",
            "Batch 32700, Loss: 7.827699300833046e-05\n",
            "Batch 32800, Loss: 0.000189116588444449\n",
            "Batch 32900, Loss: 0.00013360919547267258\n",
            "Batch 33000, Loss: 7.804358756402507e-05\n",
            "Batch 33100, Loss: 4.024195368401706e-05\n",
            "Batch 33200, Loss: 5.39579959877301e-05\n",
            "Batch 33300, Loss: 4.4298034481471404e-05\n",
            "Batch 33400, Loss: 9.163869253825396e-05\n",
            "Batch 33500, Loss: 0.00010701673454605043\n",
            "Batch 33600, Loss: 0.0001579401723574847\n",
            "Batch 33700, Loss: 5.872104884474538e-05\n",
            "Batch 33800, Loss: 0.0001120276065194048\n",
            "Batch 33900, Loss: 8.972483919933438e-05\n",
            "Batch 34000, Loss: 0.00010141256643692032\n",
            "Batch 34100, Loss: 0.00011094845831394196\n",
            "Batch 34200, Loss: 9.389549813931808e-05\n",
            "Batch 34300, Loss: 7.660999108338729e-05\n",
            "Batch 34400, Loss: 6.408654735423625e-05\n",
            "Batch 34500, Loss: 9.927142673404887e-05\n",
            "Batch 34600, Loss: 9.760270040715113e-05\n",
            "Batch 34700, Loss: 0.0001388659147778526\n",
            "Batch 34800, Loss: 0.0001623486605240032\n",
            "Batch 34900, Loss: 0.00027987195062451065\n",
            "Batch 35000, Loss: 9.210756979882717e-05\n",
            "Batch 35100, Loss: 8.197445276891813e-05\n",
            "Batch 35200, Loss: 9.878951823338866e-05\n",
            "Batch 35300, Loss: 6.242234667297453e-05\n",
            "Batch 35400, Loss: 9.950241656042635e-05\n",
            "Batch 35500, Loss: 0.0001386222429573536\n",
            "Batch 35600, Loss: 0.00010272995859850198\n",
            "Batch 35700, Loss: 8.305152732646093e-05\n",
            "Batch 35800, Loss: 7.493999873986468e-05\n",
            "Batch 35900, Loss: 0.00010713241499615833\n",
            "Batch 36000, Loss: 0.00010510973515920341\n",
            "Batch 36100, Loss: 6.790633051423356e-05\n",
            "Batch 36200, Loss: 7.27996593923308e-05\n",
            "Batch 36300, Loss: 0.0001637825625948608\n",
            "Batch 36400, Loss: 9.18775112950243e-05\n",
            "Batch 36500, Loss: 4.167010047240183e-05\n",
            "Batch 36600, Loss: 6.921996100572869e-05\n",
            "Batch 36700, Loss: 4.954646647092886e-05\n",
            "Batch 36800, Loss: 0.00015603234351146966\n",
            "Batch 36900, Loss: 0.00025960520724765956\n",
            "Batch 37000, Loss: 0.00014470930909737945\n",
            "Batch 37100, Loss: 0.00016771655646152794\n",
            "Batch 37200, Loss: 0.00015746419376228005\n",
            "Batch 37300, Loss: 0.0001457866164855659\n",
            "Batch 37400, Loss: 0.00023110122128855437\n",
            "Batch 37500, Loss: 0.0002216815628344193\n",
            "Batch 37600, Loss: 0.00010404102795291692\n",
            "Batch 37700, Loss: 6.564697832800448e-05\n",
            "Batch 37800, Loss: 0.00013529305579140782\n",
            "Batch 37900, Loss: 0.02864980511367321\n",
            "Batch 38000, Loss: 0.00015341381367761642\n",
            "Batch 38100, Loss: 0.0001647486787987873\n",
            "Batch 38200, Loss: 0.00016678283282089978\n",
            "Batch 38300, Loss: 0.030090222135186195\n",
            "Batch 38400, Loss: 8.022137626539916e-05\n",
            "Batch 38500, Loss: 6.627454422414303e-05\n",
            "Batch 38600, Loss: 3.5160464904038236e-05\n",
            "Batch 38700, Loss: 0.00010455143637955189\n",
            "Batch 38800, Loss: 8.929806062951684e-05\n",
            "Batch 38900, Loss: 6.210604624357074e-05\n",
            "Batch 39000, Loss: 8.750735287321731e-05\n",
            "Batch 39100, Loss: 7.438637112500146e-05\n",
            "Batch 39200, Loss: 6.067377398721874e-05\n",
            "Batch 39300, Loss: 5.602639066637494e-05\n",
            "Batch 39400, Loss: 5.100480484543368e-05\n",
            "Batch 39500, Loss: 5.780867286375724e-05\n",
            "Batch 39600, Loss: 8.141672878991812e-05\n",
            "Batch 39700, Loss: 6.174430018290877e-05\n",
            "Batch 39800, Loss: 6.006912371958606e-05\n",
            "Batch 39900, Loss: 5.8527693909127265e-05\n",
            "Batch 40000, Loss: 0.00012326664000283927\n",
            "Batch 40100, Loss: 8.666051871841773e-05\n",
            "Batch 40200, Loss: 7.689499034313485e-05\n",
            "Batch 40300, Loss: 4.994304254068993e-05\n",
            "Batch 40400, Loss: 6.961206963751465e-05\n",
            "Batch 40500, Loss: 0.00013949780259281397\n",
            "Batch 40600, Loss: 0.00014378268679138273\n",
            "Batch 40700, Loss: 0.0001323454052908346\n",
            "Batch 40800, Loss: 0.00017168372869491577\n",
            "Batch 40900, Loss: 0.0002855166094377637\n",
            "Batch 41000, Loss: 0.00010909342381637543\n",
            "Batch 41100, Loss: 0.00023471482563763857\n",
            "Batch 41200, Loss: 0.00013424070493783802\n",
            "Batch 41300, Loss: 0.0002422327670501545\n",
            "Batch 41400, Loss: 0.000134133588289842\n",
            "Batch 41500, Loss: 0.00013663285062648356\n",
            "Batch 41600, Loss: 0.0001806964137358591\n",
            "Batch 41700, Loss: 9.942417818820104e-05\n",
            "Batch 41800, Loss: 6.186165410326794e-05\n",
            "Batch 41900, Loss: 8.247423829743639e-05\n",
            "Batch 42000, Loss: 0.00011396776972105727\n",
            "Batch 42100, Loss: 6.722567923134193e-05\n",
            "Batch 42200, Loss: 4.765988705912605e-05\n",
            "Batch 42300, Loss: 4.7070330765563995e-05\n",
            "Batch 42400, Loss: 8.022360998438671e-05\n",
            "Batch 42500, Loss: 0.02902224101126194\n",
            "Batch 42600, Loss: 0.029141897335648537\n",
            "Batch 42700, Loss: 5.1118433475494385e-05\n",
            "Batch 42800, Loss: 4.1340026655234396e-05\n",
            "Batch 42900, Loss: 8.594724931754172e-05\n",
            "Batch 43000, Loss: 0.00013555012992583215\n",
            "Batch 43100, Loss: 0.00019190528837498277\n",
            "Batch 43200, Loss: 0.028416380286216736\n",
            "Batch 43300, Loss: 9.96598246274516e-05\n",
            "Batch 43400, Loss: 5.4453674238175154e-05\n",
            "Batch 43500, Loss: 4.2896888771792874e-05\n",
            "Batch 43600, Loss: 0.0001683538721408695\n",
            "Batch 43700, Loss: 7.784016634104773e-05\n",
            "Batch 43800, Loss: 6.460346048697829e-05\n",
            "Batch 43900, Loss: 4.158311276114546e-05\n",
            "Batch 44000, Loss: 5.267009692033753e-05\n",
            "Batch 44100, Loss: 7.378395093837753e-05\n",
            "Batch 44200, Loss: 5.6370066886302084e-05\n",
            "Batch 44300, Loss: 0.00011433176405262202\n",
            "Batch 44400, Loss: 0.00011134393571410328\n",
            "Batch 44500, Loss: 7.37871159799397e-05\n",
            "Batch 44600, Loss: 8.989081834442914e-05\n",
            "Batch 44700, Loss: 9.680038056103513e-05\n",
            "Batch 44800, Loss: 7.736664701951668e-05\n",
            "Batch 44900, Loss: 5.005089406040497e-05\n",
            "Batch 45000, Loss: 8.18937987787649e-05\n",
            "Batch 45100, Loss: 7.748362986603752e-05\n",
            "Batch 45200, Loss: 0.00011982348223682493\n",
            "Batch 45300, Loss: 6.317340739769861e-05\n",
            "Batch 45400, Loss: 9.691941522760317e-05\n",
            "Batch 45500, Loss: 0.00011445676500443369\n",
            "Batch 45600, Loss: 0.0001237571268575266\n",
            "Batch 45700, Loss: 0.00019273953512310982\n",
            "Batch 45800, Loss: 0.00011027447180822492\n",
            "Batch 45900, Loss: 9.692090679891407e-05\n",
            "Batch 46000, Loss: 7.808419468346983e-05\n",
            "Batch 46100, Loss: 0.00019715358212124556\n",
            "Batch 46200, Loss: 0.00016585769481025636\n",
            "Batch 46300, Loss: 8.965386223280802e-05\n",
            "Batch 46400, Loss: 4.981675010640174e-05\n",
            "Batch 46500, Loss: 6.996692536631599e-05\n",
            "Batch 46600, Loss: 0.0001321088057011366\n",
            "Batch 46700, Loss: 8.285779040306807e-05\n",
            "Batch 46800, Loss: 0.00010419805767014623\n",
            "Batch 46900, Loss: 6.806112651247531e-05\n",
            "Batch 47000, Loss: 4.862255082116462e-05\n",
            "Batch 47100, Loss: 0.00016776238044258207\n",
            "Batch 47200, Loss: 0.00020287955703679472\n",
            "Batch 47300, Loss: 0.0001163689885288477\n",
            "Batch 47400, Loss: 6.364710861817002e-05\n",
            "Batch 47500, Loss: 6.902008317410946e-05\n",
            "Batch 47600, Loss: 0.00010444395593367517\n",
            "Batch 47700, Loss: 0.0001645383599679917\n",
            "Batch 47800, Loss: 0.00010920761997113004\n",
            "Batch 47900, Loss: 6.341146945487708e-05\n",
            "Batch 48000, Loss: 4.8264904762618244e-05\n",
            "Batch 48100, Loss: 6.854265666333959e-05\n",
            "Batch 48200, Loss: 7.904278754722327e-05\n",
            "Batch 48300, Loss: 5.1127000915585086e-05\n",
            "Batch 48400, Loss: 5.9836649597855285e-05\n",
            "Batch 48500, Loss: 4.3250805902061984e-05\n",
            "Batch 48600, Loss: 0.00015380761760752648\n",
            "Batch 48700, Loss: 6.2336097471416e-05\n",
            "Batch 48800, Loss: 4.539797373581678e-05\n",
            "Batch 48900, Loss: 5.924150173086673e-05\n",
            "Batch 49000, Loss: 3.705838025780395e-05\n",
            "Batch 49100, Loss: 7.3312854510732e-05\n",
            "Batch 49200, Loss: 0.00010800980817293748\n",
            "Batch 49300, Loss: 0.0001373510021949187\n",
            "Batch 49400, Loss: 6.137696618679911e-05\n",
            "Batch 49500, Loss: 0.00010907983232755214\n",
            "Batch 49600, Loss: 8.845495904097334e-05\n",
            "Batch 49700, Loss: 5.136319305165671e-05\n",
            "Batch 49800, Loss: 7.76009910623543e-05\n",
            "Batch 49900, Loss: 0.0001797390286810696\n",
            "Batch 50000, Loss: 5.007771687814966e-05\n",
            "Batch 50100, Loss: 7.203107088571414e-05\n",
            "Batch 50200, Loss: 0.00013392289110925049\n",
            "Batch 50300, Loss: 7.572590402560309e-05\n",
            "Batch 50400, Loss: 7.37047812435776e-05\n",
            "Batch 50500, Loss: 0.00010566206037765369\n",
            "Batch 50600, Loss: 0.00010304011084372178\n",
            "Batch 50700, Loss: 0.028969798237085342\n",
            "Batch 50800, Loss: 8.776273898547515e-05\n",
            "Batch 50900, Loss: 0.00010184622806264088\n",
            "Batch 51000, Loss: 0.00014715231372974813\n",
            "Batch 51100, Loss: 0.00010266475146636367\n",
            "Batch 51200, Loss: 0.0001506175467511639\n",
            "Batch 51300, Loss: 0.00013654529175255448\n",
            "Batch 51400, Loss: 0.00010875197040149942\n",
            "Batch 51500, Loss: 9.897243580780923e-05\n",
            "Batch 51600, Loss: 7.488112896680832e-05\n",
            "Batch 51700, Loss: 8.537312533007935e-05\n",
            "Batch 51800, Loss: 0.0001021927164401859\n",
            "Batch 51900, Loss: 8.143684681272134e-05\n",
            "Batch 52000, Loss: 0.00012008111661998555\n",
            "Batch 52100, Loss: 6.604151712963358e-05\n",
            "Batch 52200, Loss: 7.143386028474197e-05\n",
            "Batch 52300, Loss: 0.02809126488864422\n",
            "Batch 52400, Loss: 9.133691492024809e-05\n",
            "Batch 52500, Loss: 0.00010159064549952745\n",
            "Batch 52600, Loss: 0.0001130458404077217\n",
            "Batch 52700, Loss: 8.645038906252012e-05\n",
            "Batch 52800, Loss: 0.029366955161094666\n",
            "Batch 52900, Loss: 0.0001061350412783213\n",
            "Batch 53000, Loss: 5.91366297157947e-05\n",
            "Batch 53100, Loss: 5.6395958381472155e-05\n",
            "Batch 53200, Loss: 0.0001422601199010387\n",
            "Batch 53300, Loss: 0.00013295735698193312\n",
            "Batch 53400, Loss: 0.00011017313227057457\n",
            "Batch 53500, Loss: 0.027711372822523117\n",
            "Batch 53600, Loss: 0.00021076519624330103\n",
            "Batch 53700, Loss: 0.00012628505646716803\n",
            "Batch 53800, Loss: 9.347710874862969e-05\n",
            "Batch 53900, Loss: 7.082436059135944e-05\n",
            "Batch 54000, Loss: 8.858889486873522e-05\n",
            "Batch 54100, Loss: 7.392439874820411e-05\n",
            "Batch 54200, Loss: 7.76181259425357e-05\n",
            "Batch 54300, Loss: 3.8377180317183957e-05\n",
            "Batch 54400, Loss: 7.665879093110561e-05\n",
            "Batch 54500, Loss: 0.00010326365736545995\n",
            "Batch 54600, Loss: 0.030178293585777283\n",
            "Batch 54700, Loss: 7.785153138684109e-05\n",
            "Batch 54800, Loss: 6.342339474940673e-05\n",
            "Batch 54900, Loss: 0.00013892105198465288\n",
            "Batch 55000, Loss: 0.0001242519065272063\n",
            "Batch 55100, Loss: 0.00013581707025878131\n",
            "Batch 55200, Loss: 0.0001199520193040371\n",
            "Batch 55300, Loss: 8.035716746235266e-05\n",
            "Batch 55400, Loss: 4.433249341673218e-05\n",
            "Batch 55500, Loss: 6.55720941722393e-05\n",
            "Batch 55600, Loss: 8.357981278095394e-05\n",
            "Batch 55700, Loss: 7.391397230094299e-05\n",
            "Batch 55800, Loss: 6.974246207391843e-05\n",
            "Batch 55900, Loss: 7.188763993326575e-05\n",
            "Batch 56000, Loss: 7.130030280677602e-05\n",
            "Batch 56100, Loss: 9.538798622088507e-05\n",
            "Batch 56200, Loss: 0.02892187237739563\n",
            "Batch 56300, Loss: 0.0001847513922257349\n",
            "Batch 56400, Loss: 0.00013903786020819098\n",
            "Batch 56500, Loss: 7.522910163970664e-05\n",
            "Batch 56600, Loss: 0.00012687167327385396\n",
            "Batch 56700, Loss: 0.00019776706176344305\n",
            "Batch 56800, Loss: 0.00010957702033920214\n",
            "Batch 56900, Loss: 0.00010278397530782968\n",
            "Batch 57000, Loss: 0.00010718773410189897\n",
            "Batch 57100, Loss: 0.00012437764962669462\n",
            "Batch 57200, Loss: 7.654161163372919e-05\n",
            "Batch 57300, Loss: 8.310200064443052e-05\n",
            "Batch 57400, Loss: 6.867398042231798e-05\n",
            "Batch 57500, Loss: 6.604598456760868e-05\n",
            "Batch 57600, Loss: 4.732496745418757e-05\n",
            "Batch 57700, Loss: 7.08180305082351e-05\n",
            "Batch 57800, Loss: 5.424355549621396e-05\n",
            "Batch 57900, Loss: 5.745903035858646e-05\n",
            "Batch 58000, Loss: 7.63072821428068e-05\n",
            "Batch 58100, Loss: 6.187115650391206e-05\n",
            "Batch 58200, Loss: 8.990534115582705e-05\n",
            "Batch 58300, Loss: 0.0003039482398889959\n",
            "Batch 58400, Loss: 8.846483251545578e-05\n",
            "Batch 58500, Loss: 0.0001204397194669582\n",
            "Batch 58600, Loss: 0.00011637718125712126\n",
            "Batch 58700, Loss: 7.975884363986552e-05\n",
            "Batch 58800, Loss: 5.400921872933395e-05\n",
            "Batch 58900, Loss: 9.442956798011437e-05\n",
            "Batch 59000, Loss: 0.00010325658513465896\n",
            "Batch 59100, Loss: 0.00012293951294850558\n",
            "Batch 59200, Loss: 0.0001012296270346269\n",
            "Batch 59300, Loss: 4.93538573209662e-05\n",
            "Batch 59400, Loss: 4.1353250708198175e-05\n",
            "Batch 59500, Loss: 8.775938476901501e-05\n",
            "Batch 59600, Loss: 5.292696368996985e-05\n",
            "Batch 59700, Loss: 3.050965824513696e-05\n",
            "Batch 59800, Loss: 2.597808816062752e-05\n",
            "Batch 59900, Loss: 5.543273437069729e-05\n",
            "Batch 60000, Loss: 9.788641182240099e-05\n",
            "Batch 60100, Loss: 7.534217002103105e-05\n",
            "Batch 60200, Loss: 6.377899262588471e-05\n",
            "Batch 60300, Loss: 7.058685878291726e-05\n",
            "Batch 60400, Loss: 7.678284600842744e-05\n",
            "Batch 60500, Loss: 6.760046380804852e-05\n",
            "Batch 60600, Loss: 0.00012401289131958038\n",
            "Batch 60700, Loss: 6.569279503310099e-05\n",
            "Batch 60800, Loss: 0.00013712726649828255\n",
            "Batch 60900, Loss: 0.00012865928874816746\n",
            "Batch 61000, Loss: 7.427777745760977e-05\n",
            "Batch 61100, Loss: 6.461053271777928e-05\n",
            "Batch 61200, Loss: 6.831092468928546e-05\n",
            "Batch 61300, Loss: 5.841872189193964e-05\n",
            "Batch 61400, Loss: 4.517593333730474e-05\n",
            "Batch 61500, Loss: 6.783424032619223e-05\n",
            "Batch 61600, Loss: 5.030459942645393e-05\n",
            "Batch 61700, Loss: 5.984838571748696e-05\n",
            "Batch 61800, Loss: 8.191186498152092e-05\n",
            "Batch 61900, Loss: 9.312577458331361e-05\n",
            "Batch 62000, Loss: 9.15788987185806e-05\n",
            "Batch 62100, Loss: 8.16825486253947e-05\n",
            "Batch 62200, Loss: 5.18914675922133e-05\n",
            "Batch 62300, Loss: 0.0001303431490669027\n",
            "Batch 62400, Loss: 0.02665925957262516\n",
            "Batch 62500, Loss: 0.00011961559357587248\n",
            "Batch 62600, Loss: 0.00013462667993735522\n",
            "Batch 62700, Loss: 0.00016241813136730343\n",
            "Batch 62800, Loss: 0.0001309381623286754\n",
            "Batch 62900, Loss: 9.277035132981837e-05\n",
            "Batch 63000, Loss: 0.00010731831571320072\n",
            "Batch 63100, Loss: 9.323997073806822e-05\n",
            "Batch 63200, Loss: 7.702127913944423e-05\n",
            "Batch 63300, Loss: 6.009762000758201e-05\n",
            "Batch 63400, Loss: 6.068904622225091e-05\n",
            "Batch 63500, Loss: 0.00016503165534231812\n",
            "Batch 63600, Loss: 6.0431615565903485e-05\n",
            "Batch 63700, Loss: 0.00011302944767521694\n",
            "Batch 63800, Loss: 0.00016849023813847452\n",
            "Batch 63900, Loss: 0.00013270940689835697\n",
            "Batch 64000, Loss: 0.0003118270542472601\n",
            "Batch 64100, Loss: 0.00021052821830380708\n",
            "Batch 64200, Loss: 0.0001064826428773813\n",
            "Batch 64300, Loss: 6.438029959099367e-05\n",
            "Batch 64400, Loss: 0.0001222291903104633\n",
            "Batch 64500, Loss: 0.00015490171790588647\n",
            "Batch 64600, Loss: 7.655595982214436e-05\n",
            "Batch 64700, Loss: 6.808328907936811e-05\n",
            "Batch 64800, Loss: 6.390268390532583e-05\n",
            "Batch 64900, Loss: 0.00013236570521257818\n",
            "Batch 65000, Loss: 6.987434608163312e-05\n",
            "Batch 65100, Loss: 0.00024201106862165034\n",
            "Batch 65200, Loss: 0.0001624198048375547\n",
            "Batch 65300, Loss: 7.356768037425354e-05\n",
            "Batch 65400, Loss: 4.182880002190359e-05\n",
            "Batch 65500, Loss: 4.219128823024221e-05\n",
            "Batch 65600, Loss: 9.085686906473711e-05\n",
            "Batch 65700, Loss: 7.297215051949024e-05\n",
            "Batch 65800, Loss: 9.19365556910634e-05\n",
            "Batch 65900, Loss: 0.000103501915873494\n",
            "Batch 66000, Loss: 0.00010982254752889276\n",
            "Batch 66100, Loss: 0.00011518886458361521\n",
            "Batch 66200, Loss: 8.155737305060029e-05\n",
            "Batch 66300, Loss: 6.330604082904756e-05\n",
            "Batch 66400, Loss: 6.509764352813363e-05\n",
            "Batch 66500, Loss: 0.00010730657959356904\n",
            "Batch 66600, Loss: 5.6382174079772085e-05\n",
            "Batch 66700, Loss: 0.029283108189702034\n",
            "Batch 66800, Loss: 0.00011947345774387941\n",
            "Batch 66900, Loss: 0.00020563982252497226\n",
            "Batch 67000, Loss: 0.02819751389324665\n",
            "Batch 67100, Loss: 0.00016312736261170357\n",
            "Batch 67200, Loss: 0.0001725507463561371\n",
            "Batch 67300, Loss: 0.00013212612248025835\n",
            "Batch 67400, Loss: 9.669829887570813e-05\n",
            "Batch 67500, Loss: 5.028839223086834e-05\n",
            "Batch 67600, Loss: 3.1061765184858814e-05\n",
            "Batch 67700, Loss: 6.137901800684631e-05\n",
            "Batch 67800, Loss: 6.817605753894895e-05\n",
            "Batch 67900, Loss: 4.933336822432466e-05\n",
            "Batch 68000, Loss: 7.164249836932868e-05\n",
            "Batch 68100, Loss: 6.997586751822382e-05\n",
            "Batch 68200, Loss: 4.766379788634367e-05\n",
            "Batch 68300, Loss: 5.482808774104342e-05\n",
            "Batch 68400, Loss: 4.468137922231108e-05\n",
            "Batch 68500, Loss: 4.123030885239132e-05\n",
            "Batch 68600, Loss: 4.099169746041298e-05\n",
            "Batch 68700, Loss: 8.274416177300736e-05\n",
            "Batch 68800, Loss: 5.852713366039097e-05\n",
            "Batch 68900, Loss: 6.496781134046614e-05\n",
            "Batch 69000, Loss: 0.0002870779426302761\n",
            "Batch 69100, Loss: 8.227342914324254e-05\n",
            "Batch 69200, Loss: 7.499419734813273e-05\n",
            "Batch 69300, Loss: 0.031343113631010056\n",
            "Batch 69400, Loss: 0.00010194681817665696\n",
            "Batch 69500, Loss: 6.783889693906531e-05\n",
            "Batch 69600, Loss: 3.7531324778683484e-05\n",
            "Batch 69700, Loss: 7.475930760847405e-05\n",
            "Batch 69800, Loss: 0.00012770065222866833\n",
            "Batch 69900, Loss: 7.536042539868504e-05\n",
            "Batch 70000, Loss: 7.41624680813402e-05\n",
            "Batch 70100, Loss: 6.557619053637609e-05\n",
            "Batch 70200, Loss: 0.00010720860154833645\n",
            "Batch 70300, Loss: 8.513729699188843e-05\n",
            "Batch 70400, Loss: 0.00013522877998184413\n",
            "Batch 70500, Loss: 0.00017428759019821882\n",
            "Batch 70600, Loss: 9.885917825158685e-05\n",
            "Batch 70700, Loss: 0.00011603348684730008\n",
            "Batch 70800, Loss: 7.070551509968936e-05\n",
            "Batch 70900, Loss: 0.0001913383894134313\n",
            "Batch 71000, Loss: 0.00014584659948013723\n",
            "Batch 71100, Loss: 8.382681699004024e-05\n",
            "Batch 71200, Loss: 5.1981067372253165e-05\n",
            "Batch 71300, Loss: 4.314742545830086e-05\n",
            "Batch 71400, Loss: 0.00020540413970593363\n",
            "Batch 71500, Loss: 0.00014633282262366265\n",
            "Batch 71600, Loss: 0.0001126985953305848\n",
            "Batch 71700, Loss: 6.582933565368876e-05\n",
            "Batch 71800, Loss: 0.00010471722634974867\n",
            "Batch 71900, Loss: 0.00015431750216521323\n",
            "Batch 72000, Loss: 7.524716784246266e-05\n",
            "Batch 72100, Loss: 0.000100778452178929\n",
            "Batch 72200, Loss: 0.00013536104233935475\n",
            "Batch 72300, Loss: 9.636913455324247e-05\n",
            "Batch 72400, Loss: 0.00010841254697879776\n",
            "Batch 72500, Loss: 9.135312575381249e-05\n",
            "Batch 72600, Loss: 8.4191735368222e-05\n",
            "Batch 72700, Loss: 8.848941797623411e-05\n",
            "Batch 72800, Loss: 5.676031287293881e-05\n",
            "Batch 72900, Loss: 9.742163092596456e-05\n",
            "Batch 73000, Loss: 0.00015527709911111742\n",
            "Batch 73100, Loss: 7.774982077535242e-05\n",
            "Batch 73200, Loss: 8.263853669632226e-05\n",
            "Batch 73300, Loss: 0.00011998182162642479\n",
            "Batch 73400, Loss: 5.7360302889719605e-05\n",
            "Batch 73500, Loss: 0.031222345307469368\n",
            "Batch 73600, Loss: 7.96629028627649e-05\n",
            "Batch 73700, Loss: 8.395572513109073e-05\n",
            "Batch 73800, Loss: 0.00034453594707883894\n",
            "Batch 73900, Loss: 0.00019886548398062587\n",
            "Batch 74000, Loss: 9.457169653614983e-05\n",
            "Batch 74100, Loss: 0.00013667270832229406\n",
            "Batch 74200, Loss: 0.00011365480168024078\n",
            "Batch 74300, Loss: 8.64692046889104e-05\n",
            "Batch 74400, Loss: 5.9863843489438295e-05\n",
            "Batch 74500, Loss: 6.524200580315664e-05\n",
            "Batch 74600, Loss: 5.199168299441226e-05\n",
            "Batch 74700, Loss: 0.00011842708045151085\n",
            "Batch 74800, Loss: 6.533999112434685e-05\n",
            "Batch 74900, Loss: 8.291794802062213e-05\n",
            "Batch 75000, Loss: 7.420978363370523e-05\n",
            "Batch 75100, Loss: 0.00013429918908514082\n",
            "Batch 75200, Loss: 0.0001453892473364249\n",
            "Batch 75300, Loss: 9.25565036595799e-05\n",
            "Batch 75400, Loss: 0.00016410948592238128\n",
            "Batch 75500, Loss: 8.814125612843782e-05\n",
            "Batch 75600, Loss: 7.466578244930133e-05\n",
            "Batch 75700, Loss: 0.00010566523269517347\n",
            "Batch 75800, Loss: 0.0002030405157711357\n",
            "Batch 75900, Loss: 8.539026748621836e-05\n",
            "Batch 76000, Loss: 9.350355685455725e-05\n",
            "Batch 76100, Loss: 4.7939294745447114e-05\n",
            "Batch 76200, Loss: 5.689349927706644e-05\n",
            "Batch 76300, Loss: 5.975002932245843e-05\n",
            "Batch 76400, Loss: 9.862762090051547e-05\n",
            "Batch 76500, Loss: 0.00012785471335519105\n",
            "Batch 76600, Loss: 0.00020387439872138202\n",
            "Batch 76700, Loss: 0.0002986893232446164\n",
            "Batch 76800, Loss: 5.782282823929563e-05\n",
            "Batch 76900, Loss: 5.4609397921012715e-05\n",
            "Batch 77000, Loss: 9.431183570995927e-05\n",
            "Batch 77100, Loss: 7.33193737687543e-05\n",
            "Batch 77200, Loss: 3.8131303881527856e-05\n",
            "Batch 77300, Loss: 5.746554961660877e-05\n",
            "Batch 77400, Loss: 9.061097807716578e-05\n",
            "Batch 77500, Loss: 0.0001405879738740623\n",
            "Batch 77600, Loss: 0.00013619227684102952\n",
            "Batch 77700, Loss: 8.585429168306291e-05\n",
            "Batch 77800, Loss: 8.966858149506152e-05\n",
            "Batch 77900, Loss: 0.0002916106896009296\n",
            "Batch 78000, Loss: 9.085128112928942e-05\n",
            "Batch 78100, Loss: 0.00012139891623519361\n",
            "Batch 78200, Loss: 0.00011984546290477738\n",
            "Batch 78300, Loss: 0.00014812755398452282\n",
            "Batch 78400, Loss: 0.0001416747982148081\n",
            "Batch 78500, Loss: 0.00014452895266003907\n",
            "Batch 78600, Loss: 6.17588302702643e-05\n",
            "Batch 78700, Loss: 9.528701775707304e-05\n",
            "Batch 78800, Loss: 9.264964319299906e-05\n",
            "Batch 78900, Loss: 9.87351086223498e-05\n",
            "Batch 79000, Loss: 0.00010924003436230123\n",
            "Batch 79100, Loss: 0.00010041277710115537\n",
            "Batch 79200, Loss: 0.00010267816833220422\n",
            "Batch 79300, Loss: 0.00012330948084127158\n",
            "Batch 79400, Loss: 5.6395958381472155e-05\n",
            "Batch 79500, Loss: 4.6725170250283554e-05\n",
            "Batch 79600, Loss: 4.063330925418995e-05\n",
            "Batch 79700, Loss: 3.789585753111169e-05\n",
            "Batch 79800, Loss: 0.03142639622092247\n",
            "Batch 79900, Loss: 7.40547911846079e-05\n",
            "Batch 80000, Loss: 0.00010958186612697318\n",
            "Batch 80100, Loss: 6.355490040732548e-05\n",
            "Batch 80200, Loss: 0.00013213431520853192\n",
            "Batch 80300, Loss: 9.563425555825233e-05\n",
            "Batch 80400, Loss: 7.536321936640888e-05\n",
            "Batch 80500, Loss: 9.063072502613068e-05\n",
            "Batch 80600, Loss: 7.226298475870863e-05\n",
            "Batch 80700, Loss: 0.00012379120744299144\n",
            "Batch 80800, Loss: 8.050470205489546e-05\n",
            "Batch 80900, Loss: 9.515923011349514e-05\n",
            "Batch 81000, Loss: 8.656923455419019e-05\n",
            "Batch 81100, Loss: 7.381263276329264e-05\n",
            "Batch 81200, Loss: 8.395199984079227e-05\n",
            "Batch 81300, Loss: 0.00012771779438480735\n",
            "Batch 81400, Loss: 0.00012820605479646474\n",
            "Batch 81500, Loss: 0.00015445405733771622\n",
            "Batch 81600, Loss: 0.0001586322468938306\n",
            "Batch 81700, Loss: 0.00013500430213753134\n",
            "Batch 81800, Loss: 0.00012379325926303864\n",
            "Batch 81900, Loss: 6.60716905258596e-05\n",
            "Batch 82000, Loss: 0.0001663776347413659\n",
            "Batch 82100, Loss: 0.00011603703023865819\n",
            "Batch 82200, Loss: 0.00013834596029482782\n",
            "Batch 82300, Loss: 0.00011221611930523068\n",
            "Batch 82400, Loss: 6.713662878610194e-05\n",
            "Batch 82500, Loss: 5.5566662922501564e-05\n",
            "Batch 82600, Loss: 5.329225314198993e-05\n",
            "Batch 82700, Loss: 9.83875070232898e-05\n",
            "Batch 82800, Loss: 8.526769670424983e-05\n",
            "Batch 82900, Loss: 0.00010732912051025778\n",
            "Batch 83000, Loss: 0.000109597880509682\n",
            "Batch 83100, Loss: 6.880604632897303e-05\n",
            "Batch 83200, Loss: 0.0001372664119116962\n",
            "Batch 83300, Loss: 9.397894609719515e-05\n",
            "Batch 83400, Loss: 9.958325244951993e-05\n",
            "Batch 83500, Loss: 5.97239522903692e-05\n",
            "Batch 83600, Loss: 6.116367876529694e-05\n",
            "Batch 83700, Loss: 6.844560266472399e-05\n",
            "Batch 83800, Loss: 7.096873014234006e-05\n",
            "Batch 83900, Loss: 0.00015086884377524257\n",
            "Batch 84000, Loss: 0.00018813047790899873\n",
            "Batch 84100, Loss: 0.00011700142931658775\n",
            "Batch 84200, Loss: 0.00012356524530332536\n",
            "Batch 84300, Loss: 0.0001729952491587028\n",
            "Batch 84400, Loss: 7.512831507483497e-05\n",
            "Batch 84500, Loss: 7.765332702547312e-05\n",
            "Batch 84600, Loss: 0.00010602214751997963\n",
            "Batch 84700, Loss: 0.000142171629704535\n",
            "Batch 84800, Loss: 0.00012404753942973912\n",
            "Batch 84900, Loss: 7.02381512382999e-05\n",
            "Batch 85000, Loss: 9.231284639099613e-05\n",
            "Batch 85100, Loss: 0.00010149582521989942\n",
            "Batch 85200, Loss: 7.70507103879936e-05\n",
            "Batch 85300, Loss: 6.558680615853518e-05\n",
            "Batch 85400, Loss: 7.048701809253544e-05\n",
            "Batch 85500, Loss: 4.721730147139169e-05\n",
            "Batch 85600, Loss: 5.390564911067486e-05\n",
            "Batch 85700, Loss: 0.00012044922186760232\n",
            "Batch 85800, Loss: 0.029233966022729874\n",
            "Batch 85900, Loss: 0.02854844182729721\n",
            "Batch 86000, Loss: 0.00015075260307639837\n",
            "Batch 86100, Loss: 0.00010674307122826576\n",
            "Batch 86200, Loss: 4.779177106684074e-05\n",
            "Batch 86300, Loss: 7.429099787259474e-05\n",
            "Batch 86400, Loss: 7.512105366913602e-05\n",
            "Batch 86500, Loss: 0.00011245866335229948\n",
            "Batch 86600, Loss: 6.284258415689692e-05\n",
            "Batch 86700, Loss: 5.7841825764626265e-05\n",
            "Batch 86800, Loss: 0.00014608728815801442\n",
            "Batch 86900, Loss: 8.730262197786942e-05\n",
            "Batch 87000, Loss: 0.0001378653250867501\n",
            "Batch 87100, Loss: 0.00014670839300379157\n",
            "Batch 87200, Loss: 0.00013238748942967504\n",
            "Batch 87300, Loss: 6.916742131579667e-05\n",
            "Batch 87400, Loss: 8.098418766167015e-05\n",
            "Batch 87500, Loss: 0.00010220891999779269\n",
            "Batch 87600, Loss: 6.489404768217355e-05\n",
            "Batch 87700, Loss: 0.0001346495992038399\n",
            "Batch 87800, Loss: 9.922689059749246e-05\n",
            "Batch 87900, Loss: 0.0002664779021870345\n",
            "Batch 88000, Loss: 8.743022044654936e-05\n",
            "Batch 88100, Loss: 0.00011568792251637205\n",
            "Batch 88200, Loss: 0.00012153248098911718\n",
            "Batch 88300, Loss: 9.362351556774229e-05\n",
            "Batch 88400, Loss: 9.780574328033254e-05\n",
            "Batch 88500, Loss: 0.00010483309597475454\n",
            "Batch 88600, Loss: 0.00011249368253629655\n",
            "Batch 88700, Loss: 0.00015205777890514582\n",
            "Batch 88800, Loss: 9.673462045611814e-05\n",
            "Batch 88900, Loss: 9.124880307354033e-05\n",
            "Batch 89000, Loss: 0.0001495705801062286\n",
            "Batch 89100, Loss: 9.793297795113176e-05\n",
            "Batch 89200, Loss: 4.697179247159511e-05\n",
            "Batch 89300, Loss: 5.256950680632144e-05\n",
            "Batch 89400, Loss: 4.6487297368003055e-05\n",
            "Batch 89500, Loss: 5.007175786886364e-05\n",
            "Batch 89600, Loss: 5.268779204925522e-05\n",
            "Batch 89700, Loss: 5.55593978788238e-05\n",
            "Batch 89800, Loss: 6.892060628160834e-05\n",
            "Batch 89900, Loss: 6.964150088606402e-05\n",
            "Batch 90000, Loss: 0.00010792262037284672\n",
            "Batch 90100, Loss: 0.00011926537263207138\n",
            "Batch 90200, Loss: 9.230762952938676e-05\n",
            "Batch 90300, Loss: 0.00010196600487688556\n",
            "Batch 90400, Loss: 0.0001051814469974488\n",
            "Epoch 4: Average Loss: 0.001036326766126282\n",
            "Batch 0, Loss: 0.00013224888243712485\n",
            "Batch 100, Loss: 0.0002255689905723557\n",
            "Batch 200, Loss: 0.00012344210699666291\n",
            "Batch 300, Loss: 9.172214049613103e-05\n",
            "Batch 400, Loss: 9.135088475886732e-05\n",
            "Batch 500, Loss: 0.030789151787757874\n",
            "Batch 600, Loss: 0.0001290402578888461\n",
            "Batch 700, Loss: 0.00014968383766245097\n",
            "Batch 800, Loss: 0.00012892177619505674\n",
            "Batch 900, Loss: 0.00010735687101259828\n",
            "Batch 1000, Loss: 8.206665370380506e-05\n",
            "Batch 1100, Loss: 9.529875387670472e-05\n",
            "Batch 1200, Loss: 0.00012355258513707668\n",
            "Batch 1300, Loss: 0.0001536058698548004\n",
            "Batch 1400, Loss: 0.000136687041958794\n",
            "Batch 1500, Loss: 0.00011509721662150696\n",
            "Batch 1600, Loss: 0.03035661391913891\n",
            "Batch 1700, Loss: 6.500022573163733e-05\n",
            "Batch 1800, Loss: 0.00013357023999560624\n",
            "Batch 1900, Loss: 0.00021770503371953964\n",
            "Batch 2000, Loss: 0.00014074165665078908\n",
            "Batch 2100, Loss: 0.0002388311258982867\n",
            "Batch 2200, Loss: 0.00011998592526651919\n",
            "Batch 2300, Loss: 6.54811883578077e-05\n",
            "Batch 2400, Loss: 6.870582728879526e-05\n",
            "Batch 2500, Loss: 8.063454151852056e-05\n",
            "Batch 2600, Loss: 8.373032324016094e-05\n",
            "Batch 2700, Loss: 5.2586827223422006e-05\n",
            "Batch 2800, Loss: 3.252454553148709e-05\n",
            "Batch 2900, Loss: 4.2799092625500634e-05\n",
            "Batch 3000, Loss: 9.696058259578422e-05\n",
            "Batch 3100, Loss: 0.02794673852622509\n",
            "Batch 3200, Loss: 0.00014358987391460687\n",
            "Batch 3300, Loss: 0.00010030957491835579\n",
            "Batch 3400, Loss: 9.07739668036811e-05\n",
            "Batch 3500, Loss: 9.207813127432019e-05\n",
            "Batch 3600, Loss: 8.802222146186978e-05\n",
            "Batch 3700, Loss: 0.00017114102956838906\n",
            "Batch 3800, Loss: 0.028821319341659546\n",
            "Batch 3900, Loss: 0.00011245997302467003\n",
            "Batch 4000, Loss: 0.00012644098023883998\n",
            "Batch 4100, Loss: 9.540623432258144e-05\n",
            "Batch 4200, Loss: 0.0288177952170372\n",
            "Batch 4300, Loss: 0.00013228911848273128\n",
            "Batch 4400, Loss: 6.777443923056126e-05\n",
            "Batch 4500, Loss: 6.943771586520597e-05\n",
            "Batch 4600, Loss: 4.4030541175743565e-05\n",
            "Batch 4700, Loss: 0.00013752051745541394\n",
            "Batch 4800, Loss: 0.00010937470506178215\n",
            "Batch 4900, Loss: 9.017265256261453e-05\n",
            "Batch 5000, Loss: 6.97789728292264e-05\n",
            "Batch 5100, Loss: 4.948722926201299e-05\n",
            "Batch 5200, Loss: 4.089520371053368e-05\n",
            "Batch 5300, Loss: 6.535824650200084e-05\n",
            "Batch 5400, Loss: 0.00011175804684171453\n",
            "Batch 5500, Loss: 0.00011318741599097848\n",
            "Batch 5600, Loss: 7.69149191910401e-05\n",
            "Batch 5700, Loss: 0.00027170663815923035\n",
            "Batch 5800, Loss: 0.0001657867105677724\n",
            "Batch 5900, Loss: 0.0001247699692612514\n",
            "Batch 6000, Loss: 0.00011653403635136783\n",
            "Batch 6100, Loss: 0.00010069722338812426\n",
            "Batch 6200, Loss: 8.82781678228639e-05\n",
            "Batch 6300, Loss: 9.243429667549208e-05\n",
            "Batch 6400, Loss: 9.422819130122662e-05\n",
            "Batch 6500, Loss: 0.0001490776485297829\n",
            "Batch 6600, Loss: 0.000103179452707991\n",
            "Batch 6700, Loss: 0.00015410363266710192\n",
            "Batch 6800, Loss: 0.0001236913667526096\n",
            "Batch 6900, Loss: 7.49023602111265e-05\n",
            "Batch 7000, Loss: 5.568103370023891e-05\n",
            "Batch 7100, Loss: 6.238341302378103e-05\n",
            "Batch 7200, Loss: 0.0001000649863271974\n",
            "Batch 7300, Loss: 0.00013381837925408036\n",
            "Batch 7400, Loss: 0.0002096160751534626\n",
            "Batch 7500, Loss: 0.00011068038293160498\n",
            "Batch 7600, Loss: 0.029633712023496628\n",
            "Batch 7700, Loss: 9.56636868068017e-05\n",
            "Batch 7800, Loss: 9.053161920746788e-05\n",
            "Batch 7900, Loss: 6.035356273059733e-05\n",
            "Batch 8000, Loss: 0.0001313222892349586\n",
            "Batch 8100, Loss: 7.955094770295545e-05\n",
            "Batch 8200, Loss: 4.804677882930264e-05\n",
            "Batch 8300, Loss: 5.5931388487806544e-05\n",
            "Batch 8400, Loss: 0.031144438311457634\n",
            "Batch 8500, Loss: 5.355657049221918e-05\n",
            "Batch 8600, Loss: 6.786274025216699e-05\n",
            "Batch 8700, Loss: 5.211834650253877e-05\n",
            "Batch 8800, Loss: 5.688735473086126e-05\n",
            "Batch 8900, Loss: 5.915413566981442e-05\n",
            "Batch 9000, Loss: 6.845845928182825e-05\n",
            "Batch 9100, Loss: 0.00010280893911840394\n",
            "Batch 9200, Loss: 0.00019969248387496918\n",
            "Batch 9300, Loss: 9.959535964298993e-05\n",
            "Batch 9400, Loss: 0.00010428392852190882\n",
            "Batch 9500, Loss: 0.00018695808830671012\n",
            "Batch 9600, Loss: 0.00012882862938567996\n",
            "Batch 9700, Loss: 0.00014588683552574366\n",
            "Batch 9800, Loss: 0.00012369340402074158\n",
            "Batch 9900, Loss: 0.00015350303146988153\n",
            "Batch 10000, Loss: 6.718598888255656e-05\n",
            "Batch 10100, Loss: 6.455092079704627e-05\n",
            "Batch 10200, Loss: 7.610497414134443e-05\n",
            "Batch 10300, Loss: 5.85830130148679e-05\n",
            "Batch 10400, Loss: 8.352261647814885e-05\n",
            "Batch 10500, Loss: 9.994632273446769e-05\n",
            "Batch 10600, Loss: 6.413162191165611e-05\n",
            "Batch 10700, Loss: 5.803872045362368e-05\n",
            "Batch 10800, Loss: 7.450689736288041e-05\n",
            "Batch 10900, Loss: 9.913487156154588e-05\n",
            "Batch 11000, Loss: 9.507931099506095e-05\n",
            "Batch 11100, Loss: 5.847608917974867e-05\n",
            "Batch 11200, Loss: 4.296916085877456e-05\n",
            "Batch 11300, Loss: 3.9139405998867005e-05\n",
            "Batch 11400, Loss: 5.930036058998667e-05\n",
            "Batch 11500, Loss: 4.402960985316895e-05\n",
            "Batch 11600, Loss: 9.530509123578668e-05\n",
            "Batch 11700, Loss: 8.159984281519428e-05\n",
            "Batch 11800, Loss: 0.00010986147390212864\n",
            "Batch 11900, Loss: 8.899274689611048e-05\n",
            "Batch 12000, Loss: 0.00011558136611711234\n",
            "Batch 12100, Loss: 0.000148005347000435\n",
            "Batch 12200, Loss: 7.944067328935489e-05\n",
            "Batch 12300, Loss: 7.430683035636321e-05\n",
            "Batch 12400, Loss: 7.229055336210877e-05\n",
            "Batch 12500, Loss: 6.215000757947564e-05\n",
            "Batch 12600, Loss: 6.060037776478566e-05\n",
            "Batch 12700, Loss: 7.990599988261238e-05\n",
            "Batch 12800, Loss: 7.454489241354167e-05\n",
            "Batch 12900, Loss: 7.9559329606127e-05\n",
            "Batch 13000, Loss: 5.523043728317134e-05\n",
            "Batch 13100, Loss: 7.348087092395872e-05\n",
            "Batch 13200, Loss: 9.542747284285724e-05\n",
            "Batch 13300, Loss: 7.801954780006781e-05\n",
            "Batch 13400, Loss: 6.249760190257803e-05\n",
            "Batch 13500, Loss: 6.143787322798744e-05\n",
            "Batch 13600, Loss: 9.780220716493204e-05\n",
            "Batch 13700, Loss: 0.00011139851267216727\n",
            "Batch 13800, Loss: 6.190617568790913e-05\n",
            "Batch 13900, Loss: 5.044784484198317e-05\n",
            "Batch 14000, Loss: 0.000136202885187231\n",
            "Batch 14100, Loss: 6.904485053382814e-05\n",
            "Batch 14200, Loss: 8.254297426901758e-05\n",
            "Batch 14300, Loss: 9.661576768849045e-05\n",
            "Batch 14400, Loss: 8.540647104382515e-05\n",
            "Batch 14500, Loss: 9.399794362252578e-05\n",
            "Batch 14600, Loss: 9.040755685418844e-05\n",
            "Batch 14700, Loss: 8.456858631689101e-05\n",
            "Batch 14800, Loss: 6.775674410164356e-05\n",
            "Batch 14900, Loss: 0.00011187074414920062\n",
            "Batch 15000, Loss: 8.674266427988186e-05\n",
            "Batch 15100, Loss: 5.251976472209208e-05\n",
            "Batch 15200, Loss: 8.471387991448864e-05\n",
            "Batch 15300, Loss: 5.512519055628218e-05\n",
            "Batch 15400, Loss: 3.06437723338604e-05\n",
            "Batch 15500, Loss: 7.574303890578449e-05\n",
            "Batch 15600, Loss: 6.060224040993489e-05\n",
            "Batch 15700, Loss: 5.8693476603366435e-05\n",
            "Batch 15800, Loss: 4.508987694862299e-05\n",
            "Batch 15900, Loss: 5.462858098326251e-05\n",
            "Batch 16000, Loss: 6.0355800087563694e-05\n",
            "Batch 16100, Loss: 9.100477473111823e-05\n",
            "Batch 16200, Loss: 9.936493006534874e-05\n",
            "Batch 16300, Loss: 0.0001137926519731991\n",
            "Batch 16400, Loss: 0.00014946438022889197\n",
            "Batch 16500, Loss: 0.00010115865006810054\n",
            "Batch 16600, Loss: 0.00010484334052307531\n",
            "Batch 16700, Loss: 7.371055835392326e-05\n",
            "Batch 16800, Loss: 6.393360672518611e-05\n",
            "Batch 16900, Loss: 4.651355993701145e-05\n",
            "Batch 17000, Loss: 0.00011318200995447114\n",
            "Batch 17100, Loss: 0.00011235713463975117\n",
            "Batch 17200, Loss: 0.00016543031961191446\n",
            "Batch 17300, Loss: 0.00011856231867568567\n",
            "Batch 17400, Loss: 0.00014924102288205177\n",
            "Batch 17500, Loss: 0.00013967551058158278\n",
            "Batch 17600, Loss: 6.0741200286429375e-05\n",
            "Batch 17700, Loss: 0.00011760853521991521\n",
            "Batch 17800, Loss: 0.00013359053991734982\n",
            "Batch 17900, Loss: 0.00010818379814736545\n",
            "Batch 18000, Loss: 0.0001396663865307346\n",
            "Batch 18100, Loss: 9.243709064321592e-05\n",
            "Batch 18200, Loss: 0.00012118523591198027\n",
            "Batch 18300, Loss: 6.57140335533768e-05\n",
            "Batch 18400, Loss: 0.00011211254604859278\n",
            "Batch 18500, Loss: 9.410803613718599e-05\n",
            "Batch 18600, Loss: 9.565828077029437e-05\n",
            "Batch 18700, Loss: 7.466205715900287e-05\n",
            "Batch 18800, Loss: 6.297856452874839e-05\n",
            "Batch 18900, Loss: 0.00012273459287825972\n",
            "Batch 19000, Loss: 0.00010710148490034044\n",
            "Batch 19100, Loss: 8.563950541429222e-05\n",
            "Batch 19200, Loss: 0.028940251097083092\n",
            "Batch 19300, Loss: 0.00010342105815652758\n",
            "Batch 19400, Loss: 0.00010495883907424286\n",
            "Batch 19500, Loss: 0.00020924254204146564\n",
            "Batch 19600, Loss: 0.0002068660396616906\n",
            "Batch 19700, Loss: 9.831354691414163e-05\n",
            "Batch 19800, Loss: 0.0001399145257892087\n",
            "Batch 19900, Loss: 8.278569293906912e-05\n",
            "Batch 20000, Loss: 6.83506004861556e-05\n",
            "Batch 20100, Loss: 7.03795303707011e-05\n",
            "Batch 20200, Loss: 0.00011057214578613639\n",
            "Batch 20300, Loss: 0.00011760798224713653\n",
            "Batch 20400, Loss: 0.00010210441541858017\n",
            "Batch 20500, Loss: 0.00010115753684658557\n",
            "Batch 20600, Loss: 9.900782606564462e-05\n",
            "Batch 20700, Loss: 4.5046661398373544e-05\n",
            "Batch 20800, Loss: 7.071315485518426e-05\n",
            "Batch 20900, Loss: 9.158784087048844e-05\n",
            "Batch 21000, Loss: 0.00010923928493866697\n",
            "Batch 21100, Loss: 0.00016841570322867483\n",
            "Batch 21200, Loss: 0.00012786849401891232\n",
            "Batch 21300, Loss: 9.219846106134355e-05\n",
            "Batch 21400, Loss: 0.00018408946925774217\n",
            "Batch 21500, Loss: 8.123864245135337e-05\n",
            "Batch 21600, Loss: 0.00013429787941277027\n",
            "Batch 21700, Loss: 5.6642587878741324e-05\n",
            "Batch 21800, Loss: 0.00024752880563028157\n",
            "Batch 21900, Loss: 0.00015637920296285301\n",
            "Batch 22000, Loss: 9.519293962512165e-05\n",
            "Batch 22100, Loss: 8.314521255670115e-05\n",
            "Batch 22200, Loss: 0.00015600885672029108\n",
            "Batch 22300, Loss: 0.00014002443640492857\n",
            "Batch 22400, Loss: 7.119915244402364e-05\n",
            "Batch 22500, Loss: 6.438905256800354e-05\n",
            "Batch 22600, Loss: 0.00013381744793150574\n",
            "Batch 22700, Loss: 8.076120866462588e-05\n",
            "Batch 22800, Loss: 6.060000669094734e-05\n",
            "Batch 22900, Loss: 4.36496120528318e-05\n",
            "Batch 23000, Loss: 7.01316021149978e-05\n",
            "Batch 23100, Loss: 0.00013167437282390893\n",
            "Batch 23200, Loss: 0.00011355197057127953\n",
            "Batch 23300, Loss: 0.00010198630479862913\n",
            "Batch 23400, Loss: 9.757326188264415e-05\n",
            "Batch 23500, Loss: 0.00011736394662875682\n",
            "Batch 23600, Loss: 0.02775011956691742\n",
            "Batch 23700, Loss: 0.00013000988110434264\n",
            "Batch 23800, Loss: 8.75462792464532e-05\n",
            "Batch 23900, Loss: 0.00015660481585655361\n",
            "Batch 24000, Loss: 0.0001277468545595184\n",
            "Batch 24100, Loss: 0.00011212204117327929\n",
            "Batch 24200, Loss: 8.516709931427613e-05\n",
            "Batch 24300, Loss: 0.00013035432493779808\n",
            "Batch 24400, Loss: 8.790467836661264e-05\n",
            "Batch 24500, Loss: 8.231310494011268e-05\n",
            "Batch 24600, Loss: 0.00012952608813066036\n",
            "Batch 24700, Loss: 0.00011068112507928163\n",
            "Batch 24800, Loss: 0.00012976622383575886\n",
            "Batch 24900, Loss: 0.00016613843035884202\n",
            "Batch 25000, Loss: 0.0001852877321653068\n",
            "Batch 25100, Loss: 0.00020125722221564502\n",
            "Batch 25200, Loss: 0.00016828511434141546\n",
            "Batch 25300, Loss: 0.00011605435429373756\n",
            "Batch 25400, Loss: 0.00011856306809931993\n",
            "Batch 25500, Loss: 0.00016544094251003116\n",
            "Batch 25600, Loss: 0.00015755080676171929\n",
            "Batch 25700, Loss: 0.0001321788295172155\n",
            "Batch 25800, Loss: 0.00010067189577966928\n",
            "Batch 25900, Loss: 0.0001775291602825746\n",
            "Batch 26000, Loss: 0.0001494476164225489\n",
            "Batch 26100, Loss: 8.728921238798648e-05\n",
            "Batch 26200, Loss: 7.108329009497538e-05\n",
            "Batch 26300, Loss: 0.029962923377752304\n",
            "Batch 26400, Loss: 6.0350583225954324e-05\n",
            "Batch 26500, Loss: 8.898157102521509e-05\n",
            "Batch 26600, Loss: 8.707200322533026e-05\n",
            "Batch 26700, Loss: 6.213566666701809e-05\n",
            "Batch 26800, Loss: 8.575760875828564e-05\n",
            "Batch 26900, Loss: 0.028947604820132256\n",
            "Batch 27000, Loss: 7.670163176953793e-05\n",
            "Batch 27100, Loss: 0.00014072918565943837\n",
            "Batch 27200, Loss: 0.00011497855302877724\n",
            "Batch 27300, Loss: 7.095699402270839e-05\n",
            "Batch 27400, Loss: 9.540175960864872e-05\n",
            "Batch 27500, Loss: 0.00011819999053841457\n",
            "Batch 27600, Loss: 5.653696644003503e-05\n",
            "Batch 27700, Loss: 0.00021877964900340885\n",
            "Batch 27800, Loss: 0.00011092032218584791\n",
            "Batch 27900, Loss: 6.319986277958378e-05\n",
            "Batch 28000, Loss: 3.82512625947129e-05\n",
            "Batch 28100, Loss: 8.44301757751964e-05\n",
            "Batch 28200, Loss: 5.603663521469571e-05\n",
            "Batch 28300, Loss: 0.00015335771604441106\n",
            "Batch 28400, Loss: 0.00010269045742461458\n",
            "Batch 28500, Loss: 0.00010389254748588428\n",
            "Batch 28600, Loss: 9.851362119661644e-05\n",
            "Batch 28700, Loss: 0.0001205837179441005\n",
            "Batch 28800, Loss: 0.00010794925765367225\n",
            "Batch 28900, Loss: 5.067249003332108e-05\n",
            "Batch 29000, Loss: 6.8098001065664e-05\n",
            "Batch 29100, Loss: 4.548830838757567e-05\n",
            "Batch 29200, Loss: 5.574044553213753e-05\n",
            "Batch 29300, Loss: 0.00014203431783244014\n",
            "Batch 29400, Loss: 0.0001353515253867954\n",
            "Batch 29500, Loss: 0.0001835625880630687\n",
            "Batch 29600, Loss: 0.00010075981117552146\n",
            "Batch 29700, Loss: 0.00015298287326004356\n",
            "Batch 29800, Loss: 9.514283010503277e-05\n",
            "Batch 29900, Loss: 6.032300734659657e-05\n",
            "Batch 30000, Loss: 4.850462937611155e-05\n",
            "Batch 30100, Loss: 3.1327566830441356e-05\n",
            "Batch 30200, Loss: 7.64097276260145e-05\n",
            "Batch 30300, Loss: 8.284734940389171e-05\n",
            "Batch 30400, Loss: 0.00022419403831008822\n",
            "Batch 30500, Loss: 0.00010823948832694441\n",
            "Batch 30600, Loss: 0.00010836838919203728\n",
            "Batch 30700, Loss: 0.00013112147280480713\n",
            "Batch 30800, Loss: 0.00015033659292384982\n",
            "Batch 30900, Loss: 9.46424770518206e-05\n",
            "Batch 31000, Loss: 5.8746001741383225e-05\n",
            "Batch 31100, Loss: 4.42974669567775e-05\n",
            "Batch 31200, Loss: 8.009208249859512e-05\n",
            "Batch 31300, Loss: 0.00012872392835561186\n",
            "Batch 31400, Loss: 6.862796726636589e-05\n",
            "Batch 31500, Loss: 0.00011550237832125276\n",
            "Batch 31600, Loss: 8.388735295739025e-05\n",
            "Batch 31700, Loss: 7.112370803952217e-05\n",
            "Batch 31800, Loss: 6.683653191430494e-05\n",
            "Batch 31900, Loss: 5.085335942567326e-05\n",
            "Batch 32000, Loss: 4.237439134158194e-05\n",
            "Batch 32100, Loss: 4.452528082765639e-05\n",
            "Batch 32200, Loss: 7.826487853890285e-05\n",
            "Batch 32300, Loss: 0.000120359800348524\n",
            "Batch 32400, Loss: 0.00021154299611225724\n",
            "Batch 32500, Loss: 6.987880624365062e-05\n",
            "Batch 32600, Loss: 9.437235712539405e-05\n",
            "Batch 32700, Loss: 7.946953701321036e-05\n",
            "Batch 32800, Loss: 0.029860928654670715\n",
            "Batch 32900, Loss: 0.028240708634257317\n",
            "Batch 33000, Loss: 0.00012355443323031068\n",
            "Batch 33100, Loss: 5.892407716601156e-05\n",
            "Batch 33200, Loss: 4.088514106115326e-05\n",
            "Batch 33300, Loss: 0.00011207900388399139\n",
            "Batch 33400, Loss: 6.547186785610393e-05\n",
            "Batch 33500, Loss: 9.252314339391887e-05\n",
            "Batch 33600, Loss: 7.772466778988019e-05\n",
            "Batch 33700, Loss: 0.00014675420243293047\n",
            "Batch 33800, Loss: 0.00015571598487440497\n",
            "Batch 33900, Loss: 0.00016416965809185058\n",
            "Batch 34000, Loss: 7.759184518363327e-05\n",
            "Batch 34100, Loss: 4.142868783674203e-05\n",
            "Batch 34200, Loss: 5.9801437600981444e-05\n",
            "Batch 34300, Loss: 5.348298873286694e-05\n",
            "Batch 34400, Loss: 3.224140891688876e-05\n",
            "Batch 34500, Loss: 4.214546061120927e-05\n",
            "Batch 34600, Loss: 6.730297900503501e-05\n",
            "Batch 34700, Loss: 6.420016870833933e-05\n",
            "Batch 34800, Loss: 9.342624252894893e-05\n",
            "Batch 34900, Loss: 6.300836685113609e-05\n",
            "Batch 35000, Loss: 7.576092320960015e-05\n",
            "Batch 35100, Loss: 0.00014027704310137779\n",
            "Batch 35200, Loss: 7.099723006831482e-05\n",
            "Batch 35300, Loss: 7.171141623985022e-05\n",
            "Batch 35400, Loss: 6.503449549200013e-05\n",
            "Batch 35500, Loss: 7.063435623422265e-05\n",
            "Batch 35600, Loss: 0.0001009425541269593\n",
            "Batch 35700, Loss: 0.0001393282727804035\n",
            "Batch 35800, Loss: 0.00010260588896926492\n",
            "Batch 35900, Loss: 4.904892557533458e-05\n",
            "Batch 36000, Loss: 4.2358373320894316e-05\n",
            "Batch 36100, Loss: 0.0001768247748259455\n",
            "Batch 36200, Loss: 0.00010844886855920777\n",
            "Batch 36300, Loss: 9.531831165077165e-05\n",
            "Batch 36400, Loss: 0.00010068548726849258\n",
            "Batch 36500, Loss: 8.065540168900043e-05\n",
            "Batch 36600, Loss: 6.979983299970627e-05\n",
            "Batch 36700, Loss: 3.99655218643602e-05\n",
            "Batch 36800, Loss: 8.291441190522164e-05\n",
            "Batch 36900, Loss: 0.00013991136802360415\n",
            "Batch 37000, Loss: 9.162061905954033e-05\n",
            "Batch 37100, Loss: 0.00011439230001997203\n",
            "Batch 37200, Loss: 0.00010795521666295826\n",
            "Batch 37300, Loss: 0.00015410214837174863\n",
            "Batch 37400, Loss: 0.00011283923959126696\n",
            "Batch 37500, Loss: 0.0001601918920641765\n",
            "Batch 37600, Loss: 0.0001831469708122313\n",
            "Batch 37700, Loss: 0.00024015242524910718\n",
            "Batch 37800, Loss: 0.0001568499719724059\n",
            "Batch 37900, Loss: 0.00021642901992890984\n",
            "Batch 38000, Loss: 9.839513950282708e-05\n",
            "Batch 38100, Loss: 0.00011069807806052268\n",
            "Batch 38200, Loss: 0.00013908497930970043\n",
            "Batch 38300, Loss: 0.00021522530005313456\n",
            "Batch 38400, Loss: 9.519200830254704e-05\n",
            "Batch 38500, Loss: 0.00013025093358010054\n",
            "Batch 38600, Loss: 8.911550685297698e-05\n",
            "Batch 38700, Loss: 0.00011081450793426484\n",
            "Batch 38800, Loss: 6.500991003122181e-05\n",
            "Batch 38900, Loss: 6.0361388023011386e-05\n",
            "Batch 39000, Loss: 4.902135697193444e-05\n",
            "Batch 39100, Loss: 4.2339746869402006e-05\n",
            "Batch 39200, Loss: 7.919068593764678e-05\n",
            "Batch 39300, Loss: 0.00010924207890639082\n",
            "Batch 39400, Loss: 9.840427082963288e-05\n",
            "Batch 39500, Loss: 7.274898234754801e-05\n",
            "Batch 39600, Loss: 6.775525980629027e-05\n",
            "Batch 39700, Loss: 7.573838229291141e-05\n",
            "Batch 39800, Loss: 6.881815352244303e-05\n",
            "Batch 39900, Loss: 0.00014096706581767648\n",
            "Batch 40000, Loss: 0.00015111829270608723\n",
            "Batch 40100, Loss: 0.0002171097876271233\n",
            "Batch 40200, Loss: 8.754702139412984e-05\n",
            "Batch 40300, Loss: 0.00010817727888934314\n",
            "Batch 40400, Loss: 0.00013334724644664675\n",
            "Batch 40500, Loss: 0.00012286331912036985\n",
            "Batch 40600, Loss: 0.00017694324196781963\n",
            "Batch 40700, Loss: 0.00015624507796019316\n",
            "Batch 40800, Loss: 0.00013298845442477614\n",
            "Batch 40900, Loss: 0.00016853102715685964\n",
            "Batch 41000, Loss: 0.028786219656467438\n",
            "Batch 41100, Loss: 0.00010615943756420165\n",
            "Batch 41200, Loss: 0.00013346348714549094\n",
            "Batch 41300, Loss: 0.00010710986680351198\n",
            "Batch 41400, Loss: 9.935729030985385e-05\n",
            "Batch 41500, Loss: 0.0001115337508963421\n",
            "Batch 41600, Loss: 6.703157123411074e-05\n",
            "Batch 41700, Loss: 4.3982858187519014e-05\n",
            "Batch 41800, Loss: 7.00118180247955e-05\n",
            "Batch 41900, Loss: 6.524498894577846e-05\n",
            "Batch 42000, Loss: 8.789555431576446e-05\n",
            "Batch 42100, Loss: 7.06058563082479e-05\n",
            "Batch 42200, Loss: 8.885005809133872e-05\n",
            "Batch 42300, Loss: 0.00011997902765870094\n",
            "Batch 42400, Loss: 7.752069359412417e-05\n",
            "Batch 42500, Loss: 5.96345380472485e-05\n",
            "Batch 42600, Loss: 7.942559022922069e-05\n",
            "Batch 42700, Loss: 7.000436744419858e-05\n",
            "Batch 42800, Loss: 3.8989084714557976e-05\n",
            "Batch 42900, Loss: 6.213212327565998e-05\n",
            "Batch 43000, Loss: 6.236589979380369e-05\n",
            "Batch 43100, Loss: 0.00010457453754497692\n",
            "Batch 43200, Loss: 7.883023499744013e-05\n",
            "Batch 43300, Loss: 8.694217103766277e-05\n",
            "Batch 43400, Loss: 5.545173189602792e-05\n",
            "Batch 43500, Loss: 4.291849472792819e-05\n",
            "Batch 43600, Loss: 5.00860987813212e-05\n",
            "Batch 43700, Loss: 0.0001527710846858099\n",
            "Batch 43800, Loss: 7.811585965100676e-05\n",
            "Batch 43900, Loss: 9.481572487857193e-05\n",
            "Batch 44000, Loss: 7.490310963476077e-05\n",
            "Batch 44100, Loss: 6.11845389357768e-05\n",
            "Batch 44200, Loss: 0.00010876854503294453\n",
            "Batch 44300, Loss: 7.441989873768762e-05\n",
            "Batch 44400, Loss: 0.0001459630293538794\n",
            "Batch 44500, Loss: 9.290298476116732e-05\n",
            "Batch 44600, Loss: 8.658190199639648e-05\n",
            "Batch 44700, Loss: 0.0002155219262931496\n",
            "Batch 44800, Loss: 0.0001323062606388703\n",
            "Batch 44900, Loss: 2.228024459327571e-05\n",
            "Batch 45000, Loss: 8.771786269790027e-06\n",
            "Batch 45100, Loss: 5.787998816231266e-06\n",
            "Batch 45200, Loss: 3.426243347348645e-05\n",
            "Batch 45300, Loss: 3.616593312472105e-05\n",
            "Batch 45400, Loss: 0.027772339060902596\n",
            "Batch 45500, Loss: 0.00021247373661026359\n",
            "Batch 45600, Loss: 0.00012107101792935282\n",
            "Batch 45700, Loss: 0.00010247304453514516\n",
            "Batch 45800, Loss: 9.685139229986817e-05\n",
            "Batch 45900, Loss: 0.00010419617319712415\n",
            "Batch 46000, Loss: 4.655788143281825e-05\n",
            "Batch 46100, Loss: 8.685105422046036e-05\n",
            "Batch 46200, Loss: 0.00010542098607402295\n",
            "Batch 46300, Loss: 0.028700463473796844\n",
            "Batch 46400, Loss: 0.0001911416184157133\n",
            "Batch 46500, Loss: 0.00019248110766056925\n",
            "Batch 46600, Loss: 9.434030653210357e-05\n",
            "Batch 46700, Loss: 0.00011374829045962542\n",
            "Batch 46800, Loss: 6.532377301482484e-05\n",
            "Batch 46900, Loss: 6.532898987643421e-05\n",
            "Batch 47000, Loss: 6.0422658862080425e-05\n",
            "Batch 47100, Loss: 4.7539357183268294e-05\n",
            "Batch 47200, Loss: 0.0001066774784703739\n",
            "Batch 47300, Loss: 0.00012016660184599459\n",
            "Batch 47400, Loss: 6.60381410853006e-05\n",
            "Batch 47500, Loss: 8.094002259895205e-05\n",
            "Batch 47600, Loss: 4.301217995816842e-05\n",
            "Batch 47700, Loss: 8.352335134986788e-05\n",
            "Batch 47800, Loss: 0.00015111472748685628\n",
            "Batch 47900, Loss: 0.00011378630733815953\n",
            "Batch 48000, Loss: 0.00016793764370959252\n",
            "Batch 48100, Loss: 0.00010797588038258255\n",
            "Batch 48200, Loss: 8.256718137999997e-05\n",
            "Batch 48300, Loss: 0.0001553620386403054\n",
            "Batch 48400, Loss: 9.043101454153657e-05\n",
            "Batch 48500, Loss: 0.00018241777434013784\n",
            "Batch 48600, Loss: 8.396521297981963e-05\n",
            "Batch 48700, Loss: 0.00012811568740289658\n",
            "Batch 48800, Loss: 0.0002225776552222669\n",
            "Batch 48900, Loss: 8.089252514764667e-05\n",
            "Batch 49000, Loss: 0.00023784943914506584\n",
            "Batch 49100, Loss: 0.00024343164113815874\n",
            "Batch 49200, Loss: 9.482874884270132e-05\n",
            "Batch 49300, Loss: 6.265909178182483e-05\n",
            "Batch 49400, Loss: 8.990943024400622e-05\n",
            "Batch 49500, Loss: 0.00011412981984904036\n",
            "Batch 49600, Loss: 8.050580800045282e-05\n",
            "Batch 49700, Loss: 0.00010376660793554038\n",
            "Batch 49800, Loss: 8.313775470014662e-05\n",
            "Batch 49900, Loss: 0.00011840303341159597\n",
            "Batch 50000, Loss: 7.847573579056188e-05\n",
            "Batch 50100, Loss: 0.00013843257329426706\n",
            "Batch 50200, Loss: 6.439556455006823e-05\n",
            "Batch 50300, Loss: 5.0086091505363584e-05\n",
            "Batch 50400, Loss: 0.00010802302131196484\n",
            "Batch 50500, Loss: 0.00010062698856927454\n",
            "Batch 50600, Loss: 8.287603122880682e-05\n",
            "Batch 50700, Loss: 0.00010920760541921481\n",
            "Batch 50800, Loss: 4.7334833652712405e-05\n",
            "Batch 50900, Loss: 7.117847417248413e-05\n",
            "Batch 51000, Loss: 8.606980554759502e-05\n",
            "Batch 51100, Loss: 4.411156623973511e-05\n",
            "Batch 51200, Loss: 9.120073809754103e-05\n",
            "Batch 51300, Loss: 0.0001286341284867376\n",
            "Batch 51400, Loss: 0.00014558504335582256\n",
            "Batch 51500, Loss: 9.097924339585006e-05\n",
            "Batch 51600, Loss: 5.7109384215436876e-05\n",
            "Batch 51700, Loss: 8.23872396722436e-05\n",
            "Batch 51800, Loss: 9.239350038114935e-05\n",
            "Batch 51900, Loss: 8.953388896770775e-05\n",
            "Batch 52000, Loss: 0.00012457006960175931\n",
            "Batch 52100, Loss: 9.487812349107116e-05\n",
            "Batch 52200, Loss: 0.0001224288862431422\n",
            "Batch 52300, Loss: 0.00011922549310838804\n",
            "Batch 52400, Loss: 6.675419717794284e-05\n",
            "Batch 52500, Loss: 4.7791949327802286e-05\n",
            "Batch 52600, Loss: 7.127384742489085e-05\n",
            "Batch 52700, Loss: 8.141206490108743e-05\n",
            "Batch 52800, Loss: 8.903931302484125e-05\n",
            "Batch 52900, Loss: 6.759151438018307e-05\n",
            "Batch 53000, Loss: 6.4116895373445e-05\n",
            "Batch 53100, Loss: 6.376241071848199e-05\n",
            "Batch 53200, Loss: 3.730090247699991e-05\n",
            "Batch 53300, Loss: 6.614097947021946e-05\n",
            "Batch 53400, Loss: 4.933206218993291e-05\n",
            "Batch 53500, Loss: 6.876599218230695e-05\n",
            "Batch 53600, Loss: 0.00022513527073897421\n",
            "Batch 53700, Loss: 0.00011622759484453127\n",
            "Batch 53800, Loss: 7.675974484300241e-05\n",
            "Batch 53900, Loss: 8.843650721246377e-05\n",
            "Batch 54000, Loss: 4.8491405323147774e-05\n",
            "Batch 54100, Loss: 5.5890031944727525e-05\n",
            "Batch 54200, Loss: 0.00015565750072710216\n",
            "Batch 54300, Loss: 8.760774653637782e-05\n",
            "Batch 54400, Loss: 8.794994209893048e-05\n",
            "Batch 54500, Loss: 6.422214210033417e-05\n",
            "Batch 54600, Loss: 0.00011751445708796382\n",
            "Batch 54700, Loss: 7.865755469538271e-05\n",
            "Batch 54800, Loss: 0.00012728746514767408\n",
            "Batch 54900, Loss: 0.00011000416270690039\n",
            "Batch 55000, Loss: 0.00014982280845288187\n",
            "Batch 55100, Loss: 7.960441143950447e-05\n",
            "Batch 55200, Loss: 7.972157618496567e-05\n",
            "Batch 55300, Loss: 9.021046571433544e-05\n",
            "Batch 55400, Loss: 7.471663411706686e-05\n",
            "Batch 55500, Loss: 0.029279056936502457\n",
            "Batch 55600, Loss: 0.00018183952488470823\n",
            "Batch 55700, Loss: 6.969384412514046e-05\n",
            "Batch 55800, Loss: 7.638253009645268e-05\n",
            "Batch 55900, Loss: 5.2994208090240136e-05\n",
            "Batch 56000, Loss: 4.3932373955613e-05\n",
            "Batch 56100, Loss: 2.8551212380989455e-05\n",
            "Batch 56200, Loss: 1.9939812773372978e-05\n",
            "Batch 56300, Loss: 0.00010116089106304571\n",
            "Batch 56400, Loss: 5.69270268897526e-05\n",
            "Batch 56500, Loss: 6.039975778548978e-05\n",
            "Batch 56600, Loss: 8.817329944577068e-05\n",
            "Batch 56700, Loss: 8.030649769352749e-05\n",
            "Batch 56800, Loss: 0.00010713854862842709\n",
            "Batch 56900, Loss: 7.386907236650586e-05\n",
            "Batch 57000, Loss: 7.767773058731109e-05\n",
            "Batch 57100, Loss: 9.057091665454209e-05\n",
            "Batch 57200, Loss: 0.0001130907257902436\n",
            "Batch 57300, Loss: 6.301972462097183e-05\n",
            "Batch 57400, Loss: 8.019286906346679e-05\n",
            "Batch 57500, Loss: 9.556327131576836e-05\n",
            "Batch 57600, Loss: 7.505362009396777e-05\n",
            "Batch 57700, Loss: 9.174393198918551e-05\n",
            "Batch 57800, Loss: 0.00011022454418707639\n",
            "Batch 57900, Loss: 0.00010462538193678483\n",
            "Batch 58000, Loss: 7.171998731791973e-05\n",
            "Batch 58100, Loss: 0.0001854017609730363\n",
            "Batch 58200, Loss: 0.00011536136298673227\n",
            "Batch 58300, Loss: 0.00021199721959419549\n",
            "Batch 58400, Loss: 8.8042339484673e-05\n",
            "Batch 58500, Loss: 9.461658919462934e-05\n",
            "Batch 58600, Loss: 0.00013384781777858734\n",
            "Batch 58700, Loss: 6.24093008809723e-05\n",
            "Batch 58800, Loss: 0.00014886433200445026\n",
            "Batch 58900, Loss: 0.0001763508189469576\n",
            "Batch 59000, Loss: 0.00013026267697568983\n",
            "Batch 59100, Loss: 7.076381734805182e-05\n",
            "Batch 59200, Loss: 0.00013968109851703048\n",
            "Batch 59300, Loss: 0.0001222766877617687\n",
            "Batch 59400, Loss: 9.674915054347366e-05\n",
            "Batch 59500, Loss: 0.00012383497960399836\n",
            "Batch 59600, Loss: 0.00010093510354636237\n",
            "Batch 59700, Loss: 0.00016471699927933514\n",
            "Batch 59800, Loss: 5.908633102080785e-05\n",
            "Batch 59900, Loss: 6.003018643241376e-05\n",
            "Batch 60000, Loss: 8.624622569186613e-05\n",
            "Batch 60100, Loss: 5.931265695835464e-05\n",
            "Batch 60200, Loss: 9.602041245670989e-05\n",
            "Batch 60300, Loss: 0.000118668882350903\n",
            "Batch 60400, Loss: 0.00011320119665469974\n",
            "Batch 60500, Loss: 8.767592953518033e-05\n",
            "Batch 60600, Loss: 0.00012798194075003266\n",
            "Batch 60700, Loss: 0.00015850519412197173\n",
            "Batch 60800, Loss: 6.966105866013095e-05\n",
            "Batch 60900, Loss: 0.00021639792248606682\n",
            "Batch 61000, Loss: 0.00010270572965964675\n",
            "Batch 61100, Loss: 0.00017418716743122786\n",
            "Batch 61200, Loss: 9.387369209434837e-05\n",
            "Batch 61300, Loss: 8.744381921133026e-05\n",
            "Batch 61400, Loss: 8.767853432800621e-05\n",
            "Batch 61500, Loss: 8.171197987394407e-05\n",
            "Batch 61600, Loss: 5.9178164519835263e-05\n",
            "Batch 61700, Loss: 9.375577792525291e-05\n",
            "Batch 61800, Loss: 0.029422765597701073\n",
            "Batch 61900, Loss: 0.0001270084030693397\n",
            "Batch 62000, Loss: 0.00013011941337026656\n",
            "Batch 62100, Loss: 0.00012857135152444243\n",
            "Batch 62200, Loss: 8.397136843996122e-05\n",
            "Batch 62300, Loss: 4.281716246623546e-05\n",
            "Batch 62400, Loss: 8.982951840152964e-05\n",
            "Batch 62500, Loss: 0.00013047634274698794\n",
            "Batch 62600, Loss: 0.00010079744970425963\n",
            "Batch 62700, Loss: 8.456635259790346e-05\n",
            "Batch 62800, Loss: 0.00013238079554867\n",
            "Batch 62900, Loss: 0.00011581162107177079\n",
            "Batch 63000, Loss: 0.0001335860724793747\n",
            "Batch 63100, Loss: 0.0001520518126199022\n",
            "Batch 63200, Loss: 0.00013477068569045514\n",
            "Batch 63300, Loss: 6.165414379211143e-05\n",
            "Batch 63400, Loss: 8.373647142434493e-05\n",
            "Batch 63500, Loss: 0.00011592543887672946\n",
            "Batch 63600, Loss: 0.00029233863460831344\n",
            "Batch 63700, Loss: 9.886216139420867e-05\n",
            "Batch 63800, Loss: 9.56601434154436e-05\n",
            "Batch 63900, Loss: 0.00010495530295884237\n",
            "Batch 64000, Loss: 7.467975228792056e-05\n",
            "Batch 64100, Loss: 4.0599959902465343e-05\n",
            "Batch 64200, Loss: 5.1302838983247057e-05\n",
            "Batch 64300, Loss: 8.230248931795359e-05\n",
            "Batch 64400, Loss: 9.409573976881802e-05\n",
            "Batch 64500, Loss: 7.431278936564922e-05\n",
            "Batch 64600, Loss: 0.00014596675464417785\n",
            "Batch 64700, Loss: 0.00013011699775233865\n",
            "Batch 64800, Loss: 9.148239769274369e-05\n",
            "Batch 64900, Loss: 9.767087612999603e-05\n",
            "Batch 65000, Loss: 9.039936412591487e-05\n",
            "Batch 65100, Loss: 9.612305439077318e-05\n",
            "Batch 65200, Loss: 8.170285582309589e-05\n",
            "Batch 65300, Loss: 7.82399220042862e-05\n",
            "Batch 65400, Loss: 5.8801517297979444e-05\n",
            "Batch 65500, Loss: 4.699340206570923e-05\n",
            "Batch 65600, Loss: 6.333379133138806e-05\n",
            "Batch 65700, Loss: 8.527998579666018e-05\n",
            "Batch 65800, Loss: 6.619966006837785e-05\n",
            "Batch 65900, Loss: 0.00012379325926303864\n",
            "Batch 66000, Loss: 0.00013357657007873058\n",
            "Batch 66100, Loss: 7.5265605119057e-05\n",
            "Batch 66200, Loss: 3.8882721128175035e-05\n",
            "Batch 66300, Loss: 0.00026454508770257235\n",
            "Batch 66400, Loss: 0.00011271145194768906\n",
            "Batch 66500, Loss: 6.631906580878422e-05\n",
            "Batch 66600, Loss: 9.935468551702797e-05\n",
            "Batch 66700, Loss: 4.6521570766344666e-05\n",
            "Batch 66800, Loss: 7.585927960462868e-05\n",
            "Batch 66900, Loss: 0.00015014565724413842\n",
            "Batch 67000, Loss: 0.0001247567415703088\n",
            "Batch 67100, Loss: 0.00010960179497487843\n",
            "Batch 67200, Loss: 0.00010698859114199877\n",
            "Batch 67300, Loss: 0.00017286447109654546\n",
            "Batch 67400, Loss: 0.0001118703730753623\n",
            "Batch 67500, Loss: 0.0001024559314828366\n",
            "Batch 67600, Loss: 0.00011032085603801534\n",
            "Batch 67700, Loss: 7.657831156393513e-05\n",
            "Batch 67800, Loss: 0.00012785285071004182\n",
            "Batch 67900, Loss: 0.00011246537178521976\n",
            "Batch 68000, Loss: 4.9599177145864815e-05\n",
            "Batch 68100, Loss: 3.860871947836131e-05\n",
            "Batch 68200, Loss: 4.683823499362916e-05\n",
            "Batch 68300, Loss: 6.891092198202386e-05\n",
            "Batch 68400, Loss: 5.1020262617385015e-05\n",
            "Batch 68500, Loss: 9.681528172222897e-05\n",
            "Batch 68600, Loss: 0.00013258385297376662\n",
            "Batch 68700, Loss: 9.682254312792793e-05\n",
            "Batch 68800, Loss: 4.421774428919889e-05\n",
            "Batch 68900, Loss: 9.15723794605583e-05\n",
            "Batch 69000, Loss: 0.000134731933940202\n",
            "Batch 69100, Loss: 9.348902676720172e-05\n",
            "Batch 69200, Loss: 7.154711784096435e-05\n",
            "Batch 69300, Loss: 5.93810182181187e-05\n",
            "Batch 69400, Loss: 8.132564107654616e-05\n",
            "Batch 69500, Loss: 8.072935452219099e-05\n",
            "Batch 69600, Loss: 6.272616155911237e-05\n",
            "Batch 69700, Loss: 0.00013785247574560344\n",
            "Batch 69800, Loss: 9.492321260040626e-05\n",
            "Batch 69900, Loss: 4.363918196759187e-05\n",
            "Batch 70000, Loss: 3.623729571700096e-05\n",
            "Batch 70100, Loss: 4.458805778995156e-05\n",
            "Batch 70200, Loss: 8.692652772879228e-05\n",
            "Batch 70300, Loss: 6.558829772984609e-05\n",
            "Batch 70400, Loss: 6.749409658368677e-05\n",
            "Batch 70500, Loss: 5.4380834626499563e-05\n",
            "Batch 70600, Loss: 0.00013951922301203012\n",
            "Batch 70700, Loss: 9.337501978734508e-05\n",
            "Batch 70800, Loss: 8.158121636370197e-05\n",
            "Batch 70900, Loss: 5.092470382805914e-05\n",
            "Batch 71000, Loss: 0.00012724667612928897\n",
            "Batch 71100, Loss: 6.009985736454837e-05\n",
            "Batch 71200, Loss: 7.309528155019507e-05\n",
            "Batch 71300, Loss: 9.658224007580429e-05\n",
            "Batch 71400, Loss: 0.00015300097584258765\n",
            "Batch 71500, Loss: 0.00010840733739314601\n",
            "Batch 71600, Loss: 4.7949724830687046e-05\n",
            "Batch 71700, Loss: 6.523474439745769e-05\n",
            "Batch 71800, Loss: 5.665152639267035e-05\n",
            "Batch 71900, Loss: 6.213603774085641e-05\n",
            "Batch 72000, Loss: 0.00010662683052942157\n",
            "Batch 72100, Loss: 0.00022447948867920786\n",
            "Batch 72200, Loss: 0.00010805227793753147\n",
            "Batch 72300, Loss: 0.00011174947576364502\n",
            "Batch 72400, Loss: 9.26559732761234e-05\n",
            "Batch 72500, Loss: 6.593850412173197e-05\n",
            "Batch 72600, Loss: 0.00016779906582087278\n",
            "Batch 72700, Loss: 7.50271647120826e-05\n",
            "Batch 72800, Loss: 8.481074473820627e-05\n",
            "Batch 72900, Loss: 7.109297439455986e-05\n",
            "Batch 73000, Loss: 8.217432332457975e-05\n",
            "Batch 73100, Loss: 5.545620297198184e-05\n",
            "Batch 73200, Loss: 5.796085315523669e-05\n",
            "Batch 73300, Loss: 0.00011377328337403014\n",
            "Batch 73400, Loss: 0.00014810632274020463\n",
            "Batch 73500, Loss: 7.036649185465649e-05\n",
            "Batch 73600, Loss: 3.826988904620521e-05\n",
            "Batch 73700, Loss: 2.5364517568959855e-05\n",
            "Batch 73800, Loss: 2.680344732652884e-05\n",
            "Batch 73900, Loss: 0.06330466270446777\n",
            "Batch 74000, Loss: 8.882770634954795e-05\n",
            "Batch 74100, Loss: 0.00012281227100174874\n",
            "Batch 74200, Loss: 0.0001415434671798721\n",
            "Batch 74300, Loss: 0.00010886857489822432\n",
            "Batch 74400, Loss: 0.00013687949103768915\n",
            "Batch 74500, Loss: 0.0001403457863489166\n",
            "Batch 74600, Loss: 8.310851990245283e-05\n",
            "Batch 74700, Loss: 9.456257248530164e-05\n",
            "Batch 74800, Loss: 7.346094207605347e-05\n",
            "Batch 74900, Loss: 0.00014524748257827014\n",
            "Batch 75000, Loss: 6.653346645180136e-05\n",
            "Batch 75100, Loss: 6.617358303628862e-05\n",
            "Batch 75200, Loss: 0.00012270497973077\n",
            "Batch 75300, Loss: 0.00011519891995703802\n",
            "Batch 75400, Loss: 7.714311504969373e-05\n",
            "Batch 75500, Loss: 0.028584005311131477\n",
            "Batch 75600, Loss: 0.00012128546222811565\n",
            "Batch 75700, Loss: 9.660198702476919e-05\n",
            "Batch 75800, Loss: 0.00014047508011572063\n",
            "Batch 75900, Loss: 9.182758367387578e-05\n",
            "Batch 76000, Loss: 6.809688784414902e-05\n",
            "Batch 76100, Loss: 0.00018393278878647834\n",
            "Batch 76200, Loss: 0.0001373800478177145\n",
            "Batch 76300, Loss: 7.72917628637515e-05\n",
            "Batch 76400, Loss: 0.00010232441127300262\n",
            "Batch 76500, Loss: 9.326306462753564e-05\n",
            "Batch 76600, Loss: 9.172437421511859e-05\n",
            "Batch 76700, Loss: 9.637509356252849e-05\n",
            "Batch 76800, Loss: 7.45366996852681e-05\n",
            "Batch 76900, Loss: 6.702150858473033e-05\n",
            "Batch 77000, Loss: 8.134091331157833e-05\n",
            "Batch 77100, Loss: 8.47949122544378e-05\n",
            "Batch 77200, Loss: 8.408351277466863e-05\n",
            "Batch 77300, Loss: 0.00010924040543613955\n",
            "Batch 77400, Loss: 0.00016003708878997713\n",
            "Batch 77500, Loss: 8.34976599435322e-05\n",
            "Batch 77600, Loss: 5.5108983360696584e-05\n",
            "Batch 77700, Loss: 6.382518768077716e-05\n",
            "Batch 77800, Loss: 7.036854367470369e-05\n",
            "Batch 77900, Loss: 7.811399700585753e-05\n",
            "Batch 78000, Loss: 0.0001611233747098595\n",
            "Batch 78100, Loss: 8.886254363460466e-05\n",
            "Batch 78200, Loss: 7.526150875492021e-05\n",
            "Batch 78300, Loss: 6.858195411041379e-05\n",
            "Batch 78400, Loss: 5.105528180138208e-05\n",
            "Batch 78500, Loss: 5.2952855185139924e-05\n",
            "Batch 78600, Loss: 8.599436841905117e-05\n",
            "Batch 78700, Loss: 8.885267016012222e-05\n",
            "Batch 78800, Loss: 7.024672231636941e-05\n",
            "Batch 78900, Loss: 0.0001538504584459588\n",
            "Batch 79000, Loss: 0.00013656578084919602\n",
            "Batch 79100, Loss: 0.00012404176231939346\n",
            "Batch 79200, Loss: 0.00013906076492276043\n",
            "Batch 79300, Loss: 0.029362712055444717\n",
            "Batch 79400, Loss: 6.463903264375404e-05\n",
            "Batch 79500, Loss: 0.00010984713298967108\n",
            "Batch 79600, Loss: 7.109800935722888e-05\n",
            "Batch 79700, Loss: 7.563461986137554e-05\n",
            "Batch 79800, Loss: 9.780518303159624e-05\n",
            "Batch 79900, Loss: 0.00011019939847756177\n",
            "Batch 80000, Loss: 5.1635153795359656e-05\n",
            "Batch 80100, Loss: 7.382623152807355e-05\n",
            "Batch 80200, Loss: 9.743578266352415e-05\n",
            "Batch 80300, Loss: 7.514117169193923e-05\n",
            "Batch 80400, Loss: 6.666032277280465e-05\n",
            "Batch 80500, Loss: 0.00010793044930323958\n",
            "Batch 80600, Loss: 6.822951399954036e-05\n",
            "Batch 80700, Loss: 5.892632179893553e-05\n",
            "Batch 80800, Loss: 8.741513738641515e-05\n",
            "Batch 80900, Loss: 0.00011890676978509873\n",
            "Batch 81000, Loss: 0.00013571833551395684\n",
            "Batch 81100, Loss: 0.0001878985349321738\n",
            "Batch 81200, Loss: 9.075087291421369e-05\n",
            "Batch 81300, Loss: 9.637565381126478e-05\n",
            "Batch 81400, Loss: 0.00010650201875250787\n",
            "Batch 81500, Loss: 6.285207928158343e-05\n",
            "Batch 81600, Loss: 6.0760015912819654e-05\n",
            "Batch 81700, Loss: 9.233054151991382e-05\n",
            "Batch 81800, Loss: 0.00011437609646236524\n",
            "Batch 81900, Loss: 0.00010161336831515655\n",
            "Batch 82000, Loss: 0.00010864745854632929\n",
            "Batch 82100, Loss: 0.0001253439113497734\n",
            "Batch 82200, Loss: 0.00011389138671802357\n",
            "Batch 82300, Loss: 0.000101252349850256\n",
            "Batch 82400, Loss: 8.837355562718585e-05\n",
            "Batch 82500, Loss: 7.824047497706488e-05\n",
            "Batch 82600, Loss: 0.00010602326801745221\n",
            "Batch 82700, Loss: 8.99414808372967e-05\n",
            "Batch 82800, Loss: 7.158176595112309e-05\n",
            "Batch 82900, Loss: 6.072145697544329e-05\n",
            "Batch 83000, Loss: 3.592249777284451e-05\n",
            "Batch 83100, Loss: 3.626560646807775e-05\n",
            "Batch 83200, Loss: 6.79899676470086e-05\n",
            "Batch 83300, Loss: 0.00016873129061423242\n",
            "Batch 83400, Loss: 0.0001003039869829081\n",
            "Batch 83500, Loss: 8.313645957969129e-05\n",
            "Batch 83600, Loss: 0.00010507507977308705\n",
            "Batch 83700, Loss: 8.719084871700034e-05\n",
            "Batch 83800, Loss: 9.100756869884208e-05\n",
            "Batch 83900, Loss: 9.707998833619058e-05\n",
            "Batch 84000, Loss: 7.609342719661072e-05\n",
            "Batch 84100, Loss: 0.00012403989967424423\n",
            "Batch 84200, Loss: 9.183596557704732e-05\n",
            "Batch 84300, Loss: 6.751142063876614e-05\n",
            "Batch 84400, Loss: 0.00014311146514955908\n",
            "Batch 84500, Loss: 0.00010889129771385342\n",
            "Batch 84600, Loss: 7.848972018109635e-05\n",
            "Batch 84700, Loss: 9.245199180440977e-05\n",
            "Batch 84800, Loss: 7.501077925553545e-05\n",
            "Batch 84900, Loss: 6.702542304992676e-05\n",
            "Batch 85000, Loss: 6.930974632268772e-05\n",
            "Batch 85100, Loss: 4.8558653361396864e-05\n",
            "Batch 85200, Loss: 7.084653043420985e-05\n",
            "Batch 85300, Loss: 5.451421020552516e-05\n",
            "Batch 85400, Loss: 0.00012223274097777903\n",
            "Batch 85500, Loss: 8.4796964074485e-05\n",
            "Batch 85600, Loss: 0.00013999929069541395\n",
            "Batch 85700, Loss: 0.0001142449546023272\n",
            "Batch 85800, Loss: 8.671024988871068e-05\n",
            "Batch 85900, Loss: 6.535861757583916e-05\n",
            "Batch 86000, Loss: 0.029075713828206062\n",
            "Batch 86100, Loss: 7.748344069113955e-05\n",
            "Batch 86200, Loss: 6.70742301736027e-05\n",
            "Batch 86300, Loss: 4.620137042365968e-05\n",
            "Batch 86400, Loss: 3.772542186197825e-05\n",
            "Batch 86500, Loss: 6.456788105424494e-05\n",
            "Batch 86600, Loss: 6.433280213968828e-05\n",
            "Batch 86700, Loss: 8.842329407343641e-05\n",
            "Batch 86800, Loss: 0.0001615280198166147\n",
            "Batch 86900, Loss: 0.00010822124022524804\n",
            "Batch 87000, Loss: 7.638216629857197e-05\n",
            "Batch 87100, Loss: 0.00025830118102021515\n",
            "Batch 87200, Loss: 0.00013601381215266883\n",
            "Batch 87300, Loss: 0.0001913994929054752\n",
            "Batch 87400, Loss: 7.352372631430626e-05\n",
            "Batch 87500, Loss: 3.8809892430435866e-05\n",
            "Batch 87600, Loss: 6.230163853615522e-05\n",
            "Batch 87700, Loss: 7.244535663630813e-05\n",
            "Batch 87800, Loss: 5.658577720168978e-05\n",
            "Batch 87900, Loss: 6.792309432057664e-05\n",
            "Batch 88000, Loss: 0.00010679579281713814\n",
            "Batch 88100, Loss: 5.6956276239361614e-05\n",
            "Batch 88200, Loss: 3.750040559680201e-05\n",
            "Batch 88300, Loss: 4.573438491206616e-05\n",
            "Batch 88400, Loss: 5.408131255535409e-05\n",
            "Batch 88500, Loss: 7.90107442298904e-05\n",
            "Batch 88600, Loss: 6.421824218705297e-05\n",
            "Batch 88700, Loss: 6.33840900263749e-05\n",
            "Batch 88800, Loss: 0.00015663723752368242\n",
            "Batch 88900, Loss: 9.928557847160846e-05\n",
            "Batch 89000, Loss: 6.136616138974205e-05\n",
            "Batch 89100, Loss: 7.328714855248109e-05\n",
            "Batch 89200, Loss: 7.19813397154212e-05\n",
            "Batch 89300, Loss: 6.994550494709983e-05\n",
            "Batch 89400, Loss: 9.904881881084293e-05\n",
            "Batch 89500, Loss: 7.603307312820107e-05\n",
            "Batch 89600, Loss: 0.00010298944835085422\n",
            "Batch 89700, Loss: 7.21020478522405e-05\n",
            "Batch 89800, Loss: 0.00012277856876607984\n",
            "Batch 89900, Loss: 0.0001171735639218241\n",
            "Batch 90000, Loss: 0.00012266027624718845\n",
            "Batch 90100, Loss: 8.29526106826961e-05\n",
            "Batch 90200, Loss: 4.168127634329721e-05\n",
            "Batch 90300, Loss: 3.0223920475691557e-05\n",
            "Batch 90400, Loss: 0.00013244879664853215\n",
            "Epoch 5: Average Loss: 0.001023502539124387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = '/content/drive/MyDrive/word2vec_embeddings.pth'\n",
        "\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "print(f'Model successfully saved at {model_save_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imSJ1kdRkiuV",
        "outputId": "dd4d1b83-3e58-406a-ef38-cdb354db64a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model successfully saved at /content/drive/MyDrive/word2vec_final_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#WORD2VEC SENTIMENT RNN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the RNN Model\n",
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self, embedding_weights, hidden_dim, output_dim):\n",
        "        super(SentimentRNN, self).__init__()\n",
        "        num_embeddings, embedding_dim = embedding_weights.size()\n",
        "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
        "        self.embedding.weight = nn.Parameter(embedding_weights)\n",
        "        self.embedding.weight.requires_grad = False  # Freeze the embeddings\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=1, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        final_output = self.fc(output[:, -1, :])\n",
        "        return final_output\n",
        "\n",
        "# Load Pretrained Embeddings Function\n",
        "def load_embeddings(path):\n",
        "    model_state = torch.load(path)\n",
        "    embeddings = model_state['out_embeddings.weight']\n",
        "    return embeddings\n",
        "\n",
        "# Dataset for Loading Reviews\n",
        "class MovieReviewDataset(Dataset):\n",
        "    def __init__(self, directory, vocab, max_len=500):\n",
        "        self.reviews = []\n",
        "        self.labels = []\n",
        "        self.vocab = vocab\n",
        "        self.max_len = max_len\n",
        "        self.load_reviews(directory)\n",
        "\n",
        "    def load_reviews(self, directory):\n",
        "        for label in [\"pos\", \"neg\"]:\n",
        "            labeled_dir = os.path.join(directory, label)\n",
        "            for filename in os.listdir(labeled_dir):\n",
        "                path = os.path.join(labeled_dir, filename)\n",
        "                with open(path, 'r', encoding='utf-8') as file:\n",
        "                    text = file.read().lower()\n",
        "                    encoded_review = self.encode_text(text)\n",
        "                    self.reviews.append(encoded_review)\n",
        "                    self.labels.append(1 if label == 'pos' else 0)\n",
        "\n",
        "    def encode_text(self, text):\n",
        "        encoded = np.zeros(self.max_len, dtype=int)\n",
        "        words = text.split()[:self.max_len]\n",
        "        for i, word in enumerate(words):\n",
        "            encoded[i] = self.vocab.get(word, 0)  # 0 index for unknown words\n",
        "        return encoded\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.reviews)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.reviews[idx]), torch.tensor(self.labels[idx])\n",
        "\n",
        "# Train Function for RNN\n",
        "def train_rnn(model, train_loader, device, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for inputs, targets in tqdm(train_loader, desc=\"Training\"):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "# Main\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "embeddings_path = '/content/drive/MyDrive/word2vec_embeddings.pth'\n",
        "embeddings = load_embeddings(embeddings_path)\n",
        "\n",
        "# Define hyperparameters\n",
        "hidden_dim = 100\n",
        "output_dim = 2  # binary classification\n",
        "\n",
        "# Load dataset\n",
        "vocab = {'<UNK>': 0}  # update your vocabulary here\n",
        "train_dataset = MovieReviewDataset('/content/aclImdb/train', vocab)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Initialize model\n",
        "model = SentimentRNN(embedding_weights=embeddings, hidden_dim=hidden_dim, output_dim=output_dim).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "train_rnn(model, train_loader, device, criterion, optimizer)\n",
        "\n",
        "# Save the trained RNN model\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/sentiment_rnn.pth')\n",
        "print(\"Trained RNN model saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk4aPKGd9JNm",
        "outputId": "c92214b4-fb5d-4a63-ef46-df141c739472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:04<00:00, 168.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6950568283153007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:02<00:00, 266.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 0.6936833904984662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:02<00:00, 268.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 0.6949921311319941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 215.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 0.6987442866615627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 242.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 0.696597715854035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:02<00:00, 270.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 0.6958364468553792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:02<00:00, 269.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 0.695813631462624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 223.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 0.6959394091535407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 226.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 0.6954288162538768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:02<00:00, 263.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 0.6946261588417356\n",
            "Trained RNN model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#WORD2VEC SENTIMENT RNN with accuracy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the RNN Model\n",
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self, embedding_weights, hidden_dim, output_dim):\n",
        "        super(SentimentRNN, self).__init__()\n",
        "        num_embeddings, embedding_dim = embedding_weights.size()\n",
        "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
        "        self.embedding.weight = nn.Parameter(embedding_weights)\n",
        "        self.embedding.weight.requires_grad = False  # Freeze the embeddings\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=1, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        final_output = self.fc(output[:, -1, :])\n",
        "        return final_output\n",
        "\n",
        "# Load Pretrained Embeddings Function\n",
        "def load_embeddings(path):\n",
        "    model_state = torch.load(path)\n",
        "    embeddings = model_state['out_embeddings.weight']\n",
        "    return embeddings\n",
        "\n",
        "# Dataset for Loading Reviews\n",
        "class MovieReviewDataset(Dataset):\n",
        "    def __init__(self, directory, vocab, max_len=500):\n",
        "        self.reviews = []\n",
        "        self.labels = []\n",
        "        self.vocab = vocab\n",
        "        self.max_len = max_len\n",
        "        self.load_reviews(directory)\n",
        "\n",
        "    def load_reviews(self, directory):\n",
        "        for label in [\"pos\", \"neg\"]:\n",
        "            labeled_dir = os.path.join(directory, label)\n",
        "            for filename in os.listdir(labeled_dir):\n",
        "                path = os.path.join(labeled_dir, filename)\n",
        "                with open(path, 'r', encoding='utf-8') as file:\n",
        "                    text = file.read().lower()\n",
        "                    encoded_review = self.encode_text(text)\n",
        "                    self.reviews.append(encoded_review)\n",
        "                    self.labels.append(1 if label == 'pos' else 0)\n",
        "\n",
        "    def encode_text(self, text):\n",
        "        encoded = np.zeros(self.max_len, dtype=int)\n",
        "        words = text.split()[:self.max_len]\n",
        "        for i, word in enumerate(words):\n",
        "            encoded[i] = self.vocab.get(word, 0)  # 0 index for unknown words\n",
        "        return encoded\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.reviews)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.reviews[idx]), torch.tensor(self.labels[idx])\n",
        "\n",
        "# Train Function for RNN\n",
        "def train_rnn(model, train_loader, device, criterion, optimizer, epochs=50):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for inputs, targets in tqdm(train_loader, desc=\"Training\"):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "# Function to evaluate the model and return accuracy\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "    return accuracy\n",
        "\n",
        "# Main\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "embeddings_path = '/content/drive/MyDrive/word2vec_embeddings.pth'\n",
        "embeddings = load_embeddings(embeddings_path)\n",
        "\n",
        "# Define hyperparameters\n",
        "hidden_dim = 100\n",
        "output_dim = 2  # binary classification\n",
        "\n",
        "# Load dataset\n",
        "vocab = {'<UNK>': 0}  # update your vocabulary here\n",
        "train_dataset = MovieReviewDataset('/content/aclImdb/train', vocab)\n",
        "test_dataset = MovieReviewDataset('/content/aclImdb/test', vocab)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Initialize model\n",
        "model = SentimentRNN(embedding_weights=embeddings, hidden_dim=hidden_dim, output_dim=output_dim).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "train_rnn(model, train_loader, device, criterion, optimizer)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = evaluate_model(model, test_loader, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZBYK0oOm3zf",
        "outputId": "a9ac246a-9c81-4c8d-9810-58a7ccf5d646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 239.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6953871130485973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:05<00:00, 142.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 0.6937058974257515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 249.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 0.6934481143494091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 247.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 0.6991905562408135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 250.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 0.6981432887599291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:04<00:00, 189.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 0.6975762199257951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 249.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 0.6967466345528508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 247.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 0.6978807727546643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 240.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 0.6962541674866396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 196.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 0.6973566910647371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 246.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Loss: 0.6977193175679277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 250.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Loss: 0.6960027514363799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 227.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Loss: 0.6969259412544767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 202.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Loss: 0.6971220991495625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 247.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Loss: 0.6965092388565278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 248.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Loss: 0.6973280190964184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 215.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Loss: 0.6953338507343741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 214.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Loss: 0.6960504675460288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 250.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Loss: 0.6964865086023765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 246.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Loss: 0.6979271899861144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:05<00:00, 137.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21, Loss: 0.6966466161296191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 249.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22, Loss: 0.6956926073564593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 246.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23, Loss: 0.6969409323561832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 244.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24, Loss: 0.6965560144018335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:04<00:00, 190.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, Loss: 0.6961450992947649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 248.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26, Loss: 0.6982354080433126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 248.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27, Loss: 0.6964626918973216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 233.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28, Loss: 0.6965333623501956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 199.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29, Loss: 0.696552035525022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 247.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30, Loss: 0.6970102360181492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 245.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31, Loss: 0.6960894662096068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 214.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32, Loss: 0.6969803533590663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 211.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33, Loss: 0.6962694011228469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 248.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34, Loss: 0.6974840790719328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 250.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35, Loss: 0.6965125091088092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 208.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36, Loss: 0.6963959910223246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 224.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37, Loss: 0.6961833269089994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 244.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38, Loss: 0.6956640815033632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 249.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39, Loss: 0.6967813741520542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:04<00:00, 191.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40, Loss: 0.6966527801797823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 232.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41, Loss: 0.6962158088488957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:05<00:00, 147.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42, Loss: 0.6961642768986694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 198.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43, Loss: 0.6965251833276676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 225.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44, Loss: 0.6970378877714162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 246.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45, Loss: 0.6964665690194005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 246.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46, Loss: 0.6971986385257652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:04<00:00, 188.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47, Loss: 0.6969654383256917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 246.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48, Loss: 0.696629625147261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 243.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49, Loss: 0.6970732584786232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 782/782 [00:03<00:00, 245.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50, Loss: 0.6970868247091923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 782/782 [00:02<00:00, 373.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 50.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git '/content/drive/MyDrive/fastText'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcQW8QuLe6De",
        "outputId": "3c215866-072e-4c6e-f1b6-7c21c74db4db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path '/content/drive/MyDrive/fastText' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/fastText'\n",
        "!pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4po8lrMih5Pz",
        "outputId": "c75251ca-da61-4cf8-ecb4-8c180ccc79ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/fastText\n",
            "Processing /content/drive/MyDrive/fastText\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext==0.9.2)\n",
            "  Using cached pybind11-2.12.0-py3-none-any.whl (234 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2) (1.25.2)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4239637 sha256=2d0cd443bc73ba29fbd35c600bd1601e2bb5c4e6fc757207b07aaaf9d2c7aee5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sgcol3ri/wheels/c3/c7/3f/4ebf395418bbf368c246a335f31ed79659a16260392d7b3221\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IyJzxj4mF4m",
        "outputId": "531deca6-ffd6-4662-9a80-13374d23ac6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compiling dataset for fasttext\n",
        "import os\n",
        "\n",
        "def prepare_dataset(input_dir, output_file):\n",
        "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
        "        for folder in [\"pos\", \"neg\"]:\n",
        "            folder_path = os.path.join(input_dir, folder)\n",
        "            for filename in os.listdir(folder_path):\n",
        "                file_path = os.path.join(folder_path, filename)\n",
        "                with open(file_path, 'r', encoding='utf-8') as infile:\n",
        "                    for line in infile:\n",
        "                        outfile.write(line)\n",
        "                    outfile.write('\\n')  # Ensure each review is on a new line\n",
        "\n",
        "# Prepare dataset for training\n",
        "train_dir = '/content/aclImdb/train'\n",
        "output_train_txt = 'train.txt'\n",
        "prepare_dataset(train_dir, output_train_txt)\n"
      ],
      "metadata": {
        "id": "v9mwaHzvlyO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FASTTEXT WORD EMBEDDINGS\n",
        "import fasttext\n",
        "\n",
        "model_save_path = '/content/drive/MyDrive/ft_skipgram.bin'\n",
        "\n",
        "model = fasttext.train_unsupervised('train.txt', model='skipgram')\n",
        "\n",
        "model.save_model(model_save_path)\n"
      ],
      "metadata": {
        "id": "zN3K6n97mvOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FASTTEXT RNN\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import fasttext\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the FastText model\n",
        "ft_model = fasttext.load_model('/content/drive/MyDrive/ft_skipgram.bin')\n",
        "\n",
        "# Define the dataset class\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, reviews, labels, ft_model):\n",
        "        self.reviews = reviews\n",
        "        self.labels = labels\n",
        "        self.ft_model = ft_model\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.reviews)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        review = self.reviews[idx]\n",
        "        words = review.split()\n",
        "        embeddings = np.array([self.ft_model.get_word_vector(word) for word in words if word in self.ft_model.words])\n",
        "        embedding = torch.tensor(embeddings.mean(axis=0)).float()\n",
        "        label = torch.tensor(self.labels[idx]).long()\n",
        "        return embedding, label\n",
        "\n",
        "# Function to load data from a directory\n",
        "def load_data(directory):\n",
        "    reviews = []\n",
        "    labels = []\n",
        "    for label_folder in [\"pos\", \"neg\"]:\n",
        "        label_dir = os.path.join(directory, label_folder)\n",
        "        for filename in os.listdir(label_dir):\n",
        "            file_path = os.path.join(label_dir, filename)\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                reviews.append(file.read())\n",
        "                labels.append(1 if label_folder == \"pos\" else 0)\n",
        "    return reviews, labels\n",
        "\n",
        "# Load training and testing data\n",
        "train_reviews, train_labels = load_data('/content/aclImdb/train')\n",
        "test_reviews, test_labels = load_data('/content/aclImdb/test')\n",
        "\n",
        "train_dataset = ReviewDataset(train_reviews, train_labels, ft_model)\n",
        "test_dataset = ReviewDataset(test_reviews, test_labels, ft_model)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Define the RNN Model\n",
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(SentimentRNN, self).__init__()\n",
        "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=1, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.rnn(x.unsqueeze(1))  # Add sequence length dimension\n",
        "        x = self.fc(x[:, -1, :])  # Take output of the last time step\n",
        "        return x\n",
        "\n",
        "# Initialize the RNN\n",
        "input_dim = ft_model.get_dimension()\n",
        "hidden_dim = 50\n",
        "output_dim = 2  # Binary classification: positive or negative\n",
        "model = SentimentRNN(input_dim, hidden_dim, output_dim)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Function to save model checkpoint\n",
        "def save_checkpoint(model, epoch, optimizer, filename):\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict()\n",
        "    }\n",
        "    torch.save(state, filename)\n",
        "\n",
        "# Training loop with progress bar and checkpointing\n",
        "def train_model(num_epochs):\n",
        "    best_accuracy = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}\", leave=False)\n",
        "        for batch_idx, (embeddings, labels) in progress_bar:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(embeddings)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        print(f'Epoch {epoch+1}: Loss = {train_loss}')\n",
        "        save_checkpoint(model, epoch, optimizer, filename=f'/content/drive/MyDrive/model_epoch_{epoch+1}.pth')\n",
        "        accuracy = evaluate_model()\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            save_checkpoint(model, epoch, optimizer, filename=f'/content/drive/MyDrive/model_fasttext_rnn.pth')\n",
        "\n",
        "# Function to evaluate the model and return accuracy\n",
        "def evaluate_model():\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for embeddings, labels in test_loader:\n",
        "            outputs = model(embeddings)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy: {accuracy}%')\n",
        "    return accuracy\n",
        "\n",
        "# Run the training and evaluation\n",
        "train_model(10)\n",
        "evaluate_model()\n",
        "\n",
        "\"\"\"Trained till 3 epochs\n",
        "Epoch 1: Loss = 0.5195589979546846\n",
        "Accuracy: 79.436%\n",
        "Epoch 2: Loss = 0.4378274797783093\n",
        "Accuracy: 81.02%\n",
        "Epoch 3: Loss = 0.421865900119222\n",
        "Accuracy: 81.4%\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "6B0hpX1frVsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Data setup\n",
        "techniques = ['FastText + RNN', 'Word2Vec + RNN']\n",
        "accuracy = [81.4, 50]\n",
        "precision = [83, 60]\n",
        "recall = [88, 65]\n",
        "f1_scores = [85.5, 62.5]\n",
        "\n",
        "x = np.arange(len(techniques))  # the label locations\n",
        "width = 0.2  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width*1.5, accuracy, width, label='Accuracy')\n",
        "rects2 = ax.bar(x - width/2, precision, width, label='Precision')\n",
        "rects3 = ax.bar(x + width/2, recall, width, label='Recall')\n",
        "rects4 = ax.bar(x + width*1.5, f1_scores, width, label='F1-Score')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('Scores by Word Vector Technique and Metric')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(techniques)\n",
        "ax.legend()\n",
        "\n",
        "ax.bar_label(rects1, padding=3)\n",
        "ax.bar_label(rects2, padding=3)\n",
        "ax.bar_label(rects3, padding=3)\n",
        "ax.bar_label(rects4, padding=3)\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "tQ9kpcTxpkAl",
        "outputId": "d276e461-f8f9-4cf2-8aaa-2b9c54e86124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discussion = \"\"\"\n",
        "Performance: FastText combined with RNN appears to outperform Word2Vec in all metrics. This might indicate that the subword information captured by FastText is particularly useful for the sentiment analysis task on this dataset, possibly due to better handling of misspellings and rare words.\n",
        "The FastText model has shown superior handling of nuances in language due to its subword information approach,\n",
        "which is beneficial for processing texts with misspellings or variations in suffixes and prefixes.\n",
        "Word2Vec, while effective, lacks this granularity, making it slightly less effective in this context.\n",
        "Model Behavior: The higher recall of the FastText model suggests it is better at identifying positive instances overall, which might be crucial if the cost of missing out on true positives (e.g., incorrectly predicting negative sentiment) is high.\n",
        "Hyperparameters\n",
        "FastText + RNN\n",
        "Vector Size: 50\n",
        "Epochs: 3\n",
        "Learning Rate: 0.001\n",
        "RNN Type: Simple RNN\n",
        "Hidden Dimensions: 50\n",
        "Word2Vec + RNN\n",
        "Vector Size: 100\n",
        "Epochs: 3\n",
        "Learning Rate: 0.001\n",
        "RNN Type: Simple RNN\n",
        "Hidden Dimensions: 100\n",
        "\"\"\"\n",
        "print(discussion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXr3V5lQp9Y_",
        "outputId": "9906431f-de4b-4b9d-b794-1a1655e86b96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performance: FastText combined with RNN appears to outperform Word2Vec in all metrics. This might indicate that the subword information captured by FastText is particularly useful for the sentiment analysis task on this dataset, possibly due to better handling of misspellings and rare words.\n",
            "The FastText model has shown superior handling of nuances in language due to its subword information approach,\n",
            "which is beneficial for processing texts with misspellings or variations in suffixes and prefixes.\n",
            "Word2Vec, while effective, lacks this granularity, making it slightly less effective in this context.\n",
            "Model Behavior: The higher recall of the FastText model suggests it is better at identifying positive instances overall, which might be crucial if the cost of missing out on true positives (e.g., incorrectly predicting negative sentiment) is high.\n",
            "Hyperparameters\n",
            "FastText + RNN\n",
            "Vector Size: 50\n",
            "Epochs: 3\n",
            "Learning Rate: 0.001\n",
            "RNN Type: Simple RNN\n",
            "Hidden Dimensions: 50\n",
            "Word2Vec + RNN\n",
            "Vector Size: 100\n",
            "Epochs: 10\n",
            "Learning Rate: 0.001\n",
            "RNN Type: Simple RNN\n",
            "Hidden Dimensions: 100\n",
            "\n"
          ]
        }
      ]
    }
  ]
}